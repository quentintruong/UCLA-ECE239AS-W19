layer_dims = [600, 600, 600, 600]
weight_scale = 0.01
learning_rate = 1e-3
lr_decay = 0.90

model = FullyConnectedNet(layer_dims, weight_scale=weight_scale,
                          dropout=0.65, reg=1e-2, use_batchnorm=True)

solver = Solver(model, data,
                num_epochs=50, batch_size=100,
                update_rule='adam',
                optim_config={
                  'learning_rate': learning_rate,
                },
                lr_decay=lr_decay,
                verbose=True, print_every=50)
solver.train()

(Iteration 1 / 24500) loss: 3.765205
(Epoch 0 / 50) train acc: 0.132000; val_acc: 0.162000
(Iteration 51 / 24500) loss: 2.793545
(Iteration 101 / 24500) loss: 2.726092
(Iteration 151 / 24500) loss: 2.431111
(Iteration 201 / 24500) loss: 2.220208
(Iteration 251 / 24500) loss: 2.147267
(Iteration 301 / 24500) loss: 2.377143
(Iteration 351 / 24500) loss: 2.221740
(Iteration 401 / 24500) loss: 2.472030
(Iteration 451 / 24500) loss: 2.393901
(Epoch 1 / 50) train acc: 0.356000; val_acc: 0.371000
(Iteration 501 / 24500) loss: 2.358736
(Iteration 551 / 24500) loss: 2.358058
(Iteration 601 / 24500) loss: 2.272066
(Iteration 651 / 24500) loss: 2.244011
(Iteration 701 / 24500) loss: 2.298688
(Iteration 751 / 24500) loss: 2.455681
(Iteration 801 / 24500) loss: 2.381803
(Iteration 851 / 24500) loss: 2.248328
(Iteration 901 / 24500) loss: 2.406036
(Iteration 951 / 24500) loss: 2.482948
(Epoch 2 / 50) train acc: 0.394000; val_acc: 0.371000
(Iteration 1001 / 24500) loss: 2.373458
(Iteration 1051 / 24500) loss: 2.519264
(Iteration 1101 / 24500) loss: 2.336360
(Iteration 1151 / 24500) loss: 2.082204
(Iteration 1201 / 24500) loss: 2.280577
(Iteration 1251 / 24500) loss: 2.148705
(Iteration 1301 / 24500) loss: 2.339917
(Iteration 1351 / 24500) loss: 2.222550
(Iteration 1401 / 24500) loss: 2.086957
(Iteration 1451 / 24500) loss: 2.351424
(Epoch 3 / 50) train acc: 0.402000; val_acc: 0.379000
(Iteration 1501 / 24500) loss: 2.159680
(Iteration 1551 / 24500) loss: 2.149807
(Iteration 1601 / 24500) loss: 2.170636
(Iteration 1651 / 24500) loss: 2.112008
(Iteration 1701 / 24500) loss: 2.289326
(Iteration 1751 / 24500) loss: 2.318209
(Iteration 1801 / 24500) loss: 2.300287
(Iteration 1851 / 24500) loss: 2.213140
(Iteration 1901 / 24500) loss: 2.306298
(Iteration 1951 / 24500) loss: 2.277017
(Epoch 4 / 50) train acc: 0.407000; val_acc: 0.404000
(Iteration 2001 / 24500) loss: 2.345607
(Iteration 2051 / 24500) loss: 2.211717
(Iteration 2101 / 24500) loss: 2.346415
(Iteration 2151 / 24500) loss: 1.999277
(Iteration 2201 / 24500) loss: 2.348626
(Iteration 2251 / 24500) loss: 2.124281
(Iteration 2301 / 24500) loss: 2.261478
(Iteration 2351 / 24500) loss: 2.136482
(Iteration 2401 / 24500) loss: 2.303007
(Epoch 5 / 50) train acc: 0.401000; val_acc: 0.408000
(Iteration 2451 / 24500) loss: 2.355100
(Iteration 2501 / 24500) loss: 2.163588
(Iteration 2551 / 24500) loss: 2.251271
(Iteration 2601 / 24500) loss: 2.166062
(Iteration 2651 / 24500) loss: 2.315866
(Iteration 2701 / 24500) loss: 2.132506
(Iteration 2751 / 24500) loss: 2.000320
(Iteration 2801 / 24500) loss: 2.235900
(Iteration 2851 / 24500) loss: 2.117551
(Iteration 2901 / 24500) loss: 2.032191
(Epoch 6 / 50) train acc: 0.408000; val_acc: 0.431000
(Iteration 2951 / 24500) loss: 2.005164
(Iteration 3001 / 24500) loss: 2.056718
(Iteration 3051 / 24500) loss: 2.176844
(Iteration 3101 / 24500) loss: 1.927646
(Iteration 3151 / 24500) loss: 2.064572
(Iteration 3201 / 24500) loss: 2.233743
(Iteration 3251 / 24500) loss: 2.111240
(Iteration 3301 / 24500) loss: 2.205294
(Iteration 3351 / 24500) loss: 1.961187
(Iteration 3401 / 24500) loss: 2.047934
(Epoch 7 / 50) train acc: 0.405000; val_acc: 0.414000
(Iteration 3451 / 24500) loss: 1.948154
(Iteration 3501 / 24500) loss: 2.018408
(Iteration 3551 / 24500) loss: 2.237627
(Iteration 3601 / 24500) loss: 2.154683
(Iteration 3651 / 24500) loss: 2.115275
(Iteration 3701 / 24500) loss: 2.022950
(Iteration 3751 / 24500) loss: 2.044873
(Iteration 3801 / 24500) loss: 2.023390
(Iteration 3851 / 24500) loss: 1.995747
(Iteration 3901 / 24500) loss: 2.118171
(Epoch 8 / 50) train acc: 0.443000; val_acc: 0.441000
(Iteration 3951 / 24500) loss: 1.901531
(Iteration 4001 / 24500) loss: 2.075955
(Iteration 4051 / 24500) loss: 2.127205
(Iteration 4101 / 24500) loss: 2.168507
(Iteration 4151 / 24500) loss: 2.023074
(Iteration 4201 / 24500) loss: 2.015149
(Iteration 4251 / 24500) loss: 2.001038
(Iteration 4301 / 24500) loss: 1.903151
(Iteration 4351 / 24500) loss: 1.976579
(Iteration 4401 / 24500) loss: 2.004165
(Epoch 9 / 50) train acc: 0.414000; val_acc: 0.444000
(Iteration 4451 / 24500) loss: 2.185496
(Iteration 4501 / 24500) loss: 1.886354
(Iteration 4551 / 24500) loss: 1.965631
(Iteration 4601 / 24500) loss: 2.139363
(Iteration 4651 / 24500) loss: 1.949539
(Iteration 4701 / 24500) loss: 1.980352
(Iteration 4751 / 24500) loss: 1.950918
(Iteration 4801 / 24500) loss: 2.158069
(Iteration 4851 / 24500) loss: 1.982108
(Epoch 10 / 50) train acc: 0.450000; val_acc: 0.454000
(Iteration 4901 / 24500) loss: 1.952042
(Iteration 4951 / 24500) loss: 2.180947
(Iteration 5001 / 24500) loss: 1.896496
(Iteration 5051 / 24500) loss: 1.954600
(Iteration 5101 / 24500) loss: 1.877891
(Iteration 5151 / 24500) loss: 2.006534
(Iteration 5201 / 24500) loss: 2.092291
(Iteration 5251 / 24500) loss: 1.960914
(Iteration 5301 / 24500) loss: 2.127457
(Iteration 5351 / 24500) loss: 1.859506
(Epoch 11 / 50) train acc: 0.474000; val_acc: 0.478000
(Iteration 5401 / 24500) loss: 1.912023
(Iteration 5451 / 24500) loss: 2.051781
(Iteration 5501 / 24500) loss: 2.051043
(Iteration 5551 / 24500) loss: 1.846194
(Iteration 5601 / 24500) loss: 1.920511
(Iteration 5651 / 24500) loss: 2.005759
(Iteration 5701 / 24500) loss: 1.953337
(Iteration 5751 / 24500) loss: 1.975846
(Iteration 5801 / 24500) loss: 1.802813
(Iteration 5851 / 24500) loss: 1.982488
(Epoch 12 / 50) train acc: 0.449000; val_acc: 0.469000
(Iteration 5901 / 24500) loss: 1.916444
(Iteration 5951 / 24500) loss: 1.933677
(Iteration 6001 / 24500) loss: 1.845700
(Iteration 6051 / 24500) loss: 1.797872
(Iteration 6101 / 24500) loss: 1.921240
(Iteration 6151 / 24500) loss: 1.967711
(Iteration 6201 / 24500) loss: 1.865489
(Iteration 6251 / 24500) loss: 1.901004
(Iteration 6301 / 24500) loss: 1.752470
(Iteration 6351 / 24500) loss: 1.868127
(Epoch 13 / 50) train acc: 0.481000; val_acc: 0.466000
(Iteration 6401 / 24500) loss: 1.824366
(Iteration 6451 / 24500) loss: 1.708911
(Iteration 6501 / 24500) loss: 1.834939
(Iteration 6551 / 24500) loss: 1.866000
(Iteration 6601 / 24500) loss: 1.786565
(Iteration 6651 / 24500) loss: 1.903741
(Iteration 6701 / 24500) loss: 1.915412
(Iteration 6751 / 24500) loss: 1.876158
(Iteration 6801 / 24500) loss: 1.856335
(Iteration 6851 / 24500) loss: 1.915139
(Epoch 14 / 50) train acc: 0.478000; val_acc: 0.476000
(Iteration 6901 / 24500) loss: 1.737212
(Iteration 6951 / 24500) loss: 1.667369
(Iteration 7001 / 24500) loss: 1.696513
(Iteration 7051 / 24500) loss: 1.900352
(Iteration 7101 / 24500) loss: 1.771016
(Iteration 7151 / 24500) loss: 1.905990
(Iteration 7201 / 24500) loss: 1.949518
(Iteration 7251 / 24500) loss: 1.871893
(Iteration 7301 / 24500) loss: 1.969307
(Epoch 15 / 50) train acc: 0.494000; val_acc: 0.486000
(Iteration 7351 / 24500) loss: 1.754198
(Iteration 7401 / 24500) loss: 1.940828
(Iteration 7451 / 24500) loss: 1.907396
(Iteration 7501 / 24500) loss: 1.783697
(Iteration 7551 / 24500) loss: 1.705118
(Iteration 7601 / 24500) loss: 1.878670
(Iteration 7651 / 24500) loss: 1.911698
(Iteration 7701 / 24500) loss: 1.750385
(Iteration 7751 / 24500) loss: 1.803198
(Iteration 7801 / 24500) loss: 1.848950
(Epoch 16 / 50) train acc: 0.506000; val_acc: 0.504000
(Iteration 7851 / 24500) loss: 1.566481
(Iteration 7901 / 24500) loss: 1.819065
(Iteration 7951 / 24500) loss: 1.714454
(Iteration 8001 / 24500) loss: 1.839505
(Iteration 8051 / 24500) loss: 1.719944
(Iteration 8101 / 24500) loss: 1.725248
(Iteration 8151 / 24500) loss: 1.733683
(Iteration 8201 / 24500) loss: 1.687533
(Iteration 8251 / 24500) loss: 1.715892
(Iteration 8301 / 24500) loss: 1.656328
(Epoch 17 / 50) train acc: 0.549000; val_acc: 0.509000
(Iteration 8351 / 24500) loss: 1.736889
(Iteration 8401 / 24500) loss: 1.877027
(Iteration 8451 / 24500) loss: 1.821257
(Iteration 8501 / 24500) loss: 1.743951
(Iteration 8551 / 24500) loss: 1.747993
(Iteration 8601 / 24500) loss: 1.626291
(Iteration 8651 / 24500) loss: 1.680232
(Iteration 8701 / 24500) loss: 1.608044
(Iteration 8751 / 24500) loss: 1.640219
(Iteration 8801 / 24500) loss: 1.825457
(Epoch 18 / 50) train acc: 0.543000; val_acc: 0.529000
(Iteration 8851 / 24500) loss: 1.743896
(Iteration 8901 / 24500) loss: 1.698803
(Iteration 8951 / 24500) loss: 1.672611
(Iteration 9001 / 24500) loss: 1.712581
(Iteration 9051 / 24500) loss: 1.605271
(Iteration 9101 / 24500) loss: 1.641917
(Iteration 9151 / 24500) loss: 1.590716
(Iteration 9201 / 24500) loss: 1.660824
(Iteration 9251 / 24500) loss: 1.566453
(Iteration 9301 / 24500) loss: 1.567844
(Epoch 19 / 50) train acc: 0.540000; val_acc: 0.525000
(Iteration 9351 / 24500) loss: 1.690261
(Iteration 9401 / 24500) loss: 1.632042
(Iteration 9451 / 24500) loss: 1.741629
(Iteration 9501 / 24500) loss: 1.578641
(Iteration 9551 / 24500) loss: 1.615191
(Iteration 9601 / 24500) loss: 1.496563
(Iteration 9651 / 24500) loss: 1.737654
(Iteration 9701 / 24500) loss: 1.785660
(Iteration 9751 / 24500) loss: 1.595712
(Epoch 20 / 50) train acc: 0.567000; val_acc: 0.532000
(Iteration 9801 / 24500) loss: 1.558226
(Iteration 9851 / 24500) loss: 1.611059
(Iteration 9901 / 24500) loss: 1.516576
(Iteration 9951 / 24500) loss: 1.676150
(Iteration 10001 / 24500) loss: 1.756187
(Iteration 10051 / 24500) loss: 1.762238
(Iteration 10101 / 24500) loss: 1.494736
(Iteration 10151 / 24500) loss: 1.371771
(Iteration 10201 / 24500) loss: 1.629604
(Iteration 10251 / 24500) loss: 1.822259
(Epoch 21 / 50) train acc: 0.548000; val_acc: 0.534000
(Iteration 10301 / 24500) loss: 1.665601
(Iteration 10351 / 24500) loss: 1.582017
(Iteration 10401 / 24500) loss: 1.688677
(Iteration 10451 / 24500) loss: 1.707078
(Iteration 10501 / 24500) loss: 1.601576
(Iteration 10551 / 24500) loss: 1.521347
(Iteration 10601 / 24500) loss: 1.514544
(Iteration 10651 / 24500) loss: 1.459400
(Iteration 10701 / 24500) loss: 1.649837
(Iteration 10751 / 24500) loss: 1.516342
(Epoch 22 / 50) train acc: 0.608000; val_acc: 0.555000
(Iteration 10801 / 24500) loss: 1.642452
(Iteration 10851 / 24500) loss: 1.590786
(Iteration 10901 / 24500) loss: 1.657056
(Iteration 10951 / 24500) loss: 1.444793
(Iteration 11001 / 24500) loss: 1.420202
(Iteration 11051 / 24500) loss: 1.664224
(Iteration 11101 / 24500) loss: 1.431727
(Iteration 11151 / 24500) loss: 1.547195
(Iteration 11201 / 24500) loss: 1.632170
(Iteration 11251 / 24500) loss: 1.421889
(Epoch 23 / 50) train acc: 0.575000; val_acc: 0.535000
(Iteration 11301 / 24500) loss: 1.634316
(Iteration 11351 / 24500) loss: 1.488192
(Iteration 11401 / 24500) loss: 1.460522
(Iteration 11451 / 24500) loss: 1.481416
(Iteration 11501 / 24500) loss: 1.383638
(Iteration 11551 / 24500) loss: 1.545959
(Iteration 11601 / 24500) loss: 1.537670
(Iteration 11651 / 24500) loss: 1.571275
(Iteration 11701 / 24500) loss: 1.480024
(Iteration 11751 / 24500) loss: 1.492606
(Epoch 24 / 50) train acc: 0.606000; val_acc: 0.544000
(Iteration 11801 / 24500) loss: 1.475953
(Iteration 11851 / 24500) loss: 1.535989
(Iteration 11901 / 24500) loss: 1.372653
(Iteration 11951 / 24500) loss: 1.360691
(Iteration 12001 / 24500) loss: 1.672365
(Iteration 12051 / 24500) loss: 1.444866
(Iteration 12101 / 24500) loss: 1.709802
(Iteration 12151 / 24500) loss: 1.375436
(Iteration 12201 / 24500) loss: 1.340372
(Epoch 25 / 50) train acc: 0.618000; val_acc: 0.550000
(Iteration 12251 / 24500) loss: 1.350701
(Iteration 12301 / 24500) loss: 1.575650
(Iteration 12351 / 24500) loss: 1.455452
(Iteration 12401 / 24500) loss: 1.411451
(Iteration 12451 / 24500) loss: 1.473040
(Iteration 12501 / 24500) loss: 1.411170
(Iteration 12551 / 24500) loss: 1.361149
(Iteration 12601 / 24500) loss: 1.393566
(Iteration 12651 / 24500) loss: 1.443673
(Iteration 12701 / 24500) loss: 1.716223
(Epoch 26 / 50) train acc: 0.618000; val_acc: 0.558000
(Iteration 12751 / 24500) loss: 1.606592
(Iteration 12801 / 24500) loss: 1.257672
(Iteration 12851 / 24500) loss: 1.539649
(Iteration 12901 / 24500) loss: 1.256927
(Iteration 12951 / 24500) loss: 1.360899
(Iteration 13001 / 24500) loss: 1.465080
(Iteration 13051 / 24500) loss: 1.522725
(Iteration 13101 / 24500) loss: 1.246586
(Iteration 13151 / 24500) loss: 1.295998
(Iteration 13201 / 24500) loss: 1.336215
(Epoch 27 / 50) train acc: 0.619000; val_acc: 0.570000
(Iteration 13251 / 24500) loss: 1.360457
(Iteration 13301 / 24500) loss: 1.524833
(Iteration 13351 / 24500) loss: 1.332070
(Iteration 13401 / 24500) loss: 1.453113
(Iteration 13451 / 24500) loss: 1.375298
(Iteration 13501 / 24500) loss: 1.354000
(Iteration 13551 / 24500) loss: 1.359019
(Iteration 13601 / 24500) loss: 1.261883
(Iteration 13651 / 24500) loss: 1.302540
(Iteration 13701 / 24500) loss: 1.380647
(Epoch 28 / 50) train acc: 0.650000; val_acc: 0.575000
(Iteration 13751 / 24500) loss: 1.363284
(Iteration 13801 / 24500) loss: 1.424658
(Iteration 13851 / 24500) loss: 1.389256
(Iteration 13901 / 24500) loss: 1.492973
(Iteration 13951 / 24500) loss: 1.449989
(Iteration 14001 / 24500) loss: 1.325588
(Iteration 14051 / 24500) loss: 1.316014
(Iteration 14101 / 24500) loss: 1.442979
(Iteration 14151 / 24500) loss: 1.156765
(Iteration 14201 / 24500) loss: 1.326411
(Epoch 29 / 50) train acc: 0.643000; val_acc: 0.568000
(Iteration 14251 / 24500) loss: 1.476848
(Iteration 14301 / 24500) loss: 1.354989
(Iteration 14351 / 24500) loss: 1.365676
(Iteration 14401 / 24500) loss: 1.444257
(Iteration 14451 / 24500) loss: 1.494376
(Iteration 14501 / 24500) loss: 1.464214
(Iteration 14551 / 24500) loss: 1.308990
(Iteration 14601 / 24500) loss: 1.482562
(Iteration 14651 / 24500) loss: 1.394076
(Epoch 30 / 50) train acc: 0.651000; val_acc: 0.579000
(Iteration 14701 / 24500) loss: 1.330119
(Iteration 14751 / 24500) loss: 1.079619
(Iteration 14801 / 24500) loss: 1.226109
(Iteration 14851 / 24500) loss: 1.290350
(Iteration 14901 / 24500) loss: 1.454158
(Iteration 14951 / 24500) loss: 1.206138
(Iteration 15001 / 24500) loss: 1.230015
(Iteration 15051 / 24500) loss: 1.478915
(Iteration 15101 / 24500) loss: 1.538096
(Iteration 15151 / 24500) loss: 1.457251
(Epoch 31 / 50) train acc: 0.681000; val_acc: 0.590000
(Iteration 15201 / 24500) loss: 1.336078
(Iteration 15251 / 24500) loss: 1.324594
(Iteration 15301 / 24500) loss: 1.081675
(Iteration 15351 / 24500) loss: 1.347949
(Iteration 15401 / 24500) loss: 1.236696
(Iteration 15451 / 24500) loss: 1.251602
(Iteration 15501 / 24500) loss: 1.355105
(Iteration 15551 / 24500) loss: 1.216936
(Iteration 15601 / 24500) loss: 1.196118
(Iteration 15651 / 24500) loss: 1.407024
(Epoch 32 / 50) train acc: 0.666000; val_acc: 0.585000
(Iteration 15701 / 24500) loss: 1.298111
(Iteration 15751 / 24500) loss: 1.129748
(Iteration 15801 / 24500) loss: 1.198461
(Iteration 15851 / 24500) loss: 1.350908
(Iteration 15901 / 24500) loss: 1.269700
(Iteration 15951 / 24500) loss: 1.402927
(Iteration 16001 / 24500) loss: 1.185835
(Iteration 16051 / 24500) loss: 1.156691
(Iteration 16101 / 24500) loss: 1.419990
(Iteration 16151 / 24500) loss: 1.379032
(Epoch 33 / 50) train acc: 0.693000; val_acc: 0.596000
(Iteration 16201 / 24500) loss: 1.251922
(Iteration 16251 / 24500) loss: 1.320518
(Iteration 16301 / 24500) loss: 1.082011
(Iteration 16351 / 24500) loss: 1.418786
(Iteration 16401 / 24500) loss: 1.293097
(Iteration 16451 / 24500) loss: 1.395955
(Iteration 16501 / 24500) loss: 1.374683
(Iteration 16551 / 24500) loss: 1.180517
(Iteration 16601 / 24500) loss: 1.421061
(Iteration 16651 / 24500) loss: 1.284411
(Epoch 34 / 50) train acc: 0.698000; val_acc: 0.584000
(Iteration 16701 / 24500) loss: 1.257402
(Iteration 16751 / 24500) loss: 1.326773
(Iteration 16801 / 24500) loss: 1.119397
(Iteration 16851 / 24500) loss: 1.317542
(Iteration 16901 / 24500) loss: 1.256027
(Iteration 16951 / 24500) loss: 1.208741
(Iteration 17001 / 24500) loss: 1.232255
(Iteration 17051 / 24500) loss: 1.265063
(Iteration 17101 / 24500) loss: 1.308227
(Epoch 35 / 50) train acc: 0.720000; val_acc: 0.590000
(Iteration 17151 / 24500) loss: 1.245182
(Iteration 17201 / 24500) loss: 1.234257
(Iteration 17251 / 24500) loss: 1.383342
(Iteration 17301 / 24500) loss: 1.240496
(Iteration 17351 / 24500) loss: 1.184752
(Iteration 17401 / 24500) loss: 1.330649
(Iteration 17451 / 24500) loss: 1.096786
(Iteration 17501 / 24500) loss: 1.156686
(Iteration 17551 / 24500) loss: 1.257925
(Iteration 17601 / 24500) loss: 1.268607
(Epoch 36 / 50) train acc: 0.700000; val_acc: 0.572000
(Iteration 17651 / 24500) loss: 1.252268
(Iteration 17701 / 24500) loss: 1.304912
(Iteration 17751 / 24500) loss: 1.037714
(Iteration 17801 / 24500) loss: 1.383084
(Iteration 17851 / 24500) loss: 1.199527
(Iteration 17901 / 24500) loss: 1.230473
(Iteration 17951 / 24500) loss: 1.232694
(Iteration 18001 / 24500) loss: 1.127512
(Iteration 18051 / 24500) loss: 1.251164
(Iteration 18101 / 24500) loss: 1.043112
(Epoch 37 / 50) train acc: 0.717000; val_acc: 0.591000
(Iteration 18151 / 24500) loss: 1.286001
(Iteration 18201 / 24500) loss: 1.058494
(Iteration 18251 / 24500) loss: 1.291902
(Iteration 18301 / 24500) loss: 0.919883
(Iteration 18351 / 24500) loss: 1.100044
(Iteration 18401 / 24500) loss: 1.233392
(Iteration 18451 / 24500) loss: 1.144453
(Iteration 18501 / 24500) loss: 1.216721
(Iteration 18551 / 24500) loss: 1.071530
(Iteration 18601 / 24500) loss: 1.190532
(Epoch 38 / 50) train acc: 0.741000; val_acc: 0.590000
(Iteration 18651 / 24500) loss: 1.267715
(Iteration 18701 / 24500) loss: 1.129571
(Iteration 18751 / 24500) loss: 1.075180
(Iteration 18801 / 24500) loss: 1.013258
(Iteration 18851 / 24500) loss: 1.160598
(Iteration 18901 / 24500) loss: 1.051074
(Iteration 18951 / 24500) loss: 1.333185
(Iteration 19001 / 24500) loss: 1.215936
(Iteration 19051 / 24500) loss: 1.036422
(Iteration 19101 / 24500) loss: 1.061363
(Epoch 39 / 50) train acc: 0.762000; val_acc: 0.592000
(Iteration 19151 / 24500) loss: 0.992314
(Iteration 19201 / 24500) loss: 1.154806
(Iteration 19251 / 24500) loss: 1.120316
(Iteration 19301 / 24500) loss: 1.313212
(Iteration 19351 / 24500) loss: 1.080257
(Iteration 19401 / 24500) loss: 1.109140
(Iteration 19451 / 24500) loss: 1.082659
(Iteration 19501 / 24500) loss: 1.052760
(Iteration 19551 / 24500) loss: 0.975353
(Epoch 40 / 50) train acc: 0.756000; val_acc: 0.591000
(Iteration 19601 / 24500) loss: 0.935504
(Iteration 19651 / 24500) loss: 1.170397
(Iteration 19701 / 24500) loss: 1.310615
(Iteration 19751 / 24500) loss: 1.178163
(Iteration 19801 / 24500) loss: 1.117427
(Iteration 19851 / 24500) loss: 1.209149
(Iteration 19901 / 24500) loss: 1.168611
(Iteration 19951 / 24500) loss: 1.203938
(Iteration 20001 / 24500) loss: 0.933199
(Iteration 20051 / 24500) loss: 1.021166
(Epoch 41 / 50) train acc: 0.764000; val_acc: 0.597000
(Iteration 20101 / 24500) loss: 1.082582
(Iteration 20151 / 24500) loss: 1.089042
(Iteration 20201 / 24500) loss: 0.962149
(Iteration 20251 / 24500) loss: 1.161808
(Iteration 20301 / 24500) loss: 1.185659
(Iteration 20351 / 24500) loss: 1.071883
(Iteration 20401 / 24500) loss: 1.170793
(Iteration 20451 / 24500) loss: 1.141296
(Iteration 20501 / 24500) loss: 0.965246
(Iteration 20551 / 24500) loss: 1.167399
(Epoch 42 / 50) train acc: 0.736000; val_acc: 0.580000
(Iteration 20601 / 24500) loss: 1.138071
(Iteration 20651 / 24500) loss: 1.035543
(Iteration 20701 / 24500) loss: 1.102871
(Iteration 20751 / 24500) loss: 1.128345
(Iteration 20801 / 24500) loss: 1.156164
(Iteration 20851 / 24500) loss: 1.290518
(Iteration 20901 / 24500) loss: 1.049857
(Iteration 20951 / 24500) loss: 1.131861
(Iteration 21001 / 24500) loss: 1.114448
(Iteration 21051 / 24500) loss: 1.066890
(Epoch 43 / 50) train acc: 0.776000; val_acc: 0.595000
(Iteration 21101 / 24500) loss: 1.051686
(Iteration 21151 / 24500) loss: 0.903448
(Iteration 21201 / 24500) loss: 1.051502
(Iteration 21251 / 24500) loss: 1.081450
(Iteration 21301 / 24500) loss: 1.436026
(Iteration 21351 / 24500) loss: 1.127717
(Iteration 21401 / 24500) loss: 0.942529
(Iteration 21451 / 24500) loss: 0.993711
(Iteration 21501 / 24500) loss: 0.948646
(Iteration 21551 / 24500) loss: 1.129484
(Epoch 44 / 50) train acc: 0.770000; val_acc: 0.583000
(Iteration 21601 / 24500) loss: 1.047479
(Iteration 21651 / 24500) loss: 0.990265
(Iteration 21701 / 24500) loss: 1.122963
(Iteration 21751 / 24500) loss: 1.116339
(Iteration 21801 / 24500) loss: 1.200067
(Iteration 21851 / 24500) loss: 1.032286
(Iteration 21901 / 24500) loss: 1.041082
(Iteration 21951 / 24500) loss: 1.102337
(Iteration 22001 / 24500) loss: 1.000093
(Epoch 45 / 50) train acc: 0.765000; val_acc: 0.600000
(Iteration 22051 / 24500) loss: 1.187967
(Iteration 22101 / 24500) loss: 0.879573
(Iteration 22151 / 24500) loss: 1.292536
(Iteration 22201 / 24500) loss: 0.902103
(Iteration 22251 / 24500) loss: 0.992383
(Iteration 22301 / 24500) loss: 1.084275
(Iteration 22351 / 24500) loss: 1.025601
(Iteration 22401 / 24500) loss: 1.004683
(Iteration 22451 / 24500) loss: 0.912043
(Iteration 22501 / 24500) loss: 1.050639
(Epoch 46 / 50) train acc: 0.784000; val_acc: 0.600000
(Iteration 22551 / 24500) loss: 1.133819
(Iteration 22601 / 24500) loss: 0.969080
(Iteration 22651 / 24500) loss: 1.054646
(Iteration 22701 / 24500) loss: 1.123463
(Iteration 22751 / 24500) loss: 1.049543
(Iteration 22801 / 24500) loss: 0.916471
(Iteration 22851 / 24500) loss: 1.037972
(Iteration 22901 / 24500) loss: 1.036747
(Iteration 22951 / 24500) loss: 1.087766
(Iteration 23001 / 24500) loss: 0.903846
(Epoch 47 / 50) train acc: 0.813000; val_acc: 0.593000
(Iteration 23051 / 24500) loss: 0.974416
(Iteration 23101 / 24500) loss: 0.906331
(Iteration 23151 / 24500) loss: 0.915804
(Iteration 23201 / 24500) loss: 0.820969
(Iteration 23251 / 24500) loss: 0.989895
(Iteration 23301 / 24500) loss: 1.266501
(Iteration 23351 / 24500) loss: 0.921358
(Iteration 23401 / 24500) loss: 1.142307
(Iteration 23451 / 24500) loss: 1.038884
(Iteration 23501 / 24500) loss: 0.889222
(Epoch 48 / 50) train acc: 0.798000; val_acc: 0.591000
(Iteration 23551 / 24500) loss: 0.969121
(Iteration 23601 / 24500) loss: 0.986475
(Iteration 23651 / 24500) loss: 1.024916
(Iteration 23701 / 24500) loss: 0.902607
(Iteration 23751 / 24500) loss: 0.923493
(Iteration 23801 / 24500) loss: 1.023135
(Iteration 23851 / 24500) loss: 0.950753
(Iteration 23901 / 24500) loss: 1.111397
(Iteration 23951 / 24500) loss: 0.960240
(Iteration 24001 / 24500) loss: 1.072007
(Epoch 49 / 50) train acc: 0.804000; val_acc: 0.583000
(Iteration 24051 / 24500) loss: 0.942492
(Iteration 24101 / 24500) loss: 0.892266
(Iteration 24151 / 24500) loss: 0.862780
(Iteration 24201 / 24500) loss: 0.990167
(Iteration 24251 / 24500) loss: 0.886193
(Iteration 24301 / 24500) loss: 0.914786
(Iteration 24351 / 24500) loss: 0.901439
(Iteration 24401 / 24500) loss: 0.983511
(Iteration 24451 / 24500) loss: 1.320739
(Epoch 50 / 50) train acc: 0.798000; val_acc: 0.589000