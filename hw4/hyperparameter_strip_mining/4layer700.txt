layer_dims = [600, 600, 600, 700]
weight_scale = 0.01
learning_rate = 1e-3
lr_decay = 0.90

model = FullyConnectedNet(layer_dims, weight_scale=weight_scale,
                          dropout=0.65, reg=0.0, use_batchnorm=True)

solver = Solver(model, data,
                num_epochs=50, batch_size=100,
                update_rule='adam',
                optim_config={
                  'learning_rate': learning_rate,
                },
                lr_decay=lr_decay,
                verbose=True, print_every=50)
solver.train()

(Iteration 1 / 24500) loss: 2.311311
(Epoch 0 / 50) train acc: 0.175000; val_acc: 0.180000
(Iteration 51 / 24500) loss: 1.793573
(Iteration 101 / 24500) loss: 1.758120
(Iteration 151 / 24500) loss: 1.970392
(Iteration 201 / 24500) loss: 1.806760
(Iteration 251 / 24500) loss: 1.611012
(Iteration 301 / 24500) loss: 1.510179
(Iteration 351 / 24500) loss: 1.879898
(Iteration 401 / 24500) loss: 1.738898
(Iteration 451 / 24500) loss: 1.548916
(Epoch 1 / 50) train acc: 0.452000; val_acc: 0.464000
(Iteration 501 / 24500) loss: 1.424621
(Iteration 551 / 24500) loss: 1.546625
(Iteration 601 / 24500) loss: 1.701098
(Iteration 651 / 24500) loss: 1.525763
(Iteration 701 / 24500) loss: 1.502155
(Iteration 751 / 24500) loss: 1.525423
(Iteration 801 / 24500) loss: 1.573772
(Iteration 851 / 24500) loss: 1.452218
(Iteration 901 / 24500) loss: 1.685906
(Iteration 951 / 24500) loss: 1.454457
(Epoch 2 / 50) train acc: 0.510000; val_acc: 0.480000
(Iteration 1001 / 24500) loss: 1.418455
(Iteration 1051 / 24500) loss: 1.431879
(Iteration 1101 / 24500) loss: 1.445878
(Iteration 1151 / 24500) loss: 1.461624
(Iteration 1201 / 24500) loss: 1.479994
(Iteration 1251 / 24500) loss: 1.440538
(Iteration 1301 / 24500) loss: 1.310663
(Iteration 1351 / 24500) loss: 1.369697
(Iteration 1401 / 24500) loss: 1.589489
(Iteration 1451 / 24500) loss: 1.551129
(Epoch 3 / 50) train acc: 0.557000; val_acc: 0.523000
(Iteration 1501 / 24500) loss: 1.261743
(Iteration 1551 / 24500) loss: 1.345720
(Iteration 1601 / 24500) loss: 1.423632
(Iteration 1651 / 24500) loss: 1.581316
(Iteration 1701 / 24500) loss: 1.382542
(Iteration 1751 / 24500) loss: 1.512209
(Iteration 1801 / 24500) loss: 1.471501
(Iteration 1851 / 24500) loss: 1.400053
(Iteration 1901 / 24500) loss: 1.353924
(Iteration 1951 / 24500) loss: 1.264267
(Epoch 4 / 50) train acc: 0.558000; val_acc: 0.513000
(Iteration 2001 / 24500) loss: 1.458942
(Iteration 2051 / 24500) loss: 1.470834
(Iteration 2101 / 24500) loss: 1.248432
(Iteration 2151 / 24500) loss: 1.223015
(Iteration 2201 / 24500) loss: 1.274916
(Iteration 2251 / 24500) loss: 1.433032
(Iteration 2301 / 24500) loss: 1.345087
(Iteration 2351 / 24500) loss: 1.338729
(Iteration 2401 / 24500) loss: 1.288593
(Epoch 5 / 50) train acc: 0.580000; val_acc: 0.516000
(Iteration 2451 / 24500) loss: 1.328203
(Iteration 2501 / 24500) loss: 1.323782
(Iteration 2551 / 24500) loss: 1.265834
(Iteration 2601 / 24500) loss: 1.183630
(Iteration 2651 / 24500) loss: 1.360527
(Iteration 2701 / 24500) loss: 1.271614
(Iteration 2751 / 24500) loss: 1.262180
(Iteration 2801 / 24500) loss: 1.388339
(Iteration 2851 / 24500) loss: 1.146084
(Iteration 2901 / 24500) loss: 1.032192
(Epoch 6 / 50) train acc: 0.608000; val_acc: 0.538000
(Iteration 2951 / 24500) loss: 1.143596
(Iteration 3001 / 24500) loss: 1.162398
(Iteration 3051 / 24500) loss: 1.193240
(Iteration 3101 / 24500) loss: 1.270761
(Iteration 3151 / 24500) loss: 1.112394
(Iteration 3201 / 24500) loss: 1.330969
(Iteration 3251 / 24500) loss: 1.338341
(Iteration 3301 / 24500) loss: 1.298035
(Iteration 3351 / 24500) loss: 1.309496
(Iteration 3401 / 24500) loss: 1.311370
(Epoch 7 / 50) train acc: 0.629000; val_acc: 0.557000
(Iteration 3451 / 24500) loss: 1.247830
(Iteration 3501 / 24500) loss: 1.225514
(Iteration 3551 / 24500) loss: 1.358672
(Iteration 3601 / 24500) loss: 1.295619
(Iteration 3651 / 24500) loss: 1.227878
(Iteration 3701 / 24500) loss: 1.179266
(Iteration 3751 / 24500) loss: 1.140355
(Iteration 3801 / 24500) loss: 1.149682
(Iteration 3851 / 24500) loss: 0.934496
(Iteration 3901 / 24500) loss: 1.040207
(Epoch 8 / 50) train acc: 0.638000; val_acc: 0.573000
(Iteration 3951 / 24500) loss: 1.052292
(Iteration 4001 / 24500) loss: 1.245587
(Iteration 4051 / 24500) loss: 1.147466
(Iteration 4101 / 24500) loss: 1.024100
(Iteration 4151 / 24500) loss: 1.200691
(Iteration 4201 / 24500) loss: 1.200354
(Iteration 4251 / 24500) loss: 1.251767
(Iteration 4301 / 24500) loss: 1.029855
(Iteration 4351 / 24500) loss: 1.261204
(Iteration 4401 / 24500) loss: 1.177363
(Epoch 9 / 50) train acc: 0.648000; val_acc: 0.557000
(Iteration 4451 / 24500) loss: 1.122716
(Iteration 4501 / 24500) loss: 1.164492
(Iteration 4551 / 24500) loss: 1.006106
(Iteration 4601 / 24500) loss: 1.037765
(Iteration 4651 / 24500) loss: 1.172163
(Iteration 4701 / 24500) loss: 1.390476
(Iteration 4751 / 24500) loss: 1.243396
(Iteration 4801 / 24500) loss: 0.990606
(Iteration 4851 / 24500) loss: 1.118634
(Epoch 10 / 50) train acc: 0.670000; val_acc: 0.567000
(Iteration 4901 / 24500) loss: 1.234153
(Iteration 4951 / 24500) loss: 1.152938
(Iteration 5001 / 24500) loss: 1.098260
(Iteration 5051 / 24500) loss: 1.085064
(Iteration 5101 / 24500) loss: 1.119705
(Iteration 5151 / 24500) loss: 1.040948
(Iteration 5201 / 24500) loss: 1.140773
(Iteration 5251 / 24500) loss: 0.959485
(Iteration 5301 / 24500) loss: 1.052428
(Iteration 5351 / 24500) loss: 1.301756
(Epoch 11 / 50) train acc: 0.680000; val_acc: 0.560000
(Iteration 5401 / 24500) loss: 0.996021
(Iteration 5451 / 24500) loss: 1.263236
(Iteration 5501 / 24500) loss: 0.999305
(Iteration 5551 / 24500) loss: 1.264340
(Iteration 5601 / 24500) loss: 0.889404
(Iteration 5651 / 24500) loss: 1.181386
(Iteration 5701 / 24500) loss: 1.206799
(Iteration 5751 / 24500) loss: 0.992549
(Iteration 5801 / 24500) loss: 1.093534
(Iteration 5851 / 24500) loss: 1.060894
(Epoch 12 / 50) train acc: 0.647000; val_acc: 0.577000
(Iteration 5901 / 24500) loss: 1.055219
(Iteration 5951 / 24500) loss: 1.204061
(Iteration 6001 / 24500) loss: 1.109696
(Iteration 6051 / 24500) loss: 1.036836
(Iteration 6101 / 24500) loss: 0.867236
(Iteration 6151 / 24500) loss: 0.939375
(Iteration 6201 / 24500) loss: 0.952566
(Iteration 6251 / 24500) loss: 0.869823
(Iteration 6301 / 24500) loss: 0.970789
(Iteration 6351 / 24500) loss: 0.947970
(Epoch 13 / 50) train acc: 0.702000; val_acc: 0.570000
(Iteration 6401 / 24500) loss: 0.991032
(Iteration 6451 / 24500) loss: 1.037689
(Iteration 6501 / 24500) loss: 1.120505
(Iteration 6551 / 24500) loss: 1.080853
(Iteration 6601 / 24500) loss: 0.893445
(Iteration 6651 / 24500) loss: 1.214262
(Iteration 6701 / 24500) loss: 0.937105
(Iteration 6751 / 24500) loss: 1.046808
(Iteration 6801 / 24500) loss: 1.168702
(Iteration 6851 / 24500) loss: 0.915704
(Epoch 14 / 50) train acc: 0.722000; val_acc: 0.584000
(Iteration 6901 / 24500) loss: 0.920725
(Iteration 6951 / 24500) loss: 0.941364
(Iteration 7001 / 24500) loss: 0.992200
(Iteration 7051 / 24500) loss: 0.975060
(Iteration 7101 / 24500) loss: 1.109116
(Iteration 7151 / 24500) loss: 1.038965
(Iteration 7201 / 24500) loss: 0.947713
(Iteration 7251 / 24500) loss: 1.071110
(Iteration 7301 / 24500) loss: 0.908781
(Epoch 15 / 50) train acc: 0.695000; val_acc: 0.589000
(Iteration 7351 / 24500) loss: 0.986623
(Iteration 7401 / 24500) loss: 0.909182
(Iteration 7451 / 24500) loss: 1.016560
(Iteration 7501 / 24500) loss: 0.953125
(Iteration 7551 / 24500) loss: 1.038061
(Iteration 7601 / 24500) loss: 0.816858
(Iteration 7651 / 24500) loss: 1.118482
(Iteration 7701 / 24500) loss: 1.012581
(Iteration 7751 / 24500) loss: 0.949869
(Iteration 7801 / 24500) loss: 1.120030
(Epoch 16 / 50) train acc: 0.698000; val_acc: 0.578000
(Iteration 7851 / 24500) loss: 1.133856
(Iteration 7901 / 24500) loss: 1.213069
(Iteration 7951 / 24500) loss: 1.109218
(Iteration 8001 / 24500) loss: 0.965493
(Iteration 8051 / 24500) loss: 1.043610
(Iteration 8101 / 24500) loss: 1.101328
(Iteration 8151 / 24500) loss: 0.927868
(Iteration 8201 / 24500) loss: 0.910315
(Iteration 8251 / 24500) loss: 0.929656
(Iteration 8301 / 24500) loss: 0.939153
(Epoch 17 / 50) train acc: 0.709000; val_acc: 0.584000
(Iteration 8351 / 24500) loss: 0.921414
(Iteration 8401 / 24500) loss: 1.055917
(Iteration 8451 / 24500) loss: 0.984353
(Iteration 8501 / 24500) loss: 0.896202
(Iteration 8551 / 24500) loss: 1.028265
(Iteration 8601 / 24500) loss: 0.767338
(Iteration 8651 / 24500) loss: 1.089804
(Iteration 8701 / 24500) loss: 1.018088
(Iteration 8751 / 24500) loss: 0.915150
(Iteration 8801 / 24500) loss: 0.938174
(Epoch 18 / 50) train acc: 0.749000; val_acc: 0.588000
(Iteration 8851 / 24500) loss: 0.946205
(Iteration 8901 / 24500) loss: 0.949321
(Iteration 8951 / 24500) loss: 0.888071
(Iteration 9001 / 24500) loss: 0.816352
(Iteration 9051 / 24500) loss: 0.905918
(Iteration 9101 / 24500) loss: 1.118715
(Iteration 9151 / 24500) loss: 0.909299
(Iteration 9201 / 24500) loss: 0.900556
(Iteration 9251 / 24500) loss: 0.900021
(Iteration 9301 / 24500) loss: 1.166341
(Epoch 19 / 50) train acc: 0.753000; val_acc: 0.587000
(Iteration 9351 / 24500) loss: 0.788766
(Iteration 9401 / 24500) loss: 1.134554
(Iteration 9451 / 24500) loss: 0.959825
(Iteration 9501 / 24500) loss: 0.957394
(Iteration 9551 / 24500) loss: 1.010518
(Iteration 9601 / 24500) loss: 0.958620
(Iteration 9651 / 24500) loss: 0.822130
(Iteration 9701 / 24500) loss: 1.231192
(Iteration 9751 / 24500) loss: 0.833161
(Epoch 20 / 50) train acc: 0.762000; val_acc: 0.576000
(Iteration 9801 / 24500) loss: 0.901699
(Iteration 9851 / 24500) loss: 0.853117
(Iteration 9901 / 24500) loss: 0.900482
(Iteration 9951 / 24500) loss: 1.041922
(Iteration 10001 / 24500) loss: 0.938913
(Iteration 10051 / 24500) loss: 0.766324
(Iteration 10101 / 24500) loss: 1.011505
(Iteration 10151 / 24500) loss: 0.866203
(Iteration 10201 / 24500) loss: 0.866552
(Iteration 10251 / 24500) loss: 0.926450
(Epoch 21 / 50) train acc: 0.755000; val_acc: 0.591000
(Iteration 10301 / 24500) loss: 0.834494
(Iteration 10351 / 24500) loss: 1.026799
(Iteration 10401 / 24500) loss: 0.940101
(Iteration 10451 / 24500) loss: 0.872485
(Iteration 10501 / 24500) loss: 0.792596
(Iteration 10551 / 24500) loss: 0.923653
(Iteration 10601 / 24500) loss: 0.907884
(Iteration 10651 / 24500) loss: 1.026921
(Iteration 10701 / 24500) loss: 0.868971
(Iteration 10751 / 24500) loss: 0.797167
(Epoch 22 / 50) train acc: 0.766000; val_acc: 0.583000
(Iteration 10801 / 24500) loss: 0.934489
(Iteration 10851 / 24500) loss: 0.892055
(Iteration 10901 / 24500) loss: 0.839174
(Iteration 10951 / 24500) loss: 0.963873
(Iteration 11001 / 24500) loss: 0.941757
(Iteration 11051 / 24500) loss: 0.822015
(Iteration 11101 / 24500) loss: 1.101300
(Iteration 11151 / 24500) loss: 0.837964
(Iteration 11201 / 24500) loss: 0.839557
(Iteration 11251 / 24500) loss: 0.825739
(Epoch 23 / 50) train acc: 0.763000; val_acc: 0.585000
(Iteration 11301 / 24500) loss: 0.818129
(Iteration 11351 / 24500) loss: 0.876174
(Iteration 11401 / 24500) loss: 0.887075
(Iteration 11451 / 24500) loss: 0.936106
(Iteration 11501 / 24500) loss: 0.984798
(Iteration 11551 / 24500) loss: 0.861762
(Iteration 11601 / 24500) loss: 0.854316
(Iteration 11651 / 24500) loss: 0.924689
(Iteration 11701 / 24500) loss: 0.840425
(Iteration 11751 / 24500) loss: 0.863875
(Epoch 24 / 50) train acc: 0.752000; val_acc: 0.574000
(Iteration 11801 / 24500) loss: 0.802592
(Iteration 11851 / 24500) loss: 0.951806
(Iteration 11901 / 24500) loss: 0.984697
(Iteration 11951 / 24500) loss: 0.867287
(Iteration 12001 / 24500) loss: 0.792503
(Iteration 12051 / 24500) loss: 0.907026
(Iteration 12101 / 24500) loss: 0.820619
(Iteration 12151 / 24500) loss: 0.887646
(Iteration 12201 / 24500) loss: 0.810578
(Epoch 25 / 50) train acc: 0.757000; val_acc: 0.573000
(Iteration 12251 / 24500) loss: 0.843515
(Iteration 12301 / 24500) loss: 0.832905
(Iteration 12351 / 24500) loss: 0.867073
(Iteration 12401 / 24500) loss: 0.858185
(Iteration 12451 / 24500) loss: 0.744701
(Iteration 12501 / 24500) loss: 0.980248
(Iteration 12551 / 24500) loss: 0.889629
(Iteration 12601 / 24500) loss: 0.955456
(Iteration 12651 / 24500) loss: 0.947248
(Iteration 12701 / 24500) loss: 0.871673
(Epoch 26 / 50) train acc: 0.768000; val_acc: 0.582000
(Iteration 12751 / 24500) loss: 0.822020
(Iteration 12801 / 24500) loss: 1.018566
(Iteration 12851 / 24500) loss: 0.743048
(Iteration 12901 / 24500) loss: 0.833590
(Iteration 12951 / 24500) loss: 0.760605
(Iteration 13001 / 24500) loss: 0.850939
(Iteration 13051 / 24500) loss: 0.723352
(Iteration 13101 / 24500) loss: 0.855767
(Iteration 13151 / 24500) loss: 0.654083
(Iteration 13201 / 24500) loss: 0.888647
(Epoch 27 / 50) train acc: 0.798000; val_acc: 0.587000
(Iteration 13251 / 24500) loss: 0.682053
(Iteration 13301 / 24500) loss: 1.068711
(Iteration 13351 / 24500) loss: 0.977325
(Iteration 13401 / 24500) loss: 0.899203
(Iteration 13451 / 24500) loss: 0.826886
(Iteration 13501 / 24500) loss: 0.956306
(Iteration 13551 / 24500) loss: 0.742450
(Iteration 13601 / 24500) loss: 0.698559
(Iteration 13651 / 24500) loss: 0.961073
(Iteration 13701 / 24500) loss: 0.936715
(Epoch 28 / 50) train acc: 0.780000; val_acc: 0.585000
(Iteration 13751 / 24500) loss: 0.849188
(Iteration 13801 / 24500) loss: 0.681703
(Iteration 13851 / 24500) loss: 0.782430
(Iteration 13901 / 24500) loss: 0.906387
(Iteration 13951 / 24500) loss: 0.752157
(Iteration 14001 / 24500) loss: 0.705177
(Iteration 14051 / 24500) loss: 0.850922
(Iteration 14101 / 24500) loss: 0.948596
(Iteration 14151 / 24500) loss: 0.814181
(Iteration 14201 / 24500) loss: 0.808791
(Epoch 29 / 50) train acc: 0.771000; val_acc: 0.585000
(Iteration 14251 / 24500) loss: 0.851780
(Iteration 14301 / 24500) loss: 0.903518
(Iteration 14351 / 24500) loss: 0.813400
(Iteration 14401 / 24500) loss: 0.990457
(Iteration 14451 / 24500) loss: 0.742595
(Iteration 14501 / 24500) loss: 0.832370
(Iteration 14551 / 24500) loss: 0.969356
(Iteration 14601 / 24500) loss: 0.714750
(Iteration 14651 / 24500) loss: 0.917257
(Epoch 30 / 50) train acc: 0.785000; val_acc: 0.596000
(Iteration 14701 / 24500) loss: 0.883572
(Iteration 14751 / 24500) loss: 0.696747
(Iteration 14801 / 24500) loss: 0.956688
(Iteration 14851 / 24500) loss: 0.778681
(Iteration 14901 / 24500) loss: 0.856096
(Iteration 14951 / 24500) loss: 0.768299
(Iteration 15001 / 24500) loss: 0.967070
(Iteration 15051 / 24500) loss: 0.838239
(Iteration 15101 / 24500) loss: 0.734339
(Iteration 15151 / 24500) loss: 0.803626
(Epoch 31 / 50) train acc: 0.795000; val_acc: 0.585000
(Iteration 15201 / 24500) loss: 0.742750
(Iteration 15251 / 24500) loss: 1.154251
(Iteration 15301 / 24500) loss: 0.825005
(Iteration 15351 / 24500) loss: 0.858796
(Iteration 15401 / 24500) loss: 0.662303
(Iteration 15451 / 24500) loss: 0.738328
(Iteration 15501 / 24500) loss: 0.837085
(Iteration 15551 / 24500) loss: 0.815085
(Iteration 15601 / 24500) loss: 0.821136
(Iteration 15651 / 24500) loss: 0.627531
(Epoch 32 / 50) train acc: 0.787000; val_acc: 0.578000
(Iteration 15701 / 24500) loss: 0.895159
(Iteration 15751 / 24500) loss: 0.657688
(Iteration 15801 / 24500) loss: 0.865649
(Iteration 15851 / 24500) loss: 0.841392
(Iteration 15901 / 24500) loss: 0.809176
(Iteration 15951 / 24500) loss: 0.855540
(Iteration 16001 / 24500) loss: 0.805088
(Iteration 16051 / 24500) loss: 0.675801
(Iteration 16101 / 24500) loss: 0.837092
(Iteration 16151 / 24500) loss: 0.792624
(Epoch 33 / 50) train acc: 0.779000; val_acc: 0.588000
(Iteration 16201 / 24500) loss: 0.783383
(Iteration 16251 / 24500) loss: 1.062418
(Iteration 16301 / 24500) loss: 0.823911
(Iteration 16351 / 24500) loss: 0.716188
(Iteration 16401 / 24500) loss: 0.768652
(Iteration 16451 / 24500) loss: 0.944571
(Iteration 16501 / 24500) loss: 0.741032
(Iteration 16551 / 24500) loss: 0.791172
(Iteration 16601 / 24500) loss: 0.740334
(Iteration 16651 / 24500) loss: 0.745519
(Epoch 34 / 50) train acc: 0.800000; val_acc: 0.584000
(Iteration 16701 / 24500) loss: 0.702556
(Iteration 16751 / 24500) loss: 0.811667
(Iteration 16801 / 24500) loss: 0.746052
(Iteration 16851 / 24500) loss: 1.127194
(Iteration 16901 / 24500) loss: 0.947774
(Iteration 16951 / 24500) loss: 0.779956
(Iteration 17001 / 24500) loss: 0.738973
(Iteration 17051 / 24500) loss: 0.864257
(Iteration 17101 / 24500) loss: 0.866448
(Epoch 35 / 50) train acc: 0.793000; val_acc: 0.577000
(Iteration 17151 / 24500) loss: 0.725830
(Iteration 17201 / 24500) loss: 0.747066
(Iteration 17251 / 24500) loss: 1.006026
(Iteration 17301 / 24500) loss: 0.768839
(Iteration 17351 / 24500) loss: 0.763063
(Iteration 17401 / 24500) loss: 0.635610
(Iteration 17451 / 24500) loss: 0.982095
(Iteration 17501 / 24500) loss: 0.737666
(Iteration 17551 / 24500) loss: 0.652710
(Iteration 17601 / 24500) loss: 0.751656
(Epoch 36 / 50) train acc: 0.801000; val_acc: 0.586000
(Iteration 17651 / 24500) loss: 0.842100
(Iteration 17701 / 24500) loss: 0.912086
(Iteration 17751 / 24500) loss: 0.818861
(Iteration 17801 / 24500) loss: 0.771147
(Iteration 17851 / 24500) loss: 0.800406
(Iteration 17901 / 24500) loss: 0.674236
(Iteration 17951 / 24500) loss: 0.714536
(Iteration 18001 / 24500) loss: 0.850464
(Iteration 18051 / 24500) loss: 0.766527
(Iteration 18101 / 24500) loss: 0.792667
(Epoch 37 / 50) train acc: 0.801000; val_acc: 0.585000
(Iteration 18151 / 24500) loss: 0.663049
(Iteration 18201 / 24500) loss: 0.667420
(Iteration 18251 / 24500) loss: 0.908634
(Iteration 18301 / 24500) loss: 0.861798
(Iteration 18351 / 24500) loss: 0.679572
(Iteration 18401 / 24500) loss: 0.815032
(Iteration 18451 / 24500) loss: 0.889668
(Iteration 18501 / 24500) loss: 0.586783
(Iteration 18551 / 24500) loss: 0.901509
(Iteration 18601 / 24500) loss: 0.738848
(Epoch 38 / 50) train acc: 0.809000; val_acc: 0.585000
(Iteration 18651 / 24500) loss: 0.630579
(Iteration 18701 / 24500) loss: 0.770562
(Iteration 18751 / 24500) loss: 0.818647
(Iteration 18801 / 24500) loss: 0.812482
(Iteration 18851 / 24500) loss: 0.763958
(Iteration 18901 / 24500) loss: 0.838991
(Iteration 18951 / 24500) loss: 0.711827
(Iteration 19001 / 24500) loss: 0.908042
(Iteration 19051 / 24500) loss: 0.803963
(Iteration 19101 / 24500) loss: 0.671180
(Epoch 39 / 50) train acc: 0.784000; val_acc: 0.587000
(Iteration 19151 / 24500) loss: 0.668097
(Iteration 19201 / 24500) loss: 0.875898
(Iteration 19251 / 24500) loss: 0.800300
(Iteration 19301 / 24500) loss: 0.733528
(Iteration 19351 / 24500) loss: 0.852289
(Iteration 19401 / 24500) loss: 0.819507
(Iteration 19451 / 24500) loss: 0.885681
(Iteration 19501 / 24500) loss: 0.924780
(Iteration 19551 / 24500) loss: 0.593843
(Epoch 40 / 50) train acc: 0.801000; val_acc: 0.584000
(Iteration 19601 / 24500) loss: 0.894526
(Iteration 19651 / 24500) loss: 0.754320
(Iteration 19701 / 24500) loss: 0.775962
(Iteration 19751 / 24500) loss: 0.935037
(Iteration 19801 / 24500) loss: 0.782073
(Iteration 19851 / 24500) loss: 0.845620
(Iteration 19901 / 24500) loss: 0.728120
(Iteration 19951 / 24500) loss: 0.870227
(Iteration 20001 / 24500) loss: 0.903155
(Iteration 20051 / 24500) loss: 0.796338
(Epoch 41 / 50) train acc: 0.806000; val_acc: 0.582000
(Iteration 20101 / 24500) loss: 0.700617
(Iteration 20151 / 24500) loss: 0.777009
(Iteration 20201 / 24500) loss: 0.611047
(Iteration 20251 / 24500) loss: 0.700348
(Iteration 20301 / 24500) loss: 0.757030
(Iteration 20351 / 24500) loss: 0.706135
(Iteration 20401 / 24500) loss: 0.838429
(Iteration 20451 / 24500) loss: 0.996557
(Iteration 20501 / 24500) loss: 0.710714
(Iteration 20551 / 24500) loss: 0.858190
(Epoch 42 / 50) train acc: 0.788000; val_acc: 0.584000
(Iteration 20601 / 24500) loss: 0.946192
(Iteration 20651 / 24500) loss: 0.902741
(Iteration 20701 / 24500) loss: 0.732492
(Iteration 20751 / 24500) loss: 0.920979
(Iteration 20801 / 24500) loss: 0.811403
(Iteration 20851 / 24500) loss: 0.835801
(Iteration 20901 / 24500) loss: 0.786513
(Iteration 20951 / 24500) loss: 1.077172
(Iteration 21001 / 24500) loss: 0.642988
(Iteration 21051 / 24500) loss: 0.762575
(Epoch 43 / 50) train acc: 0.800000; val_acc: 0.584000
(Iteration 21101 / 24500) loss: 0.711010
(Iteration 21151 / 24500) loss: 0.758704
(Iteration 21201 / 24500) loss: 0.781221
(Iteration 21251 / 24500) loss: 0.790609
(Iteration 21301 / 24500) loss: 0.967374
(Iteration 21351 / 24500) loss: 1.109433
(Iteration 21401 / 24500) loss: 1.142548
(Iteration 21451 / 24500) loss: 0.778594
(Iteration 21501 / 24500) loss: 0.812683
(Iteration 21551 / 24500) loss: 0.803957
(Epoch 44 / 50) train acc: 0.806000; val_acc: 0.589000
(Iteration 21601 / 24500) loss: 0.857914
(Iteration 21651 / 24500) loss: 0.687595
(Iteration 21701 / 24500) loss: 0.822184
(Iteration 21751 / 24500) loss: 0.859489
(Iteration 21801 / 24500) loss: 0.737341
(Iteration 21851 / 24500) loss: 0.879698
(Iteration 21901 / 24500) loss: 0.687184
(Iteration 21951 / 24500) loss: 0.855603
(Iteration 22001 / 24500) loss: 0.853249
(Epoch 45 / 50) train acc: 0.800000; val_acc: 0.589000
(Iteration 22051 / 24500) loss: 0.808312
(Iteration 22101 / 24500) loss: 0.944004
(Iteration 22151 / 24500) loss: 0.801968
(Iteration 22201 / 24500) loss: 0.754331
(Iteration 22251 / 24500) loss: 0.799435
(Iteration 22301 / 24500) loss: 0.640874
(Iteration 22351 / 24500) loss: 0.862102
(Iteration 22401 / 24500) loss: 0.841523
(Iteration 22451 / 24500) loss: 0.794851
(Iteration 22501 / 24500) loss: 0.930268
(Epoch 46 / 50) train acc: 0.814000; val_acc: 0.590000
(Iteration 22551 / 24500) loss: 0.928678
(Iteration 22601 / 24500) loss: 0.762781
(Iteration 22651 / 24500) loss: 0.913573
(Iteration 22701 / 24500) loss: 0.869312
(Iteration 22751 / 24500) loss: 0.970169
(Iteration 22801 / 24500) loss: 0.590450
(Iteration 22851 / 24500) loss: 0.671031
(Iteration 22901 / 24500) loss: 0.755087
(Iteration 22951 / 24500) loss: 0.679712
(Iteration 23001 / 24500) loss: 0.775490
(Epoch 47 / 50) train acc: 0.793000; val_acc: 0.588000
(Iteration 23051 / 24500) loss: 0.965233
(Iteration 23101 / 24500) loss: 0.877653
(Iteration 23151 / 24500) loss: 0.711549
(Iteration 23201 / 24500) loss: 0.690624
(Iteration 23251 / 24500) loss: 0.723747
(Iteration 23301 / 24500) loss: 0.817531
(Iteration 23351 / 24500) loss: 0.740090
(Iteration 23401 / 24500) loss: 0.920062
(Iteration 23451 / 24500) loss: 0.640181
(Iteration 23501 / 24500) loss: 0.717798
(Epoch 48 / 50) train acc: 0.792000; val_acc: 0.585000
(Iteration 23551 / 24500) loss: 0.681547
(Iteration 23601 / 24500) loss: 0.798360
(Iteration 23651 / 24500) loss: 0.877504
(Iteration 23701 / 24500) loss: 0.981908
(Iteration 23751 / 24500) loss: 0.812679
(Iteration 23801 / 24500) loss: 0.732698
(Iteration 23851 / 24500) loss: 0.857292
(Iteration 23901 / 24500) loss: 0.818663
(Iteration 23951 / 24500) loss: 0.860205
(Iteration 24001 / 24500) loss: 0.823050
(Epoch 49 / 50) train acc: 0.811000; val_acc: 0.589000
(Iteration 24051 / 24500) loss: 0.661211
(Iteration 24101 / 24500) loss: 1.008093
(Iteration 24151 / 24500) loss: 0.776112
(Iteration 24201 / 24500) loss: 0.709076
(Iteration 24251 / 24500) loss: 0.875495
(Iteration 24301 / 24500) loss: 0.857547
(Iteration 24351 / 24500) loss: 0.844167
(Iteration 24401 / 24500) loss: 0.643124
(Iteration 24451 / 24500) loss: 0.715130
(Epoch 50 / 50) train acc: 0.800000; val_acc: 0.589000