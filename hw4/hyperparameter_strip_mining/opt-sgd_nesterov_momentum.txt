layer_dims = [600, 600, 600, 600]
weight_scale = 0.01
learning_rate = 1e-3
lr_decay = 0.90

model = FullyConnectedNet(layer_dims, weight_scale=weight_scale,
                          dropout=0.65, reg=0, use_batchnorm=True)

solver = Solver(model, data,
                num_epochs=50, batch_size=100,
                update_rule='sgd_nesterov_momentum',
                optim_config={
                  'learning_rate': learning_rate,
                },
                lr_decay=lr_decay,
                verbose=True, print_every=50)
solver.train()

(Iteration 1 / 24500) loss: 2.349430
(Epoch 0 / 50) train acc: 0.080000; val_acc: 0.085000
(Iteration 51 / 24500) loss: 2.219891
(Iteration 101 / 24500) loss: 1.981089
(Iteration 151 / 24500) loss: 1.876155
(Iteration 201 / 24500) loss: 1.896421
(Iteration 251 / 24500) loss: 1.777141
(Iteration 301 / 24500) loss: 1.784307
(Iteration 351 / 24500) loss: 1.766670
(Iteration 401 / 24500) loss: 1.838248
(Iteration 451 / 24500) loss: 1.908609
(Epoch 1 / 50) train acc: 0.432000; val_acc: 0.435000
(Iteration 501 / 24500) loss: 1.842327
(Iteration 551 / 24500) loss: 1.575628
(Iteration 601 / 24500) loss: 1.793172
(Iteration 651 / 24500) loss: 1.756401
(Iteration 701 / 24500) loss: 1.516399
(Iteration 751 / 24500) loss: 1.547323
(Iteration 801 / 24500) loss: 1.554830
(Iteration 851 / 24500) loss: 1.579353
(Iteration 901 / 24500) loss: 1.716359
(Iteration 951 / 24500) loss: 1.596485
(Epoch 2 / 50) train acc: 0.526000; val_acc: 0.476000
(Iteration 1001 / 24500) loss: 1.515317
(Iteration 1051 / 24500) loss: 1.347381
(Iteration 1101 / 24500) loss: 1.536676
(Iteration 1151 / 24500) loss: 1.533265
(Iteration 1201 / 24500) loss: 1.537848
(Iteration 1251 / 24500) loss: 1.668225
(Iteration 1301 / 24500) loss: 1.540843
(Iteration 1351 / 24500) loss: 1.446103
(Iteration 1401 / 24500) loss: 1.641093
(Iteration 1451 / 24500) loss: 1.452446
(Epoch 3 / 50) train acc: 0.522000; val_acc: 0.489000
(Iteration 1501 / 24500) loss: 1.377459
(Iteration 1551 / 24500) loss: 1.501052
(Iteration 1601 / 24500) loss: 1.660645
(Iteration 1651 / 24500) loss: 1.570234
(Iteration 1701 / 24500) loss: 1.420901
(Iteration 1751 / 24500) loss: 1.478823
(Iteration 1801 / 24500) loss: 1.495980
(Iteration 1851 / 24500) loss: 1.382123
(Iteration 1901 / 24500) loss: 1.297844
(Iteration 1951 / 24500) loss: 1.322277
(Epoch 4 / 50) train acc: 0.510000; val_acc: 0.507000
(Iteration 2001 / 24500) loss: 1.464479
(Iteration 2051 / 24500) loss: 1.297532
(Iteration 2101 / 24500) loss: 1.288219
(Iteration 2151 / 24500) loss: 1.489317
(Iteration 2201 / 24500) loss: 1.397845
(Iteration 2251 / 24500) loss: 1.504415
(Iteration 2301 / 24500) loss: 1.339857
(Iteration 2351 / 24500) loss: 1.207229
(Iteration 2401 / 24500) loss: 1.458096
(Epoch 5 / 50) train acc: 0.529000; val_acc: 0.516000
(Iteration 2451 / 24500) loss: 1.553819
(Iteration 2501 / 24500) loss: 1.428893
(Iteration 2551 / 24500) loss: 1.474496
(Iteration 2601 / 24500) loss: 1.254155
(Iteration 2651 / 24500) loss: 1.402294
(Iteration 2701 / 24500) loss: 1.406425
(Iteration 2751 / 24500) loss: 1.554659
(Iteration 2801 / 24500) loss: 1.353550
(Iteration 2851 / 24500) loss: 1.363503
(Iteration 2901 / 24500) loss: 1.302874
(Epoch 6 / 50) train acc: 0.565000; val_acc: 0.529000
(Iteration 2951 / 24500) loss: 1.358438
(Iteration 3001 / 24500) loss: 1.334471
(Iteration 3051 / 24500) loss: 1.265139
(Iteration 3101 / 24500) loss: 1.414339
(Iteration 3151 / 24500) loss: 1.489525
(Iteration 3201 / 24500) loss: 1.283960
(Iteration 3251 / 24500) loss: 1.094853
(Iteration 3301 / 24500) loss: 1.443872
(Iteration 3351 / 24500) loss: 1.423315
(Iteration 3401 / 24500) loss: 1.444200
(Epoch 7 / 50) train acc: 0.565000; val_acc: 0.528000
(Iteration 3451 / 24500) loss: 1.207743
(Iteration 3501 / 24500) loss: 1.170096
(Iteration 3551 / 24500) loss: 1.404787
(Iteration 3601 / 24500) loss: 1.199168
(Iteration 3651 / 24500) loss: 1.374974
(Iteration 3701 / 24500) loss: 1.432437
(Iteration 3751 / 24500) loss: 1.296448
(Iteration 3801 / 24500) loss: 1.246627
(Iteration 3851 / 24500) loss: 1.313324
(Iteration 3901 / 24500) loss: 1.343570
(Epoch 8 / 50) train acc: 0.565000; val_acc: 0.524000
(Iteration 3951 / 24500) loss: 1.238897
(Iteration 4001 / 24500) loss: 1.471714
(Iteration 4051 / 24500) loss: 1.294710
(Iteration 4101 / 24500) loss: 1.393026
(Iteration 4151 / 24500) loss: 1.211708
(Iteration 4201 / 24500) loss: 1.354351
(Iteration 4251 / 24500) loss: 1.423875
(Iteration 4301 / 24500) loss: 1.439383
(Iteration 4351 / 24500) loss: 1.353851
(Iteration 4401 / 24500) loss: 1.371835
(Epoch 9 / 50) train acc: 0.586000; val_acc: 0.536000
(Iteration 4451 / 24500) loss: 1.228195
(Iteration 4501 / 24500) loss: 1.266024
(Iteration 4551 / 24500) loss: 1.270248
(Iteration 4601 / 24500) loss: 1.199219
(Iteration 4651 / 24500) loss: 1.224324
(Iteration 4701 / 24500) loss: 1.344505
(Iteration 4751 / 24500) loss: 1.259913
(Iteration 4801 / 24500) loss: 1.119143
(Iteration 4851 / 24500) loss: 1.459287
(Epoch 10 / 50) train acc: 0.593000; val_acc: 0.557000
(Iteration 4901 / 24500) loss: 1.325974
(Iteration 4951 / 24500) loss: 1.222487
(Iteration 5001 / 24500) loss: 1.227410
(Iteration 5051 / 24500) loss: 1.348163
(Iteration 5101 / 24500) loss: 1.293895
(Iteration 5151 / 24500) loss: 1.256780
(Iteration 5201 / 24500) loss: 1.287450
(Iteration 5251 / 24500) loss: 1.153941
(Iteration 5301 / 24500) loss: 1.203236
(Iteration 5351 / 24500) loss: 1.335570
(Epoch 11 / 50) train acc: 0.599000; val_acc: 0.542000
(Iteration 5401 / 24500) loss: 1.001296
(Iteration 5451 / 24500) loss: 1.087564
(Iteration 5501 / 24500) loss: 1.202886
(Iteration 5551 / 24500) loss: 1.521732
(Iteration 5601 / 24500) loss: 1.163875
(Iteration 5651 / 24500) loss: 1.235414
(Iteration 5701 / 24500) loss: 1.220625
(Iteration 5751 / 24500) loss: 1.293625
(Iteration 5801 / 24500) loss: 1.109146
(Iteration 5851 / 24500) loss: 1.387404
(Epoch 12 / 50) train acc: 0.591000; val_acc: 0.544000
(Iteration 5901 / 24500) loss: 1.271315
(Iteration 5951 / 24500) loss: 1.238138
(Iteration 6001 / 24500) loss: 1.340902
(Iteration 6051 / 24500) loss: 1.144911
(Iteration 6101 / 24500) loss: 1.179323
(Iteration 6151 / 24500) loss: 1.256851
(Iteration 6201 / 24500) loss: 1.205531
(Iteration 6251 / 24500) loss: 1.074533
(Iteration 6301 / 24500) loss: 1.220392
(Iteration 6351 / 24500) loss: 1.292398
(Epoch 13 / 50) train acc: 0.581000; val_acc: 0.549000
(Iteration 6401 / 24500) loss: 0.995295
(Iteration 6451 / 24500) loss: 1.257927
(Iteration 6501 / 24500) loss: 1.195513
(Iteration 6551 / 24500) loss: 1.301866
(Iteration 6601 / 24500) loss: 1.189790
(Iteration 6651 / 24500) loss: 1.208295
(Iteration 6701 / 24500) loss: 1.292733
(Iteration 6751 / 24500) loss: 1.175295
(Iteration 6801 / 24500) loss: 1.198658
(Iteration 6851 / 24500) loss: 1.060763
(Epoch 14 / 50) train acc: 0.619000; val_acc: 0.549000
(Iteration 6901 / 24500) loss: 1.158194
(Iteration 6951 / 24500) loss: 1.095798
(Iteration 7001 / 24500) loss: 1.207425
(Iteration 7051 / 24500) loss: 1.261719
(Iteration 7101 / 24500) loss: 1.330033
(Iteration 7151 / 24500) loss: 1.001320
(Iteration 7201 / 24500) loss: 1.319751
(Iteration 7251 / 24500) loss: 1.121961
(Iteration 7301 / 24500) loss: 1.107846
(Epoch 15 / 50) train acc: 0.600000; val_acc: 0.547000
(Iteration 7351 / 24500) loss: 1.216017
(Iteration 7401 / 24500) loss: 1.090520
(Iteration 7451 / 24500) loss: 1.276242
(Iteration 7501 / 24500) loss: 1.248582
(Iteration 7551 / 24500) loss: 1.105791
(Iteration 7601 / 24500) loss: 1.249850
(Iteration 7651 / 24500) loss: 1.136150
(Iteration 7701 / 24500) loss: 1.354642
(Iteration 7751 / 24500) loss: 1.148751
(Iteration 7801 / 24500) loss: 1.310286
(Epoch 16 / 50) train acc: 0.630000; val_acc: 0.550000
(Iteration 7851 / 24500) loss: 1.072998
(Iteration 7901 / 24500) loss: 1.071468
(Iteration 7951 / 24500) loss: 1.157614
(Iteration 8001 / 24500) loss: 1.017270
(Iteration 8051 / 24500) loss: 1.189827
(Iteration 8101 / 24500) loss: 1.116365
(Iteration 8151 / 24500) loss: 1.210843
(Iteration 8201 / 24500) loss: 1.341160
(Iteration 8251 / 24500) loss: 1.151830
(Iteration 8301 / 24500) loss: 1.165885
(Epoch 17 / 50) train acc: 0.639000; val_acc: 0.550000
(Iteration 8351 / 24500) loss: 1.108371
(Iteration 8401 / 24500) loss: 1.059231
(Iteration 8451 / 24500) loss: 1.161948
(Iteration 8501 / 24500) loss: 1.201778
(Iteration 8551 / 24500) loss: 1.232636
(Iteration 8601 / 24500) loss: 1.242190
(Iteration 8651 / 24500) loss: 1.357529
(Iteration 8701 / 24500) loss: 1.282119
(Iteration 8751 / 24500) loss: 1.406438
(Iteration 8801 / 24500) loss: 1.055985
(Epoch 18 / 50) train acc: 0.666000; val_acc: 0.552000
(Iteration 8851 / 24500) loss: 1.204534
(Iteration 8901 / 24500) loss: 1.226288
(Iteration 8951 / 24500) loss: 1.012205
(Iteration 9001 / 24500) loss: 1.128383
(Iteration 9051 / 24500) loss: 1.074690
(Iteration 9101 / 24500) loss: 1.238678
(Iteration 9151 / 24500) loss: 1.269725
(Iteration 9201 / 24500) loss: 1.146683
(Iteration 9251 / 24500) loss: 0.979178
(Iteration 9301 / 24500) loss: 0.969209
(Epoch 19 / 50) train acc: 0.633000; val_acc: 0.545000
(Iteration 9351 / 24500) loss: 1.173531
(Iteration 9401 / 24500) loss: 1.203154
(Iteration 9451 / 24500) loss: 1.108773
(Iteration 9501 / 24500) loss: 1.268281
(Iteration 9551 / 24500) loss: 1.040282
(Iteration 9601 / 24500) loss: 1.128744
(Iteration 9651 / 24500) loss: 1.325592
(Iteration 9701 / 24500) loss: 1.141276
(Iteration 9751 / 24500) loss: 1.177974
(Epoch 20 / 50) train acc: 0.649000; val_acc: 0.550000
(Iteration 9801 / 24500) loss: 1.272855
(Iteration 9851 / 24500) loss: 1.256549
(Iteration 9901 / 24500) loss: 1.057937
(Iteration 9951 / 24500) loss: 0.959736
(Iteration 10001 / 24500) loss: 1.132035
(Iteration 10051 / 24500) loss: 1.286626
(Iteration 10101 / 24500) loss: 1.207648
(Iteration 10151 / 24500) loss: 1.292275
(Iteration 10201 / 24500) loss: 1.238228
(Iteration 10251 / 24500) loss: 1.190835
(Epoch 21 / 50) train acc: 0.642000; val_acc: 0.554000
(Iteration 10301 / 24500) loss: 1.131018
(Iteration 10351 / 24500) loss: 1.052740
(Iteration 10401 / 24500) loss: 1.134089
(Iteration 10451 / 24500) loss: 1.086583
(Iteration 10501 / 24500) loss: 1.322100
(Iteration 10551 / 24500) loss: 1.145560
(Iteration 10601 / 24500) loss: 1.142830
(Iteration 10651 / 24500) loss: 1.067654
(Iteration 10701 / 24500) loss: 1.055275
(Iteration 10751 / 24500) loss: 1.178451
(Epoch 22 / 50) train acc: 0.635000; val_acc: 0.566000
(Iteration 10801 / 24500) loss: 1.154936
(Iteration 10851 / 24500) loss: 1.071778
(Iteration 10901 / 24500) loss: 1.058641
(Iteration 10951 / 24500) loss: 1.033143
(Iteration 11001 / 24500) loss: 1.067872
(Iteration 11051 / 24500) loss: 1.186964
(Iteration 11101 / 24500) loss: 1.060466
(Iteration 11151 / 24500) loss: 0.927844
(Iteration 11201 / 24500) loss: 1.216982
(Iteration 11251 / 24500) loss: 1.338510
(Epoch 23 / 50) train acc: 0.660000; val_acc: 0.552000
(Iteration 11301 / 24500) loss: 1.136562
(Iteration 11351 / 24500) loss: 1.329167
(Iteration 11401 / 24500) loss: 1.161146
(Iteration 11451 / 24500) loss: 1.123918
(Iteration 11501 / 24500) loss: 1.154351
(Iteration 11551 / 24500) loss: 0.923344
(Iteration 11601 / 24500) loss: 1.157039
(Iteration 11651 / 24500) loss: 1.249761
(Iteration 11701 / 24500) loss: 1.219585
(Iteration 11751 / 24500) loss: 1.129460
(Epoch 24 / 50) train acc: 0.676000; val_acc: 0.565000
(Iteration 11801 / 24500) loss: 1.137326
(Iteration 11851 / 24500) loss: 1.144080
(Iteration 11901 / 24500) loss: 1.128663
(Iteration 11951 / 24500) loss: 1.270634
(Iteration 12001 / 24500) loss: 1.092517
(Iteration 12051 / 24500) loss: 1.024169
(Iteration 12101 / 24500) loss: 1.326727
(Iteration 12151 / 24500) loss: 1.249877
(Iteration 12201 / 24500) loss: 1.001111
(Epoch 25 / 50) train acc: 0.684000; val_acc: 0.568000
(Iteration 12251 / 24500) loss: 1.092154
(Iteration 12301 / 24500) loss: 1.271832
(Iteration 12351 / 24500) loss: 1.153935
(Iteration 12401 / 24500) loss: 1.108342
(Iteration 12451 / 24500) loss: 1.101942
(Iteration 12501 / 24500) loss: 0.979580
(Iteration 12551 / 24500) loss: 1.166607
(Iteration 12601 / 24500) loss: 1.126839
(Iteration 12651 / 24500) loss: 1.127245
(Iteration 12701 / 24500) loss: 1.171744
(Epoch 26 / 50) train acc: 0.660000; val_acc: 0.564000
(Iteration 12751 / 24500) loss: 1.094491
(Iteration 12801 / 24500) loss: 1.065334
(Iteration 12851 / 24500) loss: 1.325549
(Iteration 12901 / 24500) loss: 1.284262
(Iteration 12951 / 24500) loss: 1.029251
(Iteration 13001 / 24500) loss: 1.164328
(Iteration 13051 / 24500) loss: 1.014443
(Iteration 13101 / 24500) loss: 1.181021
(Iteration 13151 / 24500) loss: 1.113127
(Iteration 13201 / 24500) loss: 1.105958
(Epoch 27 / 50) train acc: 0.684000; val_acc: 0.564000
(Iteration 13251 / 24500) loss: 1.151504
(Iteration 13301 / 24500) loss: 0.978754
(Iteration 13351 / 24500) loss: 1.137297
(Iteration 13401 / 24500) loss: 1.012702
(Iteration 13451 / 24500) loss: 1.153677
(Iteration 13501 / 24500) loss: 1.111311
(Iteration 13551 / 24500) loss: 1.177830
(Iteration 13601 / 24500) loss: 1.174253
(Iteration 13651 / 24500) loss: 1.176442
(Iteration 13701 / 24500) loss: 1.227686
(Epoch 28 / 50) train acc: 0.657000; val_acc: 0.568000
(Iteration 13751 / 24500) loss: 1.092207
(Iteration 13801 / 24500) loss: 1.144503
(Iteration 13851 / 24500) loss: 1.181551
(Iteration 13901 / 24500) loss: 1.069628
(Iteration 13951 / 24500) loss: 1.038279
(Iteration 14001 / 24500) loss: 1.193967
(Iteration 14051 / 24500) loss: 1.085434
(Iteration 14101 / 24500) loss: 1.085267
(Iteration 14151 / 24500) loss: 1.046604
(Iteration 14201 / 24500) loss: 1.208906
(Epoch 29 / 50) train acc: 0.662000; val_acc: 0.563000
(Iteration 14251 / 24500) loss: 1.059541
(Iteration 14301 / 24500) loss: 1.075540
(Iteration 14351 / 24500) loss: 1.148706
(Iteration 14401 / 24500) loss: 1.053615
(Iteration 14451 / 24500) loss: 0.913290
(Iteration 14501 / 24500) loss: 1.028205
(Iteration 14551 / 24500) loss: 1.039786
(Iteration 14601 / 24500) loss: 1.110282
(Iteration 14651 / 24500) loss: 1.162708
(Epoch 30 / 50) train acc: 0.669000; val_acc: 0.566000
(Iteration 14701 / 24500) loss: 0.962205
(Iteration 14751 / 24500) loss: 1.211715
(Iteration 14801 / 24500) loss: 1.071015
(Iteration 14851 / 24500) loss: 1.165667
(Iteration 14901 / 24500) loss: 1.245850
(Iteration 14951 / 24500) loss: 1.066306
(Iteration 15001 / 24500) loss: 1.207876
(Iteration 15051 / 24500) loss: 1.259709
(Iteration 15101 / 24500) loss: 1.335338
(Iteration 15151 / 24500) loss: 1.290004
(Epoch 31 / 50) train acc: 0.656000; val_acc: 0.570000
(Iteration 15201 / 24500) loss: 1.203703
(Iteration 15251 / 24500) loss: 1.143706
(Iteration 15301 / 24500) loss: 1.218491
(Iteration 15351 / 24500) loss: 1.065318
(Iteration 15401 / 24500) loss: 1.007905
(Iteration 15451 / 24500) loss: 1.167797
(Iteration 15501 / 24500) loss: 0.930591
(Iteration 15551 / 24500) loss: 1.046362
(Iteration 15601 / 24500) loss: 1.098472
(Iteration 15651 / 24500) loss: 1.082150
(Epoch 32 / 50) train acc: 0.675000; val_acc: 0.563000
(Iteration 15701 / 24500) loss: 1.155011
(Iteration 15751 / 24500) loss: 1.152235
(Iteration 15801 / 24500) loss: 1.274265
(Iteration 15851 / 24500) loss: 1.156273
(Iteration 15901 / 24500) loss: 1.189700
(Iteration 15951 / 24500) loss: 1.200262
(Iteration 16001 / 24500) loss: 1.131581
(Iteration 16051 / 24500) loss: 1.216722
(Iteration 16101 / 24500) loss: 1.146895
(Iteration 16151 / 24500) loss: 1.191824
(Epoch 33 / 50) train acc: 0.701000; val_acc: 0.569000
(Iteration 16201 / 24500) loss: 0.896269
(Iteration 16251 / 24500) loss: 1.105766
(Iteration 16301 / 24500) loss: 0.962785
(Iteration 16351 / 24500) loss: 1.143449
(Iteration 16401 / 24500) loss: 1.004859
(Iteration 16451 / 24500) loss: 1.117456
(Iteration 16501 / 24500) loss: 1.272482
(Iteration 16551 / 24500) loss: 1.075163
(Iteration 16601 / 24500) loss: 1.121111
(Iteration 16651 / 24500) loss: 1.133141
(Epoch 34 / 50) train acc: 0.691000; val_acc: 0.566000
(Iteration 16701 / 24500) loss: 1.082172
(Iteration 16751 / 24500) loss: 1.134964
(Iteration 16801 / 24500) loss: 1.014845
(Iteration 16851 / 24500) loss: 1.010888
(Iteration 16901 / 24500) loss: 1.120224
(Iteration 16951 / 24500) loss: 1.008542
(Iteration 17001 / 24500) loss: 1.062674
(Iteration 17051 / 24500) loss: 0.966313
(Iteration 17101 / 24500) loss: 1.068260
(Epoch 35 / 50) train acc: 0.700000; val_acc: 0.569000
(Iteration 17151 / 24500) loss: 1.010716
(Iteration 17201 / 24500) loss: 1.232124
(Iteration 17251 / 24500) loss: 1.182022
(Iteration 17301 / 24500) loss: 1.137117
(Iteration 17351 / 24500) loss: 1.233242
(Iteration 17401 / 24500) loss: 0.930073
(Iteration 17451 / 24500) loss: 0.966533
(Iteration 17501 / 24500) loss: 0.972124
(Iteration 17551 / 24500) loss: 1.056758
(Iteration 17601 / 24500) loss: 1.129640
(Epoch 36 / 50) train acc: 0.692000; val_acc: 0.564000
(Iteration 17651 / 24500) loss: 1.014397
(Iteration 17701 / 24500) loss: 1.010376
(Iteration 17751 / 24500) loss: 1.159602
(Iteration 17801 / 24500) loss: 1.196457
(Iteration 17851 / 24500) loss: 1.149835
(Iteration 17901 / 24500) loss: 1.034723
(Iteration 17951 / 24500) loss: 1.176591
(Iteration 18001 / 24500) loss: 0.958967
(Iteration 18051 / 24500) loss: 1.081588
(Iteration 18101 / 24500) loss: 0.995797
(Epoch 37 / 50) train acc: 0.692000; val_acc: 0.574000
(Iteration 18151 / 24500) loss: 1.115016
(Iteration 18201 / 24500) loss: 1.135090
(Iteration 18251 / 24500) loss: 0.991144
(Iteration 18301 / 24500) loss: 1.012067
(Iteration 18351 / 24500) loss: 1.113592
(Iteration 18401 / 24500) loss: 1.135345
(Iteration 18451 / 24500) loss: 1.144985
(Iteration 18501 / 24500) loss: 1.146104
(Iteration 18551 / 24500) loss: 1.107757
(Iteration 18601 / 24500) loss: 1.153710
(Epoch 38 / 50) train acc: 0.714000; val_acc: 0.562000
(Iteration 18651 / 24500) loss: 1.319343
(Iteration 18701 / 24500) loss: 1.059247
(Iteration 18751 / 24500) loss: 1.031872
(Iteration 18801 / 24500) loss: 1.106221
(Iteration 18851 / 24500) loss: 1.095762
(Iteration 18901 / 24500) loss: 1.185153
(Iteration 18951 / 24500) loss: 1.067485
(Iteration 19001 / 24500) loss: 0.950452
(Iteration 19051 / 24500) loss: 1.112372
(Iteration 19101 / 24500) loss: 1.021484
(Epoch 39 / 50) train acc: 0.690000; val_acc: 0.568000
(Iteration 19151 / 24500) loss: 1.093074
(Iteration 19201 / 24500) loss: 1.120996
(Iteration 19251 / 24500) loss: 1.102724
(Iteration 19301 / 24500) loss: 0.915599
(Iteration 19351 / 24500) loss: 1.177078
(Iteration 19401 / 24500) loss: 1.004055
(Iteration 19451 / 24500) loss: 0.951351
(Iteration 19501 / 24500) loss: 1.109111
(Iteration 19551 / 24500) loss: 0.922506
(Epoch 40 / 50) train acc: 0.695000; val_acc: 0.572000
(Iteration 19601 / 24500) loss: 0.997933
(Iteration 19651 / 24500) loss: 1.073588
(Iteration 19701 / 24500) loss: 1.038826
(Iteration 19751 / 24500) loss: 1.232828
(Iteration 19801 / 24500) loss: 1.099696
(Iteration 19851 / 24500) loss: 1.019684
(Iteration 19901 / 24500) loss: 1.059823
(Iteration 19951 / 24500) loss: 1.237058
(Iteration 20001 / 24500) loss: 1.371932
(Iteration 20051 / 24500) loss: 1.174792
(Epoch 41 / 50) train acc: 0.680000; val_acc: 0.571000
(Iteration 20101 / 24500) loss: 1.096767
(Iteration 20151 / 24500) loss: 1.146868
(Iteration 20201 / 24500) loss: 1.224874
(Iteration 20251 / 24500) loss: 1.050727
(Iteration 20301 / 24500) loss: 0.966882
(Iteration 20351 / 24500) loss: 1.091800
(Iteration 20401 / 24500) loss: 1.107920
(Iteration 20451 / 24500) loss: 1.241613
(Iteration 20501 / 24500) loss: 0.935404
(Iteration 20551 / 24500) loss: 0.969241
(Epoch 42 / 50) train acc: 0.677000; val_acc: 0.573000
(Iteration 20601 / 24500) loss: 1.190858
(Iteration 20651 / 24500) loss: 1.046250
(Iteration 20701 / 24500) loss: 1.025061
(Iteration 20751 / 24500) loss: 1.258958
(Iteration 20801 / 24500) loss: 0.928829
(Iteration 20851 / 24500) loss: 1.362095
(Iteration 20901 / 24500) loss: 1.039658
(Iteration 20951 / 24500) loss: 1.010676
(Iteration 21001 / 24500) loss: 0.971324
(Iteration 21051 / 24500) loss: 1.044724
(Epoch 43 / 50) train acc: 0.710000; val_acc: 0.572000
(Iteration 21101 / 24500) loss: 1.024495
(Iteration 21151 / 24500) loss: 0.956539
(Iteration 21201 / 24500) loss: 1.119237
(Iteration 21251 / 24500) loss: 1.185089
(Iteration 21301 / 24500) loss: 1.101015
(Iteration 21351 / 24500) loss: 1.194813
(Iteration 21401 / 24500) loss: 1.141874
(Iteration 21451 / 24500) loss: 1.052443
(Iteration 21501 / 24500) loss: 1.101094
(Iteration 21551 / 24500) loss: 0.935440
(Epoch 44 / 50) train acc: 0.673000; val_acc: 0.571000
(Iteration 21601 / 24500) loss: 1.181210
(Iteration 21651 / 24500) loss: 1.025976
(Iteration 21701 / 24500) loss: 1.209510
(Iteration 21751 / 24500) loss: 1.078063
(Iteration 21801 / 24500) loss: 1.038938
(Iteration 21851 / 24500) loss: 1.112339
(Iteration 21901 / 24500) loss: 1.007857
(Iteration 21951 / 24500) loss: 1.247641
(Iteration 22001 / 24500) loss: 1.068637
(Epoch 45 / 50) train acc: 0.664000; val_acc: 0.576000
(Iteration 22051 / 24500) loss: 1.021806
(Iteration 22101 / 24500) loss: 1.053945
(Iteration 22151 / 24500) loss: 1.195499
(Iteration 22201 / 24500) loss: 1.038367
(Iteration 22251 / 24500) loss: 1.125131
(Iteration 22301 / 24500) loss: 1.200832
(Iteration 22351 / 24500) loss: 1.003207
(Iteration 22401 / 24500) loss: 1.179828
(Iteration 22451 / 24500) loss: 1.118984
(Iteration 22501 / 24500) loss: 0.892415
(Epoch 46 / 50) train acc: 0.686000; val_acc: 0.574000
(Iteration 22551 / 24500) loss: 1.108798
(Iteration 22601 / 24500) loss: 0.991991
(Iteration 22651 / 24500) loss: 1.156470
(Iteration 22701 / 24500) loss: 1.111385
(Iteration 22751 / 24500) loss: 0.979770
(Iteration 22801 / 24500) loss: 1.147886
(Iteration 22851 / 24500) loss: 1.289139
(Iteration 22901 / 24500) loss: 1.103673
(Iteration 22951 / 24500) loss: 1.126254
(Iteration 23001 / 24500) loss: 1.066313
(Epoch 47 / 50) train acc: 0.714000; val_acc: 0.571000
(Iteration 23051 / 24500) loss: 1.180773
(Iteration 23101 / 24500) loss: 1.208659
(Iteration 23151 / 24500) loss: 0.984597
(Iteration 23201 / 24500) loss: 1.134967
(Iteration 23251 / 24500) loss: 0.962361
(Iteration 23301 / 24500) loss: 1.152453
(Iteration 23351 / 24500) loss: 1.306130
(Iteration 23401 / 24500) loss: 1.111042
(Iteration 23451 / 24500) loss: 1.031650
(Iteration 23501 / 24500) loss: 1.000566
(Epoch 48 / 50) train acc: 0.653000; val_acc: 0.572000
(Iteration 23551 / 24500) loss: 0.971546
(Iteration 23601 / 24500) loss: 1.099967
(Iteration 23651 / 24500) loss: 1.161348
(Iteration 23701 / 24500) loss: 1.174016
(Iteration 23751 / 24500) loss: 1.011950
(Iteration 23801 / 24500) loss: 1.435858
(Iteration 23851 / 24500) loss: 1.082499
(Iteration 23901 / 24500) loss: 1.132071
(Iteration 23951 / 24500) loss: 1.240697
(Iteration 24001 / 24500) loss: 1.189299
(Epoch 49 / 50) train acc: 0.676000; val_acc: 0.570000
(Iteration 24051 / 24500) loss: 1.039877
(Iteration 24101 / 24500) loss: 1.018416
(Iteration 24151 / 24500) loss: 1.297790
(Iteration 24201 / 24500) loss: 1.148773
(Iteration 24251 / 24500) loss: 1.054055
(Iteration 24301 / 24500) loss: 1.221038
(Iteration 24351 / 24500) loss: 1.156561
(Iteration 24401 / 24500) loss: 1.096671
(Iteration 24451 / 24500) loss: 1.154295
(Epoch 50 / 50) train acc: 0.708000; val_acc: 0.572000