layer_dims = [600, 600, 600, 600]
weight_scale = 0.01
learning_rate = 1e-3
lr_decay = 0.90

model = FullyConnectedNet(layer_dims, weight_scale=weight_scale,
                          dropout=0.65, reg=0, use_batchnorm=True)

solver = Solver(model, data,
                num_epochs=50, batch_size=50,
                update_rule='adam',
                optim_config={
                  'learning_rate': learning_rate,
                },
                lr_decay=lr_decay,
                verbose=True, print_every=50)
solver.train()

(Iteration 1 / 49000) loss: 2.366743
(Epoch 0 / 50) train acc: 0.189000; val_acc: 0.181000
(Iteration 51 / 49000) loss: 1.999690
(Iteration 101 / 49000) loss: 1.829126
(Iteration 151 / 49000) loss: 2.031293
(Iteration 201 / 49000) loss: 1.578570
(Iteration 251 / 49000) loss: 1.817545
(Iteration 301 / 49000) loss: 1.802130
(Iteration 351 / 49000) loss: 1.773409
(Iteration 401 / 49000) loss: 1.794544
(Iteration 451 / 49000) loss: 1.757640
(Iteration 501 / 49000) loss: 1.833597
(Iteration 551 / 49000) loss: 1.901302
(Iteration 601 / 49000) loss: 1.537753
(Iteration 651 / 49000) loss: 1.478283
(Iteration 701 / 49000) loss: 1.447692
(Iteration 751 / 49000) loss: 1.807762
(Iteration 801 / 49000) loss: 1.518855
(Iteration 851 / 49000) loss: 1.681779
(Iteration 901 / 49000) loss: 1.614178
(Iteration 951 / 49000) loss: 1.946575
(Epoch 1 / 50) train acc: 0.465000; val_acc: 0.470000
(Iteration 1001 / 49000) loss: 1.752969
(Iteration 1051 / 49000) loss: 1.423046
(Iteration 1101 / 49000) loss: 1.447656
(Iteration 1151 / 49000) loss: 1.268567
(Iteration 1201 / 49000) loss: 1.587777
(Iteration 1251 / 49000) loss: 1.481554
(Iteration 1301 / 49000) loss: 1.504861
(Iteration 1351 / 49000) loss: 1.612939
(Iteration 1401 / 49000) loss: 1.831051
(Iteration 1451 / 49000) loss: 1.612146
(Iteration 1501 / 49000) loss: 1.385491
(Iteration 1551 / 49000) loss: 1.497599
(Iteration 1601 / 49000) loss: 1.613829
(Iteration 1651 / 49000) loss: 1.247785
(Iteration 1701 / 49000) loss: 1.263216
(Iteration 1751 / 49000) loss: 1.426032
(Iteration 1801 / 49000) loss: 1.309764
(Iteration 1851 / 49000) loss: 1.419610
(Iteration 1901 / 49000) loss: 1.364844
(Iteration 1951 / 49000) loss: 1.532332
(Epoch 2 / 50) train acc: 0.507000; val_acc: 0.488000
(Iteration 2001 / 49000) loss: 1.412567
(Iteration 2051 / 49000) loss: 1.572273
(Iteration 2101 / 49000) loss: 1.093616
(Iteration 2151 / 49000) loss: 1.819915
(Iteration 2201 / 49000) loss: 1.699558
(Iteration 2251 / 49000) loss: 1.810175
(Iteration 2301 / 49000) loss: 1.449380
(Iteration 2351 / 49000) loss: 1.408482
(Iteration 2401 / 49000) loss: 1.644850
(Iteration 2451 / 49000) loss: 1.482822
(Iteration 2501 / 49000) loss: 1.631271
(Iteration 2551 / 49000) loss: 1.485486
(Iteration 2601 / 49000) loss: 1.336864
(Iteration 2651 / 49000) loss: 1.311739
(Iteration 2701 / 49000) loss: 1.509111
(Iteration 2751 / 49000) loss: 1.473588
(Iteration 2801 / 49000) loss: 1.352271
(Iteration 2851 / 49000) loss: 1.491058
(Iteration 2901 / 49000) loss: 1.495602
(Epoch 3 / 50) train acc: 0.514000; val_acc: 0.515000
(Iteration 2951 / 49000) loss: 1.537853
(Iteration 3001 / 49000) loss: 1.498439
(Iteration 3051 / 49000) loss: 1.396737
(Iteration 3101 / 49000) loss: 1.350299
(Iteration 3151 / 49000) loss: 1.459444
(Iteration 3201 / 49000) loss: 1.146855
(Iteration 3251 / 49000) loss: 1.202308
(Iteration 3301 / 49000) loss: 1.383362
(Iteration 3351 / 49000) loss: 1.446270
(Iteration 3401 / 49000) loss: 1.709575
(Iteration 3451 / 49000) loss: 1.155958
(Iteration 3501 / 49000) loss: 1.154731
(Iteration 3551 / 49000) loss: 1.331618
(Iteration 3601 / 49000) loss: 1.451620
(Iteration 3651 / 49000) loss: 1.702004
(Iteration 3701 / 49000) loss: 1.806182
(Iteration 3751 / 49000) loss: 1.499007
(Iteration 3801 / 49000) loss: 1.653063
(Iteration 3851 / 49000) loss: 1.358781
(Iteration 3901 / 49000) loss: 1.292211
(Epoch 4 / 50) train acc: 0.538000; val_acc: 0.506000
(Iteration 3951 / 49000) loss: 1.341453
(Iteration 4001 / 49000) loss: 1.329026
(Iteration 4051 / 49000) loss: 1.317177
(Iteration 4101 / 49000) loss: 1.399569
(Iteration 4151 / 49000) loss: 1.548527
(Iteration 4201 / 49000) loss: 1.475935
(Iteration 4251 / 49000) loss: 1.471016
(Iteration 4301 / 49000) loss: 1.145728
(Iteration 4351 / 49000) loss: 1.354444
(Iteration 4401 / 49000) loss: 1.144944
(Iteration 4451 / 49000) loss: 1.247837
(Iteration 4501 / 49000) loss: 1.378667
(Iteration 4551 / 49000) loss: 1.480814
(Iteration 4601 / 49000) loss: 1.388664
(Iteration 4651 / 49000) loss: 1.205140
(Iteration 4701 / 49000) loss: 1.249757
(Iteration 4751 / 49000) loss: 1.287833
(Iteration 4801 / 49000) loss: 1.440955
(Iteration 4851 / 49000) loss: 1.053712
(Epoch 5 / 50) train acc: 0.555000; val_acc: 0.543000
(Iteration 4901 / 49000) loss: 1.332944
(Iteration 4951 / 49000) loss: 1.125037
(Iteration 5001 / 49000) loss: 1.341339
(Iteration 5051 / 49000) loss: 1.527704
(Iteration 5101 / 49000) loss: 1.495212
(Iteration 5151 / 49000) loss: 1.521661
(Iteration 5201 / 49000) loss: 1.194030
(Iteration 5251 / 49000) loss: 1.134207
(Iteration 5301 / 49000) loss: 1.238386
(Iteration 5351 / 49000) loss: 1.571372
(Iteration 5401 / 49000) loss: 1.189307
(Iteration 5451 / 49000) loss: 1.396328
(Iteration 5501 / 49000) loss: 1.432141
(Iteration 5551 / 49000) loss: 1.064111
(Iteration 5601 / 49000) loss: 1.133028
(Iteration 5651 / 49000) loss: 1.441592
(Iteration 5701 / 49000) loss: 1.314367
(Iteration 5751 / 49000) loss: 1.063462
(Iteration 5801 / 49000) loss: 1.254485
(Iteration 5851 / 49000) loss: 1.272779
(Epoch 6 / 50) train acc: 0.589000; val_acc: 0.533000
(Iteration 5901 / 49000) loss: 1.452652
(Iteration 5951 / 49000) loss: 1.212390
(Iteration 6001 / 49000) loss: 1.362450
(Iteration 6051 / 49000) loss: 1.059228
(Iteration 6101 / 49000) loss: 1.394664
(Iteration 6151 / 49000) loss: 1.216331
(Iteration 6201 / 49000) loss: 1.421520
(Iteration 6251 / 49000) loss: 0.936366
(Iteration 6301 / 49000) loss: 1.420110
(Iteration 6351 / 49000) loss: 1.122389
(Iteration 6401 / 49000) loss: 1.156113
(Iteration 6451 / 49000) loss: 1.275326
(Iteration 6501 / 49000) loss: 1.373762
(Iteration 6551 / 49000) loss: 1.235899
(Iteration 6601 / 49000) loss: 1.173026
(Iteration 6651 / 49000) loss: 1.303414
(Iteration 6701 / 49000) loss: 1.433021
(Iteration 6751 / 49000) loss: 1.212020
(Iteration 6801 / 49000) loss: 1.084010
(Iteration 6851 / 49000) loss: 1.191427
(Epoch 7 / 50) train acc: 0.593000; val_acc: 0.550000
(Iteration 6901 / 49000) loss: 1.299631
(Iteration 6951 / 49000) loss: 1.454435
(Iteration 7001 / 49000) loss: 1.459894
(Iteration 7051 / 49000) loss: 1.208725
(Iteration 7101 / 49000) loss: 1.263026
(Iteration 7151 / 49000) loss: 1.171890
(Iteration 7201 / 49000) loss: 1.184996
(Iteration 7251 / 49000) loss: 1.263758
(Iteration 7301 / 49000) loss: 1.438148
(Iteration 7351 / 49000) loss: 1.384127
(Iteration 7401 / 49000) loss: 1.174350
(Iteration 7451 / 49000) loss: 1.142721
(Iteration 7501 / 49000) loss: 1.108135
(Iteration 7551 / 49000) loss: 1.027494
(Iteration 7601 / 49000) loss: 1.017701
(Iteration 7651 / 49000) loss: 1.306528
(Iteration 7701 / 49000) loss: 1.249442
(Iteration 7751 / 49000) loss: 1.375686
(Iteration 7801 / 49000) loss: 1.201714
(Epoch 8 / 50) train acc: 0.635000; val_acc: 0.558000
(Iteration 7851 / 49000) loss: 1.411157
(Iteration 7901 / 49000) loss: 1.254389
(Iteration 7951 / 49000) loss: 1.244579
(Iteration 8001 / 49000) loss: 1.478324
(Iteration 8051 / 49000) loss: 1.194286
(Iteration 8101 / 49000) loss: 1.343963
(Iteration 8151 / 49000) loss: 1.387931
(Iteration 8201 / 49000) loss: 1.344424
(Iteration 8251 / 49000) loss: 0.943305
(Iteration 8301 / 49000) loss: 1.058581
(Iteration 8351 / 49000) loss: 1.250193
(Iteration 8401 / 49000) loss: 1.300658
(Iteration 8451 / 49000) loss: 1.221507
(Iteration 8501 / 49000) loss: 1.403302
(Iteration 8551 / 49000) loss: 1.258462
(Iteration 8601 / 49000) loss: 1.196741
(Iteration 8651 / 49000) loss: 1.117893
(Iteration 8701 / 49000) loss: 0.985935
(Iteration 8751 / 49000) loss: 1.002051
(Iteration 8801 / 49000) loss: 1.128799
(Epoch 9 / 50) train acc: 0.627000; val_acc: 0.558000
(Iteration 8851 / 49000) loss: 1.303446
(Iteration 8901 / 49000) loss: 1.232128
(Iteration 8951 / 49000) loss: 1.112473
(Iteration 9001 / 49000) loss: 1.333290
(Iteration 9051 / 49000) loss: 1.175308
(Iteration 9101 / 49000) loss: 1.152787
(Iteration 9151 / 49000) loss: 1.003180
(Iteration 9201 / 49000) loss: 1.001506
(Iteration 9251 / 49000) loss: 1.469552
(Iteration 9301 / 49000) loss: 1.474324
(Iteration 9351 / 49000) loss: 1.314825
(Iteration 9401 / 49000) loss: 1.426567
(Iteration 9451 / 49000) loss: 1.244661
(Iteration 9501 / 49000) loss: 1.115358
(Iteration 9551 / 49000) loss: 1.154558
(Iteration 9601 / 49000) loss: 1.022115
(Iteration 9651 / 49000) loss: 1.160830
(Iteration 9701 / 49000) loss: 1.336367
(Iteration 9751 / 49000) loss: 1.332176
(Epoch 10 / 50) train acc: 0.642000; val_acc: 0.565000
(Iteration 9801 / 49000) loss: 1.224036
(Iteration 9851 / 49000) loss: 1.024836
(Iteration 9901 / 49000) loss: 0.957292
(Iteration 9951 / 49000) loss: 1.554759
(Iteration 10001 / 49000) loss: 1.007324
(Iteration 10051 / 49000) loss: 1.307815
(Iteration 10101 / 49000) loss: 1.088591
(Iteration 10151 / 49000) loss: 1.366646
(Iteration 10201 / 49000) loss: 1.396345
(Iteration 10251 / 49000) loss: 1.310450
(Iteration 10301 / 49000) loss: 1.082358
(Iteration 10351 / 49000) loss: 1.468901
(Iteration 10401 / 49000) loss: 1.035294
(Iteration 10451 / 49000) loss: 1.116229
(Iteration 10501 / 49000) loss: 1.189832
(Iteration 10551 / 49000) loss: 0.937404
(Iteration 10601 / 49000) loss: 1.077567
(Iteration 10651 / 49000) loss: 1.157977
(Iteration 10701 / 49000) loss: 0.984132
(Iteration 10751 / 49000) loss: 1.002818
(Epoch 11 / 50) train acc: 0.660000; val_acc: 0.557000
(Iteration 10801 / 49000) loss: 1.005552
(Iteration 10851 / 49000) loss: 0.930864
(Iteration 10901 / 49000) loss: 0.995114
(Iteration 10951 / 49000) loss: 1.037259
(Iteration 11001 / 49000) loss: 1.044499
(Iteration 11051 / 49000) loss: 1.322004
(Iteration 11101 / 49000) loss: 0.975333
(Iteration 11151 / 49000) loss: 1.059357
(Iteration 11201 / 49000) loss: 1.069419
(Iteration 11251 / 49000) loss: 1.065467
(Iteration 11301 / 49000) loss: 1.449887
(Iteration 11351 / 49000) loss: 1.063196
(Iteration 11401 / 49000) loss: 1.107822
(Iteration 11451 / 49000) loss: 1.269649
(Iteration 11501 / 49000) loss: 1.069562
(Iteration 11551 / 49000) loss: 1.107995
(Iteration 11601 / 49000) loss: 1.088867
(Iteration 11651 / 49000) loss: 1.047523
(Iteration 11701 / 49000) loss: 0.976437
(Iteration 11751 / 49000) loss: 1.122483
(Epoch 12 / 50) train acc: 0.658000; val_acc: 0.576000
(Iteration 11801 / 49000) loss: 1.077852
(Iteration 11851 / 49000) loss: 1.307103
(Iteration 11901 / 49000) loss: 1.032385
(Iteration 11951 / 49000) loss: 1.003825
(Iteration 12001 / 49000) loss: 1.321386
(Iteration 12051 / 49000) loss: 1.234769
(Iteration 12101 / 49000) loss: 1.167837
(Iteration 12151 / 49000) loss: 1.101869
(Iteration 12201 / 49000) loss: 1.301019
(Iteration 12251 / 49000) loss: 1.173139
(Iteration 12301 / 49000) loss: 1.268488
(Iteration 12351 / 49000) loss: 1.149070
(Iteration 12401 / 49000) loss: 1.033789
(Iteration 12451 / 49000) loss: 1.004097
(Iteration 12501 / 49000) loss: 1.285332
(Iteration 12551 / 49000) loss: 1.103033
(Iteration 12601 / 49000) loss: 1.117291
(Iteration 12651 / 49000) loss: 0.974972
(Iteration 12701 / 49000) loss: 1.001038
(Epoch 13 / 50) train acc: 0.687000; val_acc: 0.567000
(Iteration 12751 / 49000) loss: 1.404521
(Iteration 12801 / 49000) loss: 1.286862
(Iteration 12851 / 49000) loss: 1.057720
(Iteration 12901 / 49000) loss: 1.478313
(Iteration 12951 / 49000) loss: 1.164568
(Iteration 13001 / 49000) loss: 1.198542
(Iteration 13051 / 49000) loss: 0.811210
(Iteration 13101 / 49000) loss: 1.174809
(Iteration 13151 / 49000) loss: 1.330932
(Iteration 13201 / 49000) loss: 1.118305
(Iteration 13251 / 49000) loss: 1.060997
(Iteration 13301 / 49000) loss: 0.857701
(Iteration 13351 / 49000) loss: 0.907239
(Iteration 13401 / 49000) loss: 1.277165
(Iteration 13451 / 49000) loss: 1.125515
(Iteration 13501 / 49000) loss: 1.087443
(Iteration 13551 / 49000) loss: 0.874101
(Iteration 13601 / 49000) loss: 1.296034
(Iteration 13651 / 49000) loss: 1.041564
(Iteration 13701 / 49000) loss: 1.205032
(Epoch 14 / 50) train acc: 0.683000; val_acc: 0.568000
(Iteration 13751 / 49000) loss: 1.456212
(Iteration 13801 / 49000) loss: 0.740881
(Iteration 13851 / 49000) loss: 0.896069
(Iteration 13901 / 49000) loss: 1.029233
(Iteration 13951 / 49000) loss: 1.253983
(Iteration 14001 / 49000) loss: 0.965595
(Iteration 14051 / 49000) loss: 0.744661
(Iteration 14101 / 49000) loss: 1.147263
(Iteration 14151 / 49000) loss: 1.219837
(Iteration 14201 / 49000) loss: 1.282310
(Iteration 14251 / 49000) loss: 1.201628
(Iteration 14301 / 49000) loss: 1.050822
(Iteration 14351 / 49000) loss: 0.959800
(Iteration 14401 / 49000) loss: 0.987258
(Iteration 14451 / 49000) loss: 1.008169
(Iteration 14501 / 49000) loss: 1.194629
(Iteration 14551 / 49000) loss: 1.235548
(Iteration 14601 / 49000) loss: 1.026301
(Iteration 14651 / 49000) loss: 0.963702
(Epoch 15 / 50) train acc: 0.710000; val_acc: 0.583000
(Iteration 14701 / 49000) loss: 1.127988
(Iteration 14751 / 49000) loss: 1.315540
(Iteration 14801 / 49000) loss: 0.960485
(Iteration 14851 / 49000) loss: 1.206628
(Iteration 14901 / 49000) loss: 0.999071
(Iteration 14951 / 49000) loss: 1.057702
(Iteration 15001 / 49000) loss: 0.939451
(Iteration 15051 / 49000) loss: 1.147884
(Iteration 15101 / 49000) loss: 0.901932
(Iteration 15151 / 49000) loss: 1.147786
(Iteration 15201 / 49000) loss: 1.061930
(Iteration 15251 / 49000) loss: 1.085152
(Iteration 15301 / 49000) loss: 0.975392
(Iteration 15351 / 49000) loss: 1.079059
(Iteration 15401 / 49000) loss: 1.099315
(Iteration 15451 / 49000) loss: 0.986571
(Iteration 15501 / 49000) loss: 1.169004
(Iteration 15551 / 49000) loss: 0.937532
(Iteration 15601 / 49000) loss: 1.025629
(Iteration 15651 / 49000) loss: 0.744762
(Epoch 16 / 50) train acc: 0.718000; val_acc: 0.575000
(Iteration 15701 / 49000) loss: 1.013940
(Iteration 15751 / 49000) loss: 1.252898
(Iteration 15801 / 49000) loss: 1.169269
(Iteration 15851 / 49000) loss: 1.131732
(Iteration 15901 / 49000) loss: 0.945134
(Iteration 15951 / 49000) loss: 1.107200
(Iteration 16001 / 49000) loss: 1.041106
(Iteration 16051 / 49000) loss: 1.045952
(Iteration 16101 / 49000) loss: 0.811414
(Iteration 16151 / 49000) loss: 1.022289
(Iteration 16201 / 49000) loss: 1.000657
(Iteration 16251 / 49000) loss: 1.197875
(Iteration 16301 / 49000) loss: 1.050076
(Iteration 16351 / 49000) loss: 1.179629
(Iteration 16401 / 49000) loss: 0.930954
(Iteration 16451 / 49000) loss: 1.203609
(Iteration 16501 / 49000) loss: 1.160069
(Iteration 16551 / 49000) loss: 0.930865
(Iteration 16601 / 49000) loss: 1.041634
(Iteration 16651 / 49000) loss: 1.012812
(Epoch 17 / 50) train acc: 0.697000; val_acc: 0.572000
(Iteration 16701 / 49000) loss: 0.872604
(Iteration 16751 / 49000) loss: 0.946295
(Iteration 16801 / 49000) loss: 1.256506
(Iteration 16851 / 49000) loss: 0.960987
(Iteration 16901 / 49000) loss: 1.296044
(Iteration 16951 / 49000) loss: 1.074626
(Iteration 17001 / 49000) loss: 1.117265
(Iteration 17051 / 49000) loss: 1.345105
(Iteration 17101 / 49000) loss: 0.880004
(Iteration 17151 / 49000) loss: 1.206728
(Iteration 17201 / 49000) loss: 0.758604
(Iteration 17251 / 49000) loss: 1.157627
(Iteration 17301 / 49000) loss: 0.975036
(Iteration 17351 / 49000) loss: 1.098286
(Iteration 17401 / 49000) loss: 0.908502
(Iteration 17451 / 49000) loss: 0.987229
(Iteration 17501 / 49000) loss: 0.939911
(Iteration 17551 / 49000) loss: 0.799944
(Iteration 17601 / 49000) loss: 0.710779
(Epoch 18 / 50) train acc: 0.733000; val_acc: 0.568000
(Iteration 17651 / 49000) loss: 1.291306
(Iteration 17701 / 49000) loss: 1.022010
(Iteration 17751 / 49000) loss: 1.034792
(Iteration 17801 / 49000) loss: 1.043129
(Iteration 17851 / 49000) loss: 1.045075
(Iteration 17901 / 49000) loss: 1.035806
(Iteration 17951 / 49000) loss: 0.901174
(Iteration 18001 / 49000) loss: 0.912171
(Iteration 18051 / 49000) loss: 0.949819
(Iteration 18101 / 49000) loss: 1.058140
(Iteration 18151 / 49000) loss: 0.942359
(Iteration 18201 / 49000) loss: 1.084282
(Iteration 18251 / 49000) loss: 1.242639
(Iteration 18301 / 49000) loss: 0.930616
(Iteration 18351 / 49000) loss: 1.112874
(Iteration 18401 / 49000) loss: 1.133436
(Iteration 18451 / 49000) loss: 0.751559
(Iteration 18501 / 49000) loss: 1.445732
(Iteration 18551 / 49000) loss: 1.099610
(Iteration 18601 / 49000) loss: 0.763179
(Epoch 19 / 50) train acc: 0.717000; val_acc: 0.588000
(Iteration 18651 / 49000) loss: 1.073238
(Iteration 18701 / 49000) loss: 0.892085
(Iteration 18751 / 49000) loss: 1.020544
(Iteration 18801 / 49000) loss: 1.153309
(Iteration 18851 / 49000) loss: 0.964579
(Iteration 18901 / 49000) loss: 1.209240
(Iteration 18951 / 49000) loss: 1.168570
(Iteration 19001 / 49000) loss: 1.063285
(Iteration 19051 / 49000) loss: 0.956380
(Iteration 19101 / 49000) loss: 0.935322
(Iteration 19151 / 49000) loss: 0.921501
(Iteration 19201 / 49000) loss: 1.111249
(Iteration 19251 / 49000) loss: 1.101292
(Iteration 19301 / 49000) loss: 1.159165
(Iteration 19351 / 49000) loss: 1.128126
(Iteration 19401 / 49000) loss: 0.820931
(Iteration 19451 / 49000) loss: 0.728009
(Iteration 19501 / 49000) loss: 0.824115
(Iteration 19551 / 49000) loss: 1.040755
(Epoch 20 / 50) train acc: 0.738000; val_acc: 0.571000
(Iteration 19601 / 49000) loss: 0.946734
(Iteration 19651 / 49000) loss: 1.035249
(Iteration 19701 / 49000) loss: 0.744372
(Iteration 19751 / 49000) loss: 0.748689
(Iteration 19801 / 49000) loss: 1.002821
(Iteration 19851 / 49000) loss: 1.046371
(Iteration 19901 / 49000) loss: 0.861164
(Iteration 19951 / 49000) loss: 1.197996
(Iteration 20001 / 49000) loss: 0.914820
(Iteration 20051 / 49000) loss: 0.903004
(Iteration 20101 / 49000) loss: 1.021695
(Iteration 20151 / 49000) loss: 0.893812
(Iteration 20201 / 49000) loss: 1.019510
(Iteration 20251 / 49000) loss: 0.695977
(Iteration 20301 / 49000) loss: 0.821754
(Iteration 20351 / 49000) loss: 0.892735
(Iteration 20401 / 49000) loss: 0.712837
(Iteration 20451 / 49000) loss: 0.818269
(Iteration 20501 / 49000) loss: 1.031341
(Iteration 20551 / 49000) loss: 1.159947
(Epoch 21 / 50) train acc: 0.744000; val_acc: 0.579000
(Iteration 20601 / 49000) loss: 0.989032
(Iteration 20651 / 49000) loss: 0.898728
(Iteration 20701 / 49000) loss: 1.066509
(Iteration 20751 / 49000) loss: 0.984801
(Iteration 20801 / 49000) loss: 0.834176
(Iteration 20851 / 49000) loss: 0.856670
(Iteration 20901 / 49000) loss: 0.754916
(Iteration 20951 / 49000) loss: 1.056495
(Iteration 21001 / 49000) loss: 0.966057
(Iteration 21051 / 49000) loss: 0.589059
(Iteration 21101 / 49000) loss: 1.186099
(Iteration 21151 / 49000) loss: 1.116909
(Iteration 21201 / 49000) loss: 0.981230
(Iteration 21251 / 49000) loss: 0.962348
(Iteration 21301 / 49000) loss: 0.829865
(Iteration 21351 / 49000) loss: 1.096805
(Iteration 21401 / 49000) loss: 1.131833
(Iteration 21451 / 49000) loss: 1.005889
(Iteration 21501 / 49000) loss: 0.864069
(Iteration 21551 / 49000) loss: 0.707739
(Epoch 22 / 50) train acc: 0.737000; val_acc: 0.575000
(Iteration 21601 / 49000) loss: 0.962940
(Iteration 21651 / 49000) loss: 0.853945
(Iteration 21701 / 49000) loss: 1.191789
(Iteration 21751 / 49000) loss: 0.691513
(Iteration 21801 / 49000) loss: 1.068403
(Iteration 21851 / 49000) loss: 0.764169
(Iteration 21901 / 49000) loss: 0.719523
(Iteration 21951 / 49000) loss: 0.838636
(Iteration 22001 / 49000) loss: 1.043488
(Iteration 22051 / 49000) loss: 0.947846
(Iteration 22101 / 49000) loss: 0.944785
(Iteration 22151 / 49000) loss: 0.873176
(Iteration 22201 / 49000) loss: 0.868158
(Iteration 22251 / 49000) loss: 0.693121
(Iteration 22301 / 49000) loss: 1.078967
(Iteration 22351 / 49000) loss: 0.748071
(Iteration 22401 / 49000) loss: 1.018052
(Iteration 22451 / 49000) loss: 0.777345
(Iteration 22501 / 49000) loss: 1.120461
(Epoch 23 / 50) train acc: 0.764000; val_acc: 0.580000
(Iteration 22551 / 49000) loss: 0.926457
(Iteration 22601 / 49000) loss: 0.756428
(Iteration 22651 / 49000) loss: 1.019595
(Iteration 22701 / 49000) loss: 1.120488
(Iteration 22751 / 49000) loss: 1.041458
(Iteration 22801 / 49000) loss: 1.003585
(Iteration 22851 / 49000) loss: 0.950585
(Iteration 22901 / 49000) loss: 0.952323
(Iteration 22951 / 49000) loss: 1.064212
(Iteration 23001 / 49000) loss: 0.986235
(Iteration 23051 / 49000) loss: 0.985484
(Iteration 23101 / 49000) loss: 1.077573
(Iteration 23151 / 49000) loss: 1.105025
(Iteration 23201 / 49000) loss: 0.826438
(Iteration 23251 / 49000) loss: 0.864221
(Iteration 23301 / 49000) loss: 0.914300
(Iteration 23351 / 49000) loss: 1.106201
(Iteration 23401 / 49000) loss: 1.116481
(Iteration 23451 / 49000) loss: 0.721515
(Iteration 23501 / 49000) loss: 1.063256
(Epoch 24 / 50) train acc: 0.757000; val_acc: 0.575000
(Iteration 23551 / 49000) loss: 1.170680
(Iteration 23601 / 49000) loss: 0.798580
(Iteration 23651 / 49000) loss: 0.993308
(Iteration 23701 / 49000) loss: 0.867138
(Iteration 23751 / 49000) loss: 0.817084
(Iteration 23801 / 49000) loss: 1.283105
(Iteration 23851 / 49000) loss: 0.841738
(Iteration 23901 / 49000) loss: 0.840213
(Iteration 23951 / 49000) loss: 0.832965
(Iteration 24001 / 49000) loss: 0.628306
(Iteration 24051 / 49000) loss: 0.809978
(Iteration 24101 / 49000) loss: 1.013201
(Iteration 24151 / 49000) loss: 0.827347
(Iteration 24201 / 49000) loss: 0.932996
(Iteration 24251 / 49000) loss: 0.791744
(Iteration 24301 / 49000) loss: 0.767170
(Iteration 24351 / 49000) loss: 0.955920
(Iteration 24401 / 49000) loss: 0.761775
(Iteration 24451 / 49000) loss: 1.104784
(Epoch 25 / 50) train acc: 0.767000; val_acc: 0.572000
(Iteration 24501 / 49000) loss: 1.227162
(Iteration 24551 / 49000) loss: 1.091911
(Iteration 24601 / 49000) loss: 0.710837
(Iteration 24651 / 49000) loss: 0.848375
(Iteration 24701 / 49000) loss: 1.090732
(Iteration 24751 / 49000) loss: 0.785424
(Iteration 24801 / 49000) loss: 0.689765
(Iteration 24851 / 49000) loss: 1.272662
(Iteration 24901 / 49000) loss: 0.910732
(Iteration 24951 / 49000) loss: 0.858850
(Iteration 25001 / 49000) loss: 0.918534
(Iteration 25051 / 49000) loss: 0.898563
(Iteration 25101 / 49000) loss: 1.014446
(Iteration 25151 / 49000) loss: 1.071341
(Iteration 25201 / 49000) loss: 1.014710
(Iteration 25251 / 49000) loss: 0.687727
(Iteration 25301 / 49000) loss: 0.680336
(Iteration 25351 / 49000) loss: 1.040012
(Iteration 25401 / 49000) loss: 0.698307
(Iteration 25451 / 49000) loss: 0.759298
(Epoch 26 / 50) train acc: 0.792000; val_acc: 0.586000
(Iteration 25501 / 49000) loss: 0.677998
(Iteration 25551 / 49000) loss: 1.124310
(Iteration 25601 / 49000) loss: 0.932494
(Iteration 25651 / 49000) loss: 0.810671
(Iteration 25701 / 49000) loss: 1.055513
(Iteration 25751 / 49000) loss: 0.669814
(Iteration 25801 / 49000) loss: 1.040228
(Iteration 25851 / 49000) loss: 1.004000
(Iteration 25901 / 49000) loss: 0.796249
(Iteration 25951 / 49000) loss: 0.507013
(Iteration 26001 / 49000) loss: 0.982686
(Iteration 26051 / 49000) loss: 0.826737
(Iteration 26101 / 49000) loss: 0.674451
(Iteration 26151 / 49000) loss: 1.123365
(Iteration 26201 / 49000) loss: 0.630185
(Iteration 26251 / 49000) loss: 0.870778
(Iteration 26301 / 49000) loss: 0.835975
(Iteration 26351 / 49000) loss: 0.876641
(Iteration 26401 / 49000) loss: 0.952694
(Iteration 26451 / 49000) loss: 1.054279
(Epoch 27 / 50) train acc: 0.762000; val_acc: 0.577000
(Iteration 26501 / 49000) loss: 1.273579
(Iteration 26551 / 49000) loss: 0.736403
(Iteration 26601 / 49000) loss: 0.728225
(Iteration 26651 / 49000) loss: 0.717475
(Iteration 26701 / 49000) loss: 0.905779
(Iteration 26751 / 49000) loss: 0.900205
(Iteration 26801 / 49000) loss: 1.063895
(Iteration 26851 / 49000) loss: 0.917169
(Iteration 26901 / 49000) loss: 0.791661
(Iteration 26951 / 49000) loss: 0.881772
(Iteration 27001 / 49000) loss: 0.999449
(Iteration 27051 / 49000) loss: 0.900634
(Iteration 27101 / 49000) loss: 0.989091
(Iteration 27151 / 49000) loss: 1.102289
(Iteration 27201 / 49000) loss: 0.608149
(Iteration 27251 / 49000) loss: 0.949975
(Iteration 27301 / 49000) loss: 1.118473
(Iteration 27351 / 49000) loss: 0.877606
(Iteration 27401 / 49000) loss: 0.786933
(Epoch 28 / 50) train acc: 0.775000; val_acc: 0.586000
(Iteration 27451 / 49000) loss: 0.725376
(Iteration 27501 / 49000) loss: 0.946553
(Iteration 27551 / 49000) loss: 0.719731
(Iteration 27601 / 49000) loss: 0.890433
(Iteration 27651 / 49000) loss: 1.096625
(Iteration 27701 / 49000) loss: 0.637042
(Iteration 27751 / 49000) loss: 0.891309
(Iteration 27801 / 49000) loss: 0.960596
(Iteration 27851 / 49000) loss: 1.103607
(Iteration 27901 / 49000) loss: 0.666145
(Iteration 27951 / 49000) loss: 0.969367
(Iteration 28001 / 49000) loss: 0.712406
(Iteration 28051 / 49000) loss: 0.835260
(Iteration 28101 / 49000) loss: 0.906029
(Iteration 28151 / 49000) loss: 0.980709
(Iteration 28201 / 49000) loss: 1.069366
(Iteration 28251 / 49000) loss: 0.770823
(Iteration 28301 / 49000) loss: 0.640515
(Iteration 28351 / 49000) loss: 1.332858
(Iteration 28401 / 49000) loss: 1.084422
(Epoch 29 / 50) train acc: 0.769000; val_acc: 0.582000
(Iteration 28451 / 49000) loss: 0.997769
(Iteration 28501 / 49000) loss: 0.901479
(Iteration 28551 / 49000) loss: 1.064677
(Iteration 28601 / 49000) loss: 0.765999
(Iteration 28651 / 49000) loss: 1.191292
(Iteration 28701 / 49000) loss: 0.586133
(Iteration 28751 / 49000) loss: 1.058559
(Iteration 28801 / 49000) loss: 1.279509
(Iteration 28851 / 49000) loss: 0.676252
(Iteration 28901 / 49000) loss: 0.793564
(Iteration 28951 / 49000) loss: 1.226114
(Iteration 29001 / 49000) loss: 1.057772
(Iteration 29051 / 49000) loss: 0.861847
(Iteration 29101 / 49000) loss: 1.126434
(Iteration 29151 / 49000) loss: 0.943021
(Iteration 29201 / 49000) loss: 0.941463
(Iteration 29251 / 49000) loss: 0.886508
(Iteration 29301 / 49000) loss: 0.666401
(Iteration 29351 / 49000) loss: 0.860902
(Epoch 30 / 50) train acc: 0.757000; val_acc: 0.584000
(Iteration 29401 / 49000) loss: 1.047978
(Iteration 29451 / 49000) loss: 0.619350
(Iteration 29501 / 49000) loss: 1.203325
(Iteration 29551 / 49000) loss: 0.875222
(Iteration 29601 / 49000) loss: 0.736892
(Iteration 29651 / 49000) loss: 0.982013
(Iteration 29701 / 49000) loss: 0.901773
(Iteration 29751 / 49000) loss: 0.680212
(Iteration 29801 / 49000) loss: 0.708090
(Iteration 29851 / 49000) loss: 1.033470
(Iteration 29901 / 49000) loss: 0.946957
(Iteration 29951 / 49000) loss: 1.076656
(Iteration 30001 / 49000) loss: 0.831111
(Iteration 30051 / 49000) loss: 1.145751
(Iteration 30101 / 49000) loss: 0.776725
(Iteration 30151 / 49000) loss: 1.001198
(Iteration 30201 / 49000) loss: 0.681599
(Iteration 30251 / 49000) loss: 1.106854
(Iteration 30301 / 49000) loss: 1.093979
(Iteration 30351 / 49000) loss: 1.100613
(Epoch 31 / 50) train acc: 0.772000; val_acc: 0.584000
(Iteration 30401 / 49000) loss: 0.622893
(Iteration 30451 / 49000) loss: 1.105571
(Iteration 30501 / 49000) loss: 0.978332
(Iteration 30551 / 49000) loss: 1.020525
(Iteration 30601 / 49000) loss: 0.742912
(Iteration 30651 / 49000) loss: 0.870273
(Iteration 30701 / 49000) loss: 1.008716
(Iteration 30751 / 49000) loss: 0.675142
(Iteration 30801 / 49000) loss: 0.696504
(Iteration 30851 / 49000) loss: 0.969475
(Iteration 30901 / 49000) loss: 1.067145
(Iteration 30951 / 49000) loss: 0.955518
(Iteration 31001 / 49000) loss: 1.153574
(Iteration 31051 / 49000) loss: 0.786669
(Iteration 31101 / 49000) loss: 0.764691
(Iteration 31151 / 49000) loss: 0.900953
(Iteration 31201 / 49000) loss: 1.212396
(Iteration 31251 / 49000) loss: 0.585159
(Iteration 31301 / 49000) loss: 0.779533
(Iteration 31351 / 49000) loss: 0.847944
(Epoch 32 / 50) train acc: 0.783000; val_acc: 0.580000
(Iteration 31401 / 49000) loss: 0.989738
(Iteration 31451 / 49000) loss: 0.937619
(Iteration 31501 / 49000) loss: 0.817774
(Iteration 31551 / 49000) loss: 1.121728
(Iteration 31601 / 49000) loss: 0.866360
(Iteration 31651 / 49000) loss: 1.001585
(Iteration 31701 / 49000) loss: 0.748526
(Iteration 31751 / 49000) loss: 0.737764
(Iteration 31801 / 49000) loss: 0.795215
(Iteration 31851 / 49000) loss: 0.728560
(Iteration 31901 / 49000) loss: 0.935722
(Iteration 31951 / 49000) loss: 0.641908
(Iteration 32001 / 49000) loss: 0.730694
(Iteration 32051 / 49000) loss: 0.886020
(Iteration 32101 / 49000) loss: 0.962125
(Iteration 32151 / 49000) loss: 0.917411
(Iteration 32201 / 49000) loss: 0.830859
(Iteration 32251 / 49000) loss: 0.875297
(Iteration 32301 / 49000) loss: 0.962368
(Epoch 33 / 50) train acc: 0.791000; val_acc: 0.584000
(Iteration 32351 / 49000) loss: 0.620188
(Iteration 32401 / 49000) loss: 0.949495
(Iteration 32451 / 49000) loss: 0.809588
(Iteration 32501 / 49000) loss: 1.133756
(Iteration 32551 / 49000) loss: 0.687084
(Iteration 32601 / 49000) loss: 0.891712
(Iteration 32651 / 49000) loss: 1.049707
(Iteration 32701 / 49000) loss: 1.231830
(Iteration 32751 / 49000) loss: 0.753751
(Iteration 32801 / 49000) loss: 1.153975
(Iteration 32851 / 49000) loss: 0.733286
(Iteration 32901 / 49000) loss: 1.032189
(Iteration 32951 / 49000) loss: 0.712577
(Iteration 33001 / 49000) loss: 0.807792
(Iteration 33051 / 49000) loss: 0.775247
(Iteration 33101 / 49000) loss: 0.703887
(Iteration 33151 / 49000) loss: 1.036480
(Iteration 33201 / 49000) loss: 0.563868
(Iteration 33251 / 49000) loss: 0.904566
(Iteration 33301 / 49000) loss: 0.716526
(Epoch 34 / 50) train acc: 0.769000; val_acc: 0.582000
(Iteration 33351 / 49000) loss: 1.091862
(Iteration 33401 / 49000) loss: 1.397810
(Iteration 33451 / 49000) loss: 0.973245
(Iteration 33501 / 49000) loss: 0.942442
(Iteration 33551 / 49000) loss: 0.542438
(Iteration 33601 / 49000) loss: 1.041627
(Iteration 33651 / 49000) loss: 1.045621
(Iteration 33701 / 49000) loss: 1.221822
(Iteration 33751 / 49000) loss: 0.565287
(Iteration 33801 / 49000) loss: 0.905118
(Iteration 33851 / 49000) loss: 0.794660
(Iteration 33901 / 49000) loss: 1.143139
(Iteration 33951 / 49000) loss: 0.974656
(Iteration 34001 / 49000) loss: 0.797497
(Iteration 34051 / 49000) loss: 1.131721
(Iteration 34101 / 49000) loss: 0.994617
(Iteration 34151 / 49000) loss: 1.037054
(Iteration 34201 / 49000) loss: 1.261219
(Iteration 34251 / 49000) loss: 1.158999
(Epoch 35 / 50) train acc: 0.773000; val_acc: 0.578000
(Iteration 34301 / 49000) loss: 1.151574
(Iteration 34351 / 49000) loss: 0.966122
(Iteration 34401 / 49000) loss: 0.903176
(Iteration 34451 / 49000) loss: 0.949020
(Iteration 34501 / 49000) loss: 0.898164
(Iteration 34551 / 49000) loss: 0.899737
(Iteration 34601 / 49000) loss: 0.851876
(Iteration 34651 / 49000) loss: 1.040772
(Iteration 34701 / 49000) loss: 0.809364
(Iteration 34751 / 49000) loss: 0.725182
(Iteration 34801 / 49000) loss: 1.080139
(Iteration 34851 / 49000) loss: 0.881932
(Iteration 34901 / 49000) loss: 1.073557
(Iteration 34951 / 49000) loss: 0.668372
(Iteration 35001 / 49000) loss: 0.765981
(Iteration 35051 / 49000) loss: 0.851496
(Iteration 35101 / 49000) loss: 0.890611
(Iteration 35151 / 49000) loss: 0.992909
(Iteration 35201 / 49000) loss: 0.768872
(Iteration 35251 / 49000) loss: 0.938973
(Epoch 36 / 50) train acc: 0.794000; val_acc: 0.581000
(Iteration 35301 / 49000) loss: 0.818439
(Iteration 35351 / 49000) loss: 0.695879
(Iteration 35401 / 49000) loss: 1.055613
(Iteration 35451 / 49000) loss: 0.921273
(Iteration 35501 / 49000) loss: 0.892503
(Iteration 35551 / 49000) loss: 0.778963
(Iteration 35601 / 49000) loss: 1.070835
(Iteration 35651 / 49000) loss: 0.571258
(Iteration 35701 / 49000) loss: 0.767490
(Iteration 35751 / 49000) loss: 0.740719
(Iteration 35801 / 49000) loss: 0.879570
(Iteration 35851 / 49000) loss: 0.878957
(Iteration 35901 / 49000) loss: 0.777137
(Iteration 35951 / 49000) loss: 0.878284
(Iteration 36001 / 49000) loss: 1.331581
(Iteration 36051 / 49000) loss: 0.822488
(Iteration 36101 / 49000) loss: 0.990357
(Iteration 36151 / 49000) loss: 0.987732
(Iteration 36201 / 49000) loss: 0.791342
(Iteration 36251 / 49000) loss: 0.718688
(Epoch 37 / 50) train acc: 0.778000; val_acc: 0.581000
(Iteration 36301 / 49000) loss: 0.813947
(Iteration 36351 / 49000) loss: 0.694693
(Iteration 36401 / 49000) loss: 0.854766
(Iteration 36451 / 49000) loss: 0.745976
(Iteration 36501 / 49000) loss: 0.741874
(Iteration 36551 / 49000) loss: 1.019209
(Iteration 36601 / 49000) loss: 0.798387
(Iteration 36651 / 49000) loss: 0.847119
(Iteration 36701 / 49000) loss: 0.832265
(Iteration 36751 / 49000) loss: 0.886309
(Iteration 36801 / 49000) loss: 0.840941
(Iteration 36851 / 49000) loss: 0.770766
(Iteration 36901 / 49000) loss: 0.661027
(Iteration 36951 / 49000) loss: 0.694797
(Iteration 37001 / 49000) loss: 0.822801
(Iteration 37051 / 49000) loss: 0.857440
(Iteration 37101 / 49000) loss: 1.024988
(Iteration 37151 / 49000) loss: 0.774203
(Iteration 37201 / 49000) loss: 1.036191
(Epoch 38 / 50) train acc: 0.792000; val_acc: 0.586000
(Iteration 37251 / 49000) loss: 0.791985
(Iteration 37301 / 49000) loss: 0.623317
(Iteration 37351 / 49000) loss: 0.817930
(Iteration 37401 / 49000) loss: 0.750822
(Iteration 37451 / 49000) loss: 0.918513
(Iteration 37501 / 49000) loss: 0.846930
(Iteration 37551 / 49000) loss: 0.760967
(Iteration 37601 / 49000) loss: 0.867609
(Iteration 37651 / 49000) loss: 0.723252
(Iteration 37701 / 49000) loss: 0.771936
(Iteration 37751 / 49000) loss: 0.786652
(Iteration 37801 / 49000) loss: 0.678701
(Iteration 37851 / 49000) loss: 1.034705
(Iteration 37901 / 49000) loss: 0.886084
(Iteration 37951 / 49000) loss: 0.913318
(Iteration 38001 / 49000) loss: 1.114156
(Iteration 38051 / 49000) loss: 0.585342
(Iteration 38101 / 49000) loss: 1.060885
(Iteration 38151 / 49000) loss: 0.929162
(Iteration 38201 / 49000) loss: 0.764729
(Epoch 39 / 50) train acc: 0.793000; val_acc: 0.589000
(Iteration 38251 / 49000) loss: 0.818618
(Iteration 38301 / 49000) loss: 0.734295
(Iteration 38351 / 49000) loss: 1.035574
(Iteration 38401 / 49000) loss: 1.036749
(Iteration 38451 / 49000) loss: 0.903316
(Iteration 38501 / 49000) loss: 0.883242
(Iteration 38551 / 49000) loss: 0.791559
(Iteration 38601 / 49000) loss: 0.769013
(Iteration 38651 / 49000) loss: 0.835848
(Iteration 38701 / 49000) loss: 0.737559
(Iteration 38751 / 49000) loss: 1.071037
(Iteration 38801 / 49000) loss: 0.745341
(Iteration 38851 / 49000) loss: 0.947839
(Iteration 38901 / 49000) loss: 0.753231
(Iteration 38951 / 49000) loss: 1.157403
(Iteration 39001 / 49000) loss: 0.895777
(Iteration 39051 / 49000) loss: 1.117224
(Iteration 39101 / 49000) loss: 0.732059
(Iteration 39151 / 49000) loss: 0.788024
(Epoch 40 / 50) train acc: 0.798000; val_acc: 0.580000
(Iteration 39201 / 49000) loss: 0.979750
(Iteration 39251 / 49000) loss: 0.687752
(Iteration 39301 / 49000) loss: 0.902880
(Iteration 39351 / 49000) loss: 0.826088
(Iteration 39401 / 49000) loss: 0.852803
(Iteration 39451 / 49000) loss: 0.847881
(Iteration 39501 / 49000) loss: 0.828623
(Iteration 39551 / 49000) loss: 0.783737
(Iteration 39601 / 49000) loss: 0.883752
(Iteration 39651 / 49000) loss: 0.791959
(Iteration 39701 / 49000) loss: 0.764393
(Iteration 39751 / 49000) loss: 0.891598
(Iteration 39801 / 49000) loss: 0.764413
(Iteration 39851 / 49000) loss: 0.622991
(Iteration 39901 / 49000) loss: 0.944001
(Iteration 39951 / 49000) loss: 0.913063
(Iteration 40001 / 49000) loss: 0.993933
(Iteration 40051 / 49000) loss: 1.071245
(Iteration 40101 / 49000) loss: 0.712843
(Iteration 40151 / 49000) loss: 0.844135
(Epoch 41 / 50) train acc: 0.799000; val_acc: 0.588000
(Iteration 40201 / 49000) loss: 0.767869
(Iteration 40251 / 49000) loss: 0.758172
(Iteration 40301 / 49000) loss: 0.921919
(Iteration 40351 / 49000) loss: 0.660575
(Iteration 40401 / 49000) loss: 0.863397
(Iteration 40451 / 49000) loss: 0.839895
(Iteration 40501 / 49000) loss: 0.694638
(Iteration 40551 / 49000) loss: 1.060995
(Iteration 40601 / 49000) loss: 0.847079
(Iteration 40651 / 49000) loss: 0.773607
(Iteration 40701 / 49000) loss: 0.812404
(Iteration 40751 / 49000) loss: 0.559080
(Iteration 40801 / 49000) loss: 0.882968
(Iteration 40851 / 49000) loss: 0.807729
(Iteration 40901 / 49000) loss: 0.813112
(Iteration 40951 / 49000) loss: 0.919336
(Iteration 41001 / 49000) loss: 0.865038
(Iteration 41051 / 49000) loss: 0.968009
(Iteration 41101 / 49000) loss: 0.781923
(Iteration 41151 / 49000) loss: 0.990628
(Epoch 42 / 50) train acc: 0.797000; val_acc: 0.587000
(Iteration 41201 / 49000) loss: 0.839855
(Iteration 41251 / 49000) loss: 0.651790
(Iteration 41301 / 49000) loss: 0.774065
(Iteration 41351 / 49000) loss: 0.936186
(Iteration 41401 / 49000) loss: 0.951234
(Iteration 41451 / 49000) loss: 0.783872
(Iteration 41501 / 49000) loss: 0.861278
(Iteration 41551 / 49000) loss: 0.883499
(Iteration 41601 / 49000) loss: 0.884476
(Iteration 41651 / 49000) loss: 0.791361
(Iteration 41701 / 49000) loss: 0.934998
(Iteration 41751 / 49000) loss: 0.978570
(Iteration 41801 / 49000) loss: 0.835665
(Iteration 41851 / 49000) loss: 0.815422
(Iteration 41901 / 49000) loss: 0.764346
(Iteration 41951 / 49000) loss: 1.141720
(Iteration 42001 / 49000) loss: 1.170560
(Iteration 42051 / 49000) loss: 0.917193
(Iteration 42101 / 49000) loss: 0.866482
(Epoch 43 / 50) train acc: 0.783000; val_acc: 0.588000
(Iteration 42151 / 49000) loss: 0.744960
(Iteration 42201 / 49000) loss: 0.833926
(Iteration 42251 / 49000) loss: 0.922819
(Iteration 42301 / 49000) loss: 0.598274
(Iteration 42351 / 49000) loss: 0.853175
(Iteration 42401 / 49000) loss: 1.008583
(Iteration 42451 / 49000) loss: 0.712714
(Iteration 42501 / 49000) loss: 0.809849
(Iteration 42551 / 49000) loss: 1.211139
(Iteration 42601 / 49000) loss: 0.963548
(Iteration 42651 / 49000) loss: 0.791350
(Iteration 42701 / 49000) loss: 1.139188
(Iteration 42751 / 49000) loss: 1.073242
(Iteration 42801 / 49000) loss: 0.768305
(Iteration 42851 / 49000) loss: 0.496552
(Iteration 42901 / 49000) loss: 0.905962
(Iteration 42951 / 49000) loss: 0.816644
(Iteration 43001 / 49000) loss: 0.652648
(Iteration 43051 / 49000) loss: 1.235401
(Iteration 43101 / 49000) loss: 0.880112
(Epoch 44 / 50) train acc: 0.800000; val_acc: 0.591000
(Iteration 43151 / 49000) loss: 0.979212
(Iteration 43201 / 49000) loss: 0.882501
(Iteration 43251 / 49000) loss: 0.770896
(Iteration 43301 / 49000) loss: 0.915501
(Iteration 43351 / 49000) loss: 0.676829
(Iteration 43401 / 49000) loss: 0.695275
(Iteration 43451 / 49000) loss: 1.104820
(Iteration 43501 / 49000) loss: 1.047784
(Iteration 43551 / 49000) loss: 0.757488
(Iteration 43601 / 49000) loss: 0.658202
(Iteration 43651 / 49000) loss: 0.881696
(Iteration 43701 / 49000) loss: 0.797220
(Iteration 43751 / 49000) loss: 0.830906
(Iteration 43801 / 49000) loss: 0.917316
(Iteration 43851 / 49000) loss: 1.045717
(Iteration 43901 / 49000) loss: 1.064929
(Iteration 43951 / 49000) loss: 0.988735
(Iteration 44001 / 49000) loss: 0.991260
(Iteration 44051 / 49000) loss: 0.754560
(Epoch 45 / 50) train acc: 0.786000; val_acc: 0.586000
(Iteration 44101 / 49000) loss: 0.822893
(Iteration 44151 / 49000) loss: 0.950443
(Iteration 44201 / 49000) loss: 0.646287
(Iteration 44251 / 49000) loss: 1.185039
(Iteration 44301 / 49000) loss: 0.697368
(Iteration 44351 / 49000) loss: 0.990992
(Iteration 44401 / 49000) loss: 0.975702
(Iteration 44451 / 49000) loss: 0.999594
(Iteration 44501 / 49000) loss: 0.651019
(Iteration 44551 / 49000) loss: 0.830565
(Iteration 44601 / 49000) loss: 0.877288
(Iteration 44651 / 49000) loss: 1.012928
(Iteration 44701 / 49000) loss: 0.733283
(Iteration 44751 / 49000) loss: 0.735907
(Iteration 44801 / 49000) loss: 0.703307
(Iteration 44851 / 49000) loss: 0.749859
(Iteration 44901 / 49000) loss: 0.740669
(Iteration 44951 / 49000) loss: 0.831010
(Iteration 45001 / 49000) loss: 0.830779
(Iteration 45051 / 49000) loss: 1.030038
(Epoch 46 / 50) train acc: 0.781000; val_acc: 0.590000
(Iteration 45101 / 49000) loss: 0.584377
(Iteration 45151 / 49000) loss: 0.814157
(Iteration 45201 / 49000) loss: 0.757169
(Iteration 45251 / 49000) loss: 0.612084
(Iteration 45301 / 49000) loss: 0.707468
(Iteration 45351 / 49000) loss: 0.783724
(Iteration 45401 / 49000) loss: 0.769492
(Iteration 45451 / 49000) loss: 1.030138
(Iteration 45501 / 49000) loss: 0.864866
(Iteration 45551 / 49000) loss: 0.655129
(Iteration 45601 / 49000) loss: 0.745857
(Iteration 45651 / 49000) loss: 1.063597
(Iteration 45701 / 49000) loss: 1.031998
(Iteration 45751 / 49000) loss: 0.825156
(Iteration 45801 / 49000) loss: 0.700718
(Iteration 45851 / 49000) loss: 0.836591
(Iteration 45901 / 49000) loss: 0.847171
(Iteration 45951 / 49000) loss: 0.999296
(Iteration 46001 / 49000) loss: 0.603887
(Iteration 46051 / 49000) loss: 1.217624
(Epoch 47 / 50) train acc: 0.789000; val_acc: 0.584000
(Iteration 46101 / 49000) loss: 0.737743
(Iteration 46151 / 49000) loss: 0.668117
(Iteration 46201 / 49000) loss: 0.845008
(Iteration 46251 / 49000) loss: 0.844042
(Iteration 46301 / 49000) loss: 0.946027
(Iteration 46351 / 49000) loss: 0.841060
(Iteration 46401 / 49000) loss: 0.967467
(Iteration 46451 / 49000) loss: 0.754346
(Iteration 46501 / 49000) loss: 0.649678
(Iteration 46551 / 49000) loss: 0.822742
(Iteration 46601 / 49000) loss: 0.774665
(Iteration 46651 / 49000) loss: 0.678583
(Iteration 46701 / 49000) loss: 0.947903
(Iteration 46751 / 49000) loss: 0.832089
(Iteration 46801 / 49000) loss: 0.893367
(Iteration 46851 / 49000) loss: 0.841834
(Iteration 46901 / 49000) loss: 0.954908
(Iteration 46951 / 49000) loss: 0.607865
(Iteration 47001 / 49000) loss: 1.029407
(Epoch 48 / 50) train acc: 0.808000; val_acc: 0.582000
(Iteration 47051 / 49000) loss: 0.847946
(Iteration 47101 / 49000) loss: 0.622557
(Iteration 47151 / 49000) loss: 0.895105
(Iteration 47201 / 49000) loss: 1.100442
(Iteration 47251 / 49000) loss: 0.989006
(Iteration 47301 / 49000) loss: 1.140270
(Iteration 47351 / 49000) loss: 0.662569
(Iteration 47401 / 49000) loss: 0.742061
(Iteration 47451 / 49000) loss: 0.795283
(Iteration 47501 / 49000) loss: 1.030373
(Iteration 47551 / 49000) loss: 0.805241
(Iteration 47601 / 49000) loss: 0.714323
(Iteration 47651 / 49000) loss: 0.883418
(Iteration 47701 / 49000) loss: 0.819312
(Iteration 47751 / 49000) loss: 0.954509
(Iteration 47801 / 49000) loss: 0.771641
(Iteration 47851 / 49000) loss: 0.970537
(Iteration 47901 / 49000) loss: 0.940454
(Iteration 47951 / 49000) loss: 0.752000
(Iteration 48001 / 49000) loss: 1.073947
(Epoch 49 / 50) train acc: 0.782000; val_acc: 0.585000
(Iteration 48051 / 49000) loss: 0.724797
(Iteration 48101 / 49000) loss: 0.849353
(Iteration 48151 / 49000) loss: 1.039984
(Iteration 48201 / 49000) loss: 0.563094
(Iteration 48251 / 49000) loss: 1.002955
(Iteration 48301 / 49000) loss: 1.096116
(Iteration 48351 / 49000) loss: 0.833075
(Iteration 48401 / 49000) loss: 0.739758
(Iteration 48451 / 49000) loss: 0.929814
(Iteration 48501 / 49000) loss: 0.792158
(Iteration 48551 / 49000) loss: 0.842197
(Iteration 48601 / 49000) loss: 0.796823
(Iteration 48651 / 49000) loss: 0.811510
(Iteration 48701 / 49000) loss: 0.878447
(Iteration 48751 / 49000) loss: 0.778400
(Iteration 48801 / 49000) loss: 0.573821
(Iteration 48851 / 49000) loss: 0.693065
(Iteration 48901 / 49000) loss: 1.006898
(Iteration 48951 / 49000) loss: 0.614721
(Epoch 50 / 50) train acc: 0.799000; val_acc: 0.589000