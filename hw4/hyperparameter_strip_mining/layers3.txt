layer_dims = [600, 600, 600]
weight_scale = 0.01
learning_rate = 1e-3
lr_decay = 0.90

model = FullyConnectedNet(layer_dims, weight_scale=weight_scale,
                          dropout=0.65, reg=0.0, use_batchnorm=True)

solver = Solver(model, data,
                num_epochs=50, batch_size=100,
                update_rule='adam',
                optim_config={
                  'learning_rate': learning_rate,
                },
                lr_decay=lr_decay,
                verbose=True, print_every=50)
solver.train()

(Iteration 1 / 24500) loss: 2.307665
(Epoch 0 / 50) train acc: 0.218000; val_acc: 0.211000
(Iteration 51 / 24500) loss: 1.702725
(Iteration 101 / 24500) loss: 1.727139
(Iteration 151 / 24500) loss: 1.683345
(Iteration 201 / 24500) loss: 1.659260
(Iteration 251 / 24500) loss: 1.812540
(Iteration 301 / 24500) loss: 1.530135
(Iteration 351 / 24500) loss: 1.493582
(Iteration 401 / 24500) loss: 1.762015
(Iteration 451 / 24500) loss: 1.590167
(Epoch 1 / 50) train acc: 0.481000; val_acc: 0.471000
(Iteration 501 / 24500) loss: 1.549113
(Iteration 551 / 24500) loss: 1.467584
(Iteration 601 / 24500) loss: 1.358084
(Iteration 651 / 24500) loss: 1.404995
(Iteration 701 / 24500) loss: 1.406404
(Iteration 751 / 24500) loss: 1.472001
(Iteration 801 / 24500) loss: 1.435366
(Iteration 851 / 24500) loss: 1.468695
(Iteration 901 / 24500) loss: 1.340725
(Iteration 951 / 24500) loss: 1.411392
(Epoch 2 / 50) train acc: 0.498000; val_acc: 0.497000
(Iteration 1001 / 24500) loss: 1.533172
(Iteration 1051 / 24500) loss: 1.309217
(Iteration 1101 / 24500) loss: 1.354464
(Iteration 1151 / 24500) loss: 1.339861
(Iteration 1201 / 24500) loss: 1.269913
(Iteration 1251 / 24500) loss: 1.402783
(Iteration 1301 / 24500) loss: 1.498409
(Iteration 1351 / 24500) loss: 1.274302
(Iteration 1401 / 24500) loss: 1.529729
(Iteration 1451 / 24500) loss: 1.490684
(Epoch 3 / 50) train acc: 0.559000; val_acc: 0.510000
(Iteration 1501 / 24500) loss: 1.301126
(Iteration 1551 / 24500) loss: 1.339719
(Iteration 1601 / 24500) loss: 1.192021
(Iteration 1651 / 24500) loss: 1.215498
(Iteration 1701 / 24500) loss: 1.300178
(Iteration 1751 / 24500) loss: 1.357205
(Iteration 1801 / 24500) loss: 1.347261
(Iteration 1851 / 24500) loss: 1.463178
(Iteration 1901 / 24500) loss: 1.425699
(Iteration 1951 / 24500) loss: 1.269606
(Epoch 4 / 50) train acc: 0.580000; val_acc: 0.542000
(Iteration 2001 / 24500) loss: 1.392325
(Iteration 2051 / 24500) loss: 1.352256
(Iteration 2101 / 24500) loss: 1.418270
(Iteration 2151 / 24500) loss: 1.265919
(Iteration 2201 / 24500) loss: 1.246150
(Iteration 2251 / 24500) loss: 1.294663
(Iteration 2301 / 24500) loss: 1.220733
(Iteration 2351 / 24500) loss: 1.426055
(Iteration 2401 / 24500) loss: 1.213786
(Epoch 5 / 50) train acc: 0.577000; val_acc: 0.526000
(Iteration 2451 / 24500) loss: 1.127094
(Iteration 2501 / 24500) loss: 1.161409
(Iteration 2551 / 24500) loss: 1.362147
(Iteration 2601 / 24500) loss: 1.233347
(Iteration 2651 / 24500) loss: 1.097272
(Iteration 2701 / 24500) loss: 1.144164
(Iteration 2751 / 24500) loss: 1.250656
(Iteration 2801 / 24500) loss: 1.199618
(Iteration 2851 / 24500) loss: 1.084097
(Iteration 2901 / 24500) loss: 1.268059
(Epoch 6 / 50) train acc: 0.620000; val_acc: 0.558000
(Iteration 2951 / 24500) loss: 1.273696
(Iteration 3001 / 24500) loss: 1.226255
(Iteration 3051 / 24500) loss: 1.195465
(Iteration 3101 / 24500) loss: 1.225128
(Iteration 3151 / 24500) loss: 1.159493
(Iteration 3201 / 24500) loss: 1.133028
(Iteration 3251 / 24500) loss: 1.137095
(Iteration 3301 / 24500) loss: 1.103974
(Iteration 3351 / 24500) loss: 1.180212
(Iteration 3401 / 24500) loss: 1.136137
(Epoch 7 / 50) train acc: 0.652000; val_acc: 0.569000
(Iteration 3451 / 24500) loss: 1.250208
(Iteration 3501 / 24500) loss: 1.357012
(Iteration 3551 / 24500) loss: 1.239599
(Iteration 3601 / 24500) loss: 1.004816
(Iteration 3651 / 24500) loss: 1.197298
(Iteration 3701 / 24500) loss: 1.193207
(Iteration 3751 / 24500) loss: 1.181140
(Iteration 3801 / 24500) loss: 0.952122
(Iteration 3851 / 24500) loss: 1.326147
(Iteration 3901 / 24500) loss: 1.061781
(Epoch 8 / 50) train acc: 0.641000; val_acc: 0.567000
(Iteration 3951 / 24500) loss: 1.153845
(Iteration 4001 / 24500) loss: 1.174085
(Iteration 4051 / 24500) loss: 1.316962
(Iteration 4101 / 24500) loss: 1.169460
(Iteration 4151 / 24500) loss: 1.154510
(Iteration 4201 / 24500) loss: 1.004538
(Iteration 4251 / 24500) loss: 1.155829
(Iteration 4301 / 24500) loss: 0.981991
(Iteration 4351 / 24500) loss: 1.199506
(Iteration 4401 / 24500) loss: 1.113970
(Epoch 9 / 50) train acc: 0.657000; val_acc: 0.588000
(Iteration 4451 / 24500) loss: 1.273731
(Iteration 4501 / 24500) loss: 1.241264
(Iteration 4551 / 24500) loss: 1.153949
(Iteration 4601 / 24500) loss: 1.236600
(Iteration 4651 / 24500) loss: 1.035293
(Iteration 4701 / 24500) loss: 1.091569
(Iteration 4751 / 24500) loss: 0.979862
(Iteration 4801 / 24500) loss: 0.986284
(Iteration 4851 / 24500) loss: 1.096334
(Epoch 10 / 50) train acc: 0.674000; val_acc: 0.574000
(Iteration 4901 / 24500) loss: 0.977250
(Iteration 4951 / 24500) loss: 1.067247
(Iteration 5001 / 24500) loss: 1.259068
(Iteration 5051 / 24500) loss: 1.185173
(Iteration 5101 / 24500) loss: 1.104361
(Iteration 5151 / 24500) loss: 1.143070
(Iteration 5201 / 24500) loss: 0.929852
(Iteration 5251 / 24500) loss: 1.080387
(Iteration 5301 / 24500) loss: 1.062354
(Iteration 5351 / 24500) loss: 1.120345
(Epoch 11 / 50) train acc: 0.653000; val_acc: 0.580000
(Iteration 5401 / 24500) loss: 1.189580
(Iteration 5451 / 24500) loss: 1.142039
(Iteration 5501 / 24500) loss: 0.905623
(Iteration 5551 / 24500) loss: 1.066666
(Iteration 5601 / 24500) loss: 0.885622
(Iteration 5651 / 24500) loss: 0.985579
(Iteration 5701 / 24500) loss: 1.193834
(Iteration 5751 / 24500) loss: 0.855383
(Iteration 5801 / 24500) loss: 1.069249
(Iteration 5851 / 24500) loss: 0.999601
(Epoch 12 / 50) train acc: 0.699000; val_acc: 0.584000
(Iteration 5901 / 24500) loss: 1.193555
(Iteration 5951 / 24500) loss: 0.951300
(Iteration 6001 / 24500) loss: 1.032092
(Iteration 6051 / 24500) loss: 1.019809
(Iteration 6101 / 24500) loss: 1.055615
(Iteration 6151 / 24500) loss: 0.976617
(Iteration 6201 / 24500) loss: 0.987988
(Iteration 6251 / 24500) loss: 0.906280
(Iteration 6301 / 24500) loss: 1.132942
(Iteration 6351 / 24500) loss: 0.923605
(Epoch 13 / 50) train acc: 0.731000; val_acc: 0.588000
(Iteration 6401 / 24500) loss: 1.002203
(Iteration 6451 / 24500) loss: 1.239366
(Iteration 6501 / 24500) loss: 0.940348
(Iteration 6551 / 24500) loss: 0.956499
(Iteration 6601 / 24500) loss: 1.151259
(Iteration 6651 / 24500) loss: 1.038209
(Iteration 6701 / 24500) loss: 0.901215
(Iteration 6751 / 24500) loss: 0.825951
(Iteration 6801 / 24500) loss: 0.981335
(Iteration 6851 / 24500) loss: 1.056345
(Epoch 14 / 50) train acc: 0.693000; val_acc: 0.595000
(Iteration 6901 / 24500) loss: 0.936599
(Iteration 6951 / 24500) loss: 0.903431
(Iteration 7001 / 24500) loss: 1.066046
(Iteration 7051 / 24500) loss: 0.876764
(Iteration 7101 / 24500) loss: 1.151598
(Iteration 7151 / 24500) loss: 0.973788
(Iteration 7201 / 24500) loss: 1.001788
(Iteration 7251 / 24500) loss: 1.034890
(Iteration 7301 / 24500) loss: 1.094122
(Epoch 15 / 50) train acc: 0.737000; val_acc: 0.590000
(Iteration 7351 / 24500) loss: 0.912804
(Iteration 7401 / 24500) loss: 1.079788
(Iteration 7451 / 24500) loss: 0.817398
(Iteration 7501 / 24500) loss: 0.897146
(Iteration 7551 / 24500) loss: 0.843887
(Iteration 7601 / 24500) loss: 0.966686
(Iteration 7651 / 24500) loss: 0.988726
(Iteration 7701 / 24500) loss: 0.864921
(Iteration 7751 / 24500) loss: 1.040469
(Iteration 7801 / 24500) loss: 1.103523
(Epoch 16 / 50) train acc: 0.742000; val_acc: 0.592000
(Iteration 7851 / 24500) loss: 0.760546
(Iteration 7901 / 24500) loss: 1.052837
(Iteration 7951 / 24500) loss: 0.964191
(Iteration 8001 / 24500) loss: 0.737952
(Iteration 8051 / 24500) loss: 0.998011
(Iteration 8101 / 24500) loss: 0.994718
(Iteration 8151 / 24500) loss: 0.961766
(Iteration 8201 / 24500) loss: 1.028996
(Iteration 8251 / 24500) loss: 0.932263
(Iteration 8301 / 24500) loss: 0.818917
(Epoch 17 / 50) train acc: 0.733000; val_acc: 0.592000
(Iteration 8351 / 24500) loss: 0.935765
(Iteration 8401 / 24500) loss: 0.972055
(Iteration 8451 / 24500) loss: 0.802818
(Iteration 8501 / 24500) loss: 0.942082
(Iteration 8551 / 24500) loss: 1.004612
(Iteration 8601 / 24500) loss: 0.841242
(Iteration 8651 / 24500) loss: 0.963557
(Iteration 8701 / 24500) loss: 0.783328
(Iteration 8751 / 24500) loss: 0.971621
(Iteration 8801 / 24500) loss: 1.086847
(Epoch 18 / 50) train acc: 0.753000; val_acc: 0.586000
(Iteration 8851 / 24500) loss: 1.235479
(Iteration 8901 / 24500) loss: 0.805035
(Iteration 8951 / 24500) loss: 1.093279
(Iteration 9001 / 24500) loss: 1.209931
(Iteration 9051 / 24500) loss: 0.909657
(Iteration 9101 / 24500) loss: 0.945337
(Iteration 9151 / 24500) loss: 0.861684
(Iteration 9201 / 24500) loss: 1.059726
(Iteration 9251 / 24500) loss: 0.823627
(Iteration 9301 / 24500) loss: 1.131233
(Epoch 19 / 50) train acc: 0.772000; val_acc: 0.603000
(Iteration 9351 / 24500) loss: 0.733806
(Iteration 9401 / 24500) loss: 0.918141
(Iteration 9451 / 24500) loss: 0.730579
(Iteration 9501 / 24500) loss: 0.870627
(Iteration 9551 / 24500) loss: 0.878450
(Iteration 9601 / 24500) loss: 0.924281
(Iteration 9651 / 24500) loss: 0.953334
(Iteration 9701 / 24500) loss: 0.916326
(Iteration 9751 / 24500) loss: 1.115789
(Epoch 20 / 50) train acc: 0.769000; val_acc: 0.598000
(Iteration 9801 / 24500) loss: 0.799326
(Iteration 9851 / 24500) loss: 0.735689
(Iteration 9901 / 24500) loss: 0.835623
(Iteration 9951 / 24500) loss: 0.727150
(Iteration 10001 / 24500) loss: 0.933716
(Iteration 10051 / 24500) loss: 0.892943
(Iteration 10101 / 24500) loss: 0.929026
(Iteration 10151 / 24500) loss: 0.745446
(Iteration 10201 / 24500) loss: 1.019129
(Iteration 10251 / 24500) loss: 0.826068
(Epoch 21 / 50) train acc: 0.765000; val_acc: 0.595000
(Iteration 10301 / 24500) loss: 0.958850
(Iteration 10351 / 24500) loss: 0.854591
(Iteration 10401 / 24500) loss: 0.836778
(Iteration 10451 / 24500) loss: 0.943491
(Iteration 10501 / 24500) loss: 0.846978
(Iteration 10551 / 24500) loss: 0.974357
(Iteration 10601 / 24500) loss: 1.200270
(Iteration 10651 / 24500) loss: 0.803545
(Iteration 10701 / 24500) loss: 0.974386
(Iteration 10751 / 24500) loss: 0.828824
(Epoch 22 / 50) train acc: 0.781000; val_acc: 0.603000
(Iteration 10801 / 24500) loss: 0.854328
(Iteration 10851 / 24500) loss: 0.875416
(Iteration 10901 / 24500) loss: 0.938431
(Iteration 10951 / 24500) loss: 0.945153
(Iteration 11001 / 24500) loss: 0.731454
(Iteration 11051 / 24500) loss: 1.057713
(Iteration 11101 / 24500) loss: 0.626463
(Iteration 11151 / 24500) loss: 0.791515
(Iteration 11201 / 24500) loss: 0.914552
(Iteration 11251 / 24500) loss: 0.858319
(Epoch 23 / 50) train acc: 0.759000; val_acc: 0.592000
(Iteration 11301 / 24500) loss: 0.865450
(Iteration 11351 / 24500) loss: 0.732142
(Iteration 11401 / 24500) loss: 0.837305
(Iteration 11451 / 24500) loss: 0.981817
(Iteration 11501 / 24500) loss: 0.739515
(Iteration 11551 / 24500) loss: 0.936961
(Iteration 11601 / 24500) loss: 0.776481
(Iteration 11651 / 24500) loss: 0.855214
(Iteration 11701 / 24500) loss: 0.863737
(Iteration 11751 / 24500) loss: 0.940887
(Epoch 24 / 50) train acc: 0.757000; val_acc: 0.604000
(Iteration 11801 / 24500) loss: 0.768751
(Iteration 11851 / 24500) loss: 0.736815
(Iteration 11901 / 24500) loss: 0.854679
(Iteration 11951 / 24500) loss: 0.831082
(Iteration 12001 / 24500) loss: 1.003204
(Iteration 12051 / 24500) loss: 0.901287
(Iteration 12101 / 24500) loss: 0.923383
(Iteration 12151 / 24500) loss: 1.018381
(Iteration 12201 / 24500) loss: 0.770087
(Epoch 25 / 50) train acc: 0.770000; val_acc: 0.611000
(Iteration 12251 / 24500) loss: 0.650286
(Iteration 12301 / 24500) loss: 0.887848
(Iteration 12351 / 24500) loss: 0.835026
(Iteration 12401 / 24500) loss: 0.604384
(Iteration 12451 / 24500) loss: 0.847335
(Iteration 12501 / 24500) loss: 0.931260
(Iteration 12551 / 24500) loss: 0.965290
(Iteration 12601 / 24500) loss: 0.821087
(Iteration 12651 / 24500) loss: 0.758346
(Iteration 12701 / 24500) loss: 0.754879
(Epoch 26 / 50) train acc: 0.793000; val_acc: 0.607000
(Iteration 12751 / 24500) loss: 0.759679
(Iteration 12801 / 24500) loss: 0.773063
(Iteration 12851 / 24500) loss: 0.812144
(Iteration 12901 / 24500) loss: 0.795069
(Iteration 12951 / 24500) loss: 0.699076
(Iteration 13001 / 24500) loss: 0.724184
(Iteration 13051 / 24500) loss: 0.848268
(Iteration 13101 / 24500) loss: 0.873953
(Iteration 13151 / 24500) loss: 0.806013
(Iteration 13201 / 24500) loss: 0.755225
(Epoch 27 / 50) train acc: 0.787000; val_acc: 0.584000
(Iteration 13251 / 24500) loss: 0.843232
(Iteration 13301 / 24500) loss: 0.729172
(Iteration 13351 / 24500) loss: 0.749362
(Iteration 13401 / 24500) loss: 1.226320
(Iteration 13451 / 24500) loss: 0.937669
(Iteration 13501 / 24500) loss: 0.666967
(Iteration 13551 / 24500) loss: 0.717130
(Iteration 13601 / 24500) loss: 0.808029
(Iteration 13651 / 24500) loss: 0.965448
(Iteration 13701 / 24500) loss: 0.799111
(Epoch 28 / 50) train acc: 0.796000; val_acc: 0.591000
(Iteration 13751 / 24500) loss: 0.765610
(Iteration 13801 / 24500) loss: 0.737703
(Iteration 13851 / 24500) loss: 0.645854
(Iteration 13901 / 24500) loss: 0.928808
(Iteration 13951 / 24500) loss: 0.810480
(Iteration 14001 / 24500) loss: 0.923733
(Iteration 14051 / 24500) loss: 0.832328
(Iteration 14101 / 24500) loss: 0.790565
(Iteration 14151 / 24500) loss: 0.770740
(Iteration 14201 / 24500) loss: 0.751804
(Epoch 29 / 50) train acc: 0.796000; val_acc: 0.595000
(Iteration 14251 / 24500) loss: 0.768051
(Iteration 14301 / 24500) loss: 0.960649
(Iteration 14351 / 24500) loss: 1.109810
(Iteration 14401 / 24500) loss: 1.137656
(Iteration 14451 / 24500) loss: 1.036922
(Iteration 14501 / 24500) loss: 0.785795
(Iteration 14551 / 24500) loss: 0.825356
(Iteration 14601 / 24500) loss: 0.904250
(Iteration 14651 / 24500) loss: 0.779149
(Epoch 30 / 50) train acc: 0.818000; val_acc: 0.595000
(Iteration 14701 / 24500) loss: 0.709679
(Iteration 14751 / 24500) loss: 0.901563
(Iteration 14801 / 24500) loss: 0.717789
(Iteration 14851 / 24500) loss: 0.754827
(Iteration 14901 / 24500) loss: 0.827983
(Iteration 14951 / 24500) loss: 0.749853
(Iteration 15001 / 24500) loss: 0.739967
(Iteration 15051 / 24500) loss: 0.895393
(Iteration 15101 / 24500) loss: 0.790240
(Iteration 15151 / 24500) loss: 0.750347
(Epoch 31 / 50) train acc: 0.803000; val_acc: 0.597000
(Iteration 15201 / 24500) loss: 0.733555
(Iteration 15251 / 24500) loss: 0.739904
(Iteration 15301 / 24500) loss: 0.769878
(Iteration 15351 / 24500) loss: 0.989148
(Iteration 15401 / 24500) loss: 0.826409
(Iteration 15451 / 24500) loss: 0.632337
(Iteration 15501 / 24500) loss: 0.882621
(Iteration 15551 / 24500) loss: 0.904137
(Iteration 15601 / 24500) loss: 0.877893
(Iteration 15651 / 24500) loss: 0.879626
(Epoch 32 / 50) train acc: 0.815000; val_acc: 0.589000
(Iteration 15701 / 24500) loss: 0.890850
(Iteration 15751 / 24500) loss: 0.795136
(Iteration 15801 / 24500) loss: 0.814669
(Iteration 15851 / 24500) loss: 0.784038
(Iteration 15901 / 24500) loss: 0.878412
(Iteration 15951 / 24500) loss: 0.690842
(Iteration 16001 / 24500) loss: 0.796688
(Iteration 16051 / 24500) loss: 0.732190
(Iteration 16101 / 24500) loss: 0.855603
(Iteration 16151 / 24500) loss: 0.851530
(Epoch 33 / 50) train acc: 0.809000; val_acc: 0.594000
(Iteration 16201 / 24500) loss: 0.661218
(Iteration 16251 / 24500) loss: 0.752720
(Iteration 16301 / 24500) loss: 1.002601
(Iteration 16351 / 24500) loss: 0.693271
(Iteration 16401 / 24500) loss: 0.779841
(Iteration 16451 / 24500) loss: 0.724717
(Iteration 16501 / 24500) loss: 0.628695
(Iteration 16551 / 24500) loss: 0.779485
(Iteration 16601 / 24500) loss: 0.706491
(Iteration 16651 / 24500) loss: 0.865262
(Epoch 34 / 50) train acc: 0.793000; val_acc: 0.587000
(Iteration 16701 / 24500) loss: 0.800246
(Iteration 16751 / 24500) loss: 0.814687
(Iteration 16801 / 24500) loss: 0.807773
(Iteration 16851 / 24500) loss: 0.820443
(Iteration 16901 / 24500) loss: 0.764815
(Iteration 16951 / 24500) loss: 0.860548
(Iteration 17001 / 24500) loss: 0.699615
(Iteration 17051 / 24500) loss: 0.799499
(Iteration 17101 / 24500) loss: 0.816831
(Epoch 35 / 50) train acc: 0.797000; val_acc: 0.585000
(Iteration 17151 / 24500) loss: 0.948783
(Iteration 17201 / 24500) loss: 0.886370
(Iteration 17251 / 24500) loss: 0.762666
(Iteration 17301 / 24500) loss: 0.971233
(Iteration 17351 / 24500) loss: 0.866212
(Iteration 17401 / 24500) loss: 0.762629
(Iteration 17451 / 24500) loss: 0.861595
(Iteration 17501 / 24500) loss: 0.778464
(Iteration 17551 / 24500) loss: 0.947296
(Iteration 17601 / 24500) loss: 0.766165
(Epoch 36 / 50) train acc: 0.790000; val_acc: 0.594000
(Iteration 17651 / 24500) loss: 0.749025
(Iteration 17701 / 24500) loss: 0.667286
(Iteration 17751 / 24500) loss: 0.746351
(Iteration 17801 / 24500) loss: 0.855089
(Iteration 17851 / 24500) loss: 0.666911
(Iteration 17901 / 24500) loss: 0.723863
(Iteration 17951 / 24500) loss: 0.667703
(Iteration 18001 / 24500) loss: 0.727731
(Iteration 18051 / 24500) loss: 0.840314
(Iteration 18101 / 24500) loss: 0.634378
(Epoch 37 / 50) train acc: 0.832000; val_acc: 0.599000
(Iteration 18151 / 24500) loss: 0.726697
(Iteration 18201 / 24500) loss: 0.772507
(Iteration 18251 / 24500) loss: 1.003306
(Iteration 18301 / 24500) loss: 0.804873
(Iteration 18351 / 24500) loss: 0.821690
(Iteration 18401 / 24500) loss: 0.667730
(Iteration 18451 / 24500) loss: 0.734711
(Iteration 18501 / 24500) loss: 0.858003
(Iteration 18551 / 24500) loss: 0.817136
(Iteration 18601 / 24500) loss: 0.623981
(Epoch 38 / 50) train acc: 0.807000; val_acc: 0.596000
(Iteration 18651 / 24500) loss: 0.714593
(Iteration 18701 / 24500) loss: 0.899254
(Iteration 18751 / 24500) loss: 0.766738
(Iteration 18801 / 24500) loss: 0.736605
(Iteration 18851 / 24500) loss: 0.704550
(Iteration 18901 / 24500) loss: 0.785194
(Iteration 18951 / 24500) loss: 0.977804
(Iteration 19001 / 24500) loss: 0.808810
(Iteration 19051 / 24500) loss: 0.764587
(Iteration 19101 / 24500) loss: 0.542315
(Epoch 39 / 50) train acc: 0.803000; val_acc: 0.600000
(Iteration 19151 / 24500) loss: 0.915812
(Iteration 19201 / 24500) loss: 0.737270
(Iteration 19251 / 24500) loss: 0.810892
(Iteration 19301 / 24500) loss: 0.838027
(Iteration 19351 / 24500) loss: 0.883371
(Iteration 19401 / 24500) loss: 0.915605
(Iteration 19451 / 24500) loss: 0.647154
(Iteration 19501 / 24500) loss: 0.909947
(Iteration 19551 / 24500) loss: 0.848992
(Epoch 40 / 50) train acc: 0.819000; val_acc: 0.593000
(Iteration 19601 / 24500) loss: 0.977120
(Iteration 19651 / 24500) loss: 0.846315
(Iteration 19701 / 24500) loss: 0.683971
(Iteration 19751 / 24500) loss: 0.704095
(Iteration 19801 / 24500) loss: 0.809678
(Iteration 19851 / 24500) loss: 0.759861
(Iteration 19901 / 24500) loss: 0.867576
(Iteration 19951 / 24500) loss: 0.961735
(Iteration 20001 / 24500) loss: 0.852597
(Iteration 20051 / 24500) loss: 0.645409
(Epoch 41 / 50) train acc: 0.824000; val_acc: 0.596000
(Iteration 20101 / 24500) loss: 0.769706
(Iteration 20151 / 24500) loss: 0.867802
(Iteration 20201 / 24500) loss: 0.508569
(Iteration 20251 / 24500) loss: 0.699426
(Iteration 20301 / 24500) loss: 0.770103
(Iteration 20351 / 24500) loss: 0.821487
(Iteration 20401 / 24500) loss: 0.632451
(Iteration 20451 / 24500) loss: 0.773421
(Iteration 20501 / 24500) loss: 0.747580
(Iteration 20551 / 24500) loss: 0.919461
(Epoch 42 / 50) train acc: 0.824000; val_acc: 0.597000
(Iteration 20601 / 24500) loss: 0.732947
(Iteration 20651 / 24500) loss: 0.696255
(Iteration 20701 / 24500) loss: 0.756591
(Iteration 20751 / 24500) loss: 0.803770
(Iteration 20801 / 24500) loss: 0.802183
(Iteration 20851 / 24500) loss: 0.726099
(Iteration 20901 / 24500) loss: 0.695212
(Iteration 20951 / 24500) loss: 0.842782
(Iteration 21001 / 24500) loss: 0.929020
(Iteration 21051 / 24500) loss: 0.741268
(Epoch 43 / 50) train acc: 0.815000; val_acc: 0.600000
(Iteration 21101 / 24500) loss: 0.710464
(Iteration 21151 / 24500) loss: 0.913860
(Iteration 21201 / 24500) loss: 0.798912
(Iteration 21251 / 24500) loss: 0.568645
(Iteration 21301 / 24500) loss: 0.915158
(Iteration 21351 / 24500) loss: 0.699759
(Iteration 21401 / 24500) loss: 0.686282
(Iteration 21451 / 24500) loss: 0.772953
(Iteration 21501 / 24500) loss: 0.641875
(Iteration 21551 / 24500) loss: 0.842919
(Epoch 44 / 50) train acc: 0.823000; val_acc: 0.595000
(Iteration 21601 / 24500) loss: 0.750376
(Iteration 21651 / 24500) loss: 0.659477
(Iteration 21701 / 24500) loss: 0.769181
(Iteration 21751 / 24500) loss: 0.784940
(Iteration 21801 / 24500) loss: 0.728687
(Iteration 21851 / 24500) loss: 0.804645
(Iteration 21901 / 24500) loss: 0.745923
(Iteration 21951 / 24500) loss: 0.891810
(Iteration 22001 / 24500) loss: 0.869945
(Epoch 45 / 50) train acc: 0.846000; val_acc: 0.595000
(Iteration 22051 / 24500) loss: 0.663189
(Iteration 22101 / 24500) loss: 0.758273
(Iteration 22151 / 24500) loss: 0.753013
(Iteration 22201 / 24500) loss: 0.671727
(Iteration 22251 / 24500) loss: 0.981797
(Iteration 22301 / 24500) loss: 0.892782
(Iteration 22351 / 24500) loss: 0.772247
(Iteration 22401 / 24500) loss: 0.852581
(Iteration 22451 / 24500) loss: 0.554259
(Iteration 22501 / 24500) loss: 0.939617
(Epoch 46 / 50) train acc: 0.819000; val_acc: 0.598000
(Iteration 22551 / 24500) loss: 0.690073
(Iteration 22601 / 24500) loss: 0.823178
(Iteration 22651 / 24500) loss: 0.590782
(Iteration 22701 / 24500) loss: 0.701738
(Iteration 22751 / 24500) loss: 0.699561
(Iteration 22801 / 24500) loss: 0.638788
(Iteration 22851 / 24500) loss: 0.717734
(Iteration 22901 / 24500) loss: 1.039665
(Iteration 22951 / 24500) loss: 0.979459
(Iteration 23001 / 24500) loss: 0.635732
(Epoch 47 / 50) train acc: 0.833000; val_acc: 0.598000
(Iteration 23051 / 24500) loss: 0.932321
(Iteration 23101 / 24500) loss: 1.016718
(Iteration 23151 / 24500) loss: 0.676269
(Iteration 23201 / 24500) loss: 0.700117
(Iteration 23251 / 24500) loss: 0.842888
(Iteration 23301 / 24500) loss: 0.700405
(Iteration 23351 / 24500) loss: 0.838012
(Iteration 23401 / 24500) loss: 0.783945
(Iteration 23451 / 24500) loss: 0.928726
(Iteration 23501 / 24500) loss: 0.741190
(Epoch 48 / 50) train acc: 0.831000; val_acc: 0.599000
(Iteration 23551 / 24500) loss: 0.735267
(Iteration 23601 / 24500) loss: 0.760831
(Iteration 23651 / 24500) loss: 0.920821
(Iteration 23701 / 24500) loss: 0.905145
(Iteration 23751 / 24500) loss: 0.699308
(Iteration 23801 / 24500) loss: 0.919812
(Iteration 23851 / 24500) loss: 0.719435
(Iteration 23901 / 24500) loss: 0.670679
(Iteration 23951 / 24500) loss: 0.852591
(Iteration 24001 / 24500) loss: 0.729417
(Epoch 49 / 50) train acc: 0.801000; val_acc: 0.597000
(Iteration 24051 / 24500) loss: 0.822034
(Iteration 24101 / 24500) loss: 0.572277
(Iteration 24151 / 24500) loss: 0.650333
(Iteration 24201 / 24500) loss: 0.745454
(Iteration 24251 / 24500) loss: 0.711938
(Iteration 24301 / 24500) loss: 0.807465
(Iteration 24351 / 24500) loss: 0.682472
(Iteration 24401 / 24500) loss: 0.837068
(Iteration 24451 / 24500) loss: 0.639879
(Epoch 50 / 50) train acc: 0.830000; val_acc: 0.596000