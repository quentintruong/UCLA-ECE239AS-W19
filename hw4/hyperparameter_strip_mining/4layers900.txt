layer_dims = [900, 900, 900, 900]
weight_scale = 0.01
learning_rate = 1e-3
lr_decay = 0.90

model = FullyConnectedNet(layer_dims, weight_scale=weight_scale,
                          dropout=0.65, reg=0.0, use_batchnorm=True)

solver = Solver(model, data,
                num_epochs=50, batch_size=100,
                update_rule='adam',
                optim_config={
                  'learning_rate': learning_rate,
                },
                lr_decay=lr_decay,
                verbose=True, print_every=50)
solver.train()

(Iteration 1 / 24500) loss: 2.330976
(Epoch 0 / 50) train acc: 0.208000; val_acc: 0.188000
(Iteration 51 / 24500) loss: 1.925053
(Iteration 101 / 24500) loss: 1.625962
(Iteration 151 / 24500) loss: 1.707308
(Iteration 201 / 24500) loss: 1.596903
(Iteration 251 / 24500) loss: 1.667930
(Iteration 301 / 24500) loss: 1.543986
(Iteration 351 / 24500) loss: 1.819236
(Iteration 401 / 24500) loss: 1.689836
(Iteration 451 / 24500) loss: 1.827407
(Epoch 1 / 50) train acc: 0.443000; val_acc: 0.472000
(Iteration 501 / 24500) loss: 1.538082
(Iteration 551 / 24500) loss: 1.606946
(Iteration 601 / 24500) loss: 1.472935
(Iteration 651 / 24500) loss: 1.510835
(Iteration 701 / 24500) loss: 1.515305
(Iteration 751 / 24500) loss: 1.381062
(Iteration 801 / 24500) loss: 1.448919
(Iteration 851 / 24500) loss: 1.502336
(Iteration 901 / 24500) loss: 1.688889
(Iteration 951 / 24500) loss: 1.298651
(Epoch 2 / 50) train acc: 0.501000; val_acc: 0.502000
(Iteration 1001 / 24500) loss: 1.598791
(Iteration 1051 / 24500) loss: 1.502806
(Iteration 1101 / 24500) loss: 1.590494
(Iteration 1151 / 24500) loss: 1.385877
(Iteration 1201 / 24500) loss: 1.483013
(Iteration 1251 / 24500) loss: 1.371992
(Iteration 1301 / 24500) loss: 1.530830
(Iteration 1351 / 24500) loss: 1.458737
(Iteration 1401 / 24500) loss: 1.341419
(Iteration 1451 / 24500) loss: 1.331244
(Epoch 3 / 50) train acc: 0.543000; val_acc: 0.524000
(Iteration 1501 / 24500) loss: 1.311878
(Iteration 1551 / 24500) loss: 1.419547
(Iteration 1601 / 24500) loss: 1.538969
(Iteration 1651 / 24500) loss: 1.381324
(Iteration 1701 / 24500) loss: 1.405796
(Iteration 1751 / 24500) loss: 1.275455
(Iteration 1801 / 24500) loss: 1.250065
(Iteration 1851 / 24500) loss: 1.454532
(Iteration 1901 / 24500) loss: 1.413939
(Iteration 1951 / 24500) loss: 1.305130
(Epoch 4 / 50) train acc: 0.593000; val_acc: 0.525000
(Iteration 2001 / 24500) loss: 1.401362
(Iteration 2051 / 24500) loss: 1.189772
(Iteration 2101 / 24500) loss: 1.174630
(Iteration 2151 / 24500) loss: 1.282710
(Iteration 2201 / 24500) loss: 1.162232
(Iteration 2251 / 24500) loss: 1.349225
(Iteration 2301 / 24500) loss: 1.342656
(Iteration 2351 / 24500) loss: 1.037812
(Iteration 2401 / 24500) loss: 1.130372
(Epoch 5 / 50) train acc: 0.606000; val_acc: 0.549000
(Iteration 2451 / 24500) loss: 1.175054
(Iteration 2501 / 24500) loss: 1.261253
(Iteration 2551 / 24500) loss: 1.231458
(Iteration 2601 / 24500) loss: 1.100433
(Iteration 2651 / 24500) loss: 1.259087
(Iteration 2701 / 24500) loss: 1.392324
(Iteration 2751 / 24500) loss: 1.205585
(Iteration 2801 / 24500) loss: 1.284325
(Iteration 2851 / 24500) loss: 1.301639
(Iteration 2901 / 24500) loss: 1.159091
(Epoch 6 / 50) train acc: 0.589000; val_acc: 0.544000
(Iteration 2951 / 24500) loss: 1.459319
(Iteration 3001 / 24500) loss: 1.185311
(Iteration 3051 / 24500) loss: 1.249436
(Iteration 3101 / 24500) loss: 1.202236
(Iteration 3151 / 24500) loss: 1.332980
(Iteration 3201 / 24500) loss: 1.370233
(Iteration 3251 / 24500) loss: 1.268033
(Iteration 3301 / 24500) loss: 1.226144
(Iteration 3351 / 24500) loss: 1.030312
(Iteration 3401 / 24500) loss: 1.213873
(Epoch 7 / 50) train acc: 0.645000; val_acc: 0.571000
(Iteration 3451 / 24500) loss: 1.405277
(Iteration 3501 / 24500) loss: 1.096086
(Iteration 3551 / 24500) loss: 1.052872
(Iteration 3601 / 24500) loss: 1.105696
(Iteration 3651 / 24500) loss: 1.139007
(Iteration 3701 / 24500) loss: 1.050780
(Iteration 3751 / 24500) loss: 0.986980
(Iteration 3801 / 24500) loss: 1.171208
(Iteration 3851 / 24500) loss: 1.152593
(Iteration 3901 / 24500) loss: 1.016397
(Epoch 8 / 50) train acc: 0.638000; val_acc: 0.570000
(Iteration 3951 / 24500) loss: 1.306332
(Iteration 4001 / 24500) loss: 1.094700
(Iteration 4051 / 24500) loss: 1.000872
(Iteration 4101 / 24500) loss: 1.153575
(Iteration 4151 / 24500) loss: 1.432839
(Iteration 4201 / 24500) loss: 1.015638
(Iteration 4251 / 24500) loss: 1.111442
(Iteration 4301 / 24500) loss: 1.363256
(Iteration 4351 / 24500) loss: 1.063336
(Iteration 4401 / 24500) loss: 1.132292
(Epoch 9 / 50) train acc: 0.675000; val_acc: 0.563000
(Iteration 4451 / 24500) loss: 1.091540
(Iteration 4501 / 24500) loss: 1.155588
(Iteration 4551 / 24500) loss: 1.141772
(Iteration 4601 / 24500) loss: 0.976197
(Iteration 4651 / 24500) loss: 1.005505
(Iteration 4701 / 24500) loss: 0.886152
(Iteration 4751 / 24500) loss: 0.989018
(Iteration 4801 / 24500) loss: 0.946693
(Iteration 4851 / 24500) loss: 1.124177
(Epoch 10 / 50) train acc: 0.669000; val_acc: 0.555000
(Iteration 4901 / 24500) loss: 1.174504
(Iteration 4951 / 24500) loss: 0.944905
(Iteration 5001 / 24500) loss: 0.914822
(Iteration 5051 / 24500) loss: 1.020887
(Iteration 5101 / 24500) loss: 1.037446
(Iteration 5151 / 24500) loss: 1.024712
(Iteration 5201 / 24500) loss: 1.176835
(Iteration 5251 / 24500) loss: 1.132606
(Iteration 5301 / 24500) loss: 1.207702
(Iteration 5351 / 24500) loss: 1.010996
(Epoch 11 / 50) train acc: 0.693000; val_acc: 0.574000
(Iteration 5401 / 24500) loss: 1.140459
(Iteration 5451 / 24500) loss: 1.225536
(Iteration 5501 / 24500) loss: 1.170802
(Iteration 5551 / 24500) loss: 1.173492
(Iteration 5601 / 24500) loss: 0.950158
(Iteration 5651 / 24500) loss: 0.900127
(Iteration 5701 / 24500) loss: 1.107116
(Iteration 5751 / 24500) loss: 0.831589
(Iteration 5801 / 24500) loss: 1.005258
(Iteration 5851 / 24500) loss: 1.008674
(Epoch 12 / 50) train acc: 0.713000; val_acc: 0.584000
(Iteration 5901 / 24500) loss: 0.952891
(Iteration 5951 / 24500) loss: 1.005972
(Iteration 6001 / 24500) loss: 0.920058
(Iteration 6051 / 24500) loss: 1.099421
(Iteration 6101 / 24500) loss: 0.767372
(Iteration 6151 / 24500) loss: 0.891006
(Iteration 6201 / 24500) loss: 1.050443
(Iteration 6251 / 24500) loss: 0.990198
(Iteration 6301 / 24500) loss: 1.083387
(Iteration 6351 / 24500) loss: 1.084005
(Epoch 13 / 50) train acc: 0.698000; val_acc: 0.580000
(Iteration 6401 / 24500) loss: 1.074428
(Iteration 6451 / 24500) loss: 1.108103
(Iteration 6501 / 24500) loss: 0.844648
(Iteration 6551 / 24500) loss: 1.001722
(Iteration 6601 / 24500) loss: 0.938238
(Iteration 6651 / 24500) loss: 1.011276
(Iteration 6701 / 24500) loss: 0.879509
(Iteration 6751 / 24500) loss: 0.947224
(Iteration 6801 / 24500) loss: 0.732002
(Iteration 6851 / 24500) loss: 0.907882
(Epoch 14 / 50) train acc: 0.735000; val_acc: 0.583000
(Iteration 6901 / 24500) loss: 0.860336
(Iteration 6951 / 24500) loss: 0.921589
(Iteration 7001 / 24500) loss: 0.775429
(Iteration 7051 / 24500) loss: 1.031986
(Iteration 7101 / 24500) loss: 0.896548
(Iteration 7151 / 24500) loss: 0.820528
(Iteration 7201 / 24500) loss: 0.860033
(Iteration 7251 / 24500) loss: 0.899395
(Iteration 7301 / 24500) loss: 0.731638
(Epoch 15 / 50) train acc: 0.745000; val_acc: 0.584000
(Iteration 7351 / 24500) loss: 1.139155
(Iteration 7401 / 24500) loss: 0.822768
(Iteration 7451 / 24500) loss: 0.856590
(Iteration 7501 / 24500) loss: 0.781747
(Iteration 7551 / 24500) loss: 0.959738
(Iteration 7601 / 24500) loss: 0.967898
(Iteration 7651 / 24500) loss: 0.932201
(Iteration 7701 / 24500) loss: 0.912294
(Iteration 7751 / 24500) loss: 0.881551
(Iteration 7801 / 24500) loss: 0.867875
(Epoch 16 / 50) train acc: 0.742000; val_acc: 0.574000
(Iteration 7851 / 24500) loss: 0.910479
(Iteration 7901 / 24500) loss: 0.877276
(Iteration 7951 / 24500) loss: 0.935331
(Iteration 8001 / 24500) loss: 0.750883
(Iteration 8051 / 24500) loss: 0.901990
(Iteration 8101 / 24500) loss: 0.883649
(Iteration 8151 / 24500) loss: 0.909833
(Iteration 8201 / 24500) loss: 0.967403
(Iteration 8251 / 24500) loss: 1.038371
(Iteration 8301 / 24500) loss: 0.943668
(Epoch 17 / 50) train acc: 0.748000; val_acc: 0.581000
(Iteration 8351 / 24500) loss: 0.910414
(Iteration 8401 / 24500) loss: 0.894145
(Iteration 8451 / 24500) loss: 0.861882
(Iteration 8501 / 24500) loss: 0.992075
(Iteration 8551 / 24500) loss: 0.992177
(Iteration 8601 / 24500) loss: 0.764808
(Iteration 8651 / 24500) loss: 0.940326
(Iteration 8701 / 24500) loss: 0.854406
(Iteration 8751 / 24500) loss: 0.958369
(Iteration 8801 / 24500) loss: 0.862336
(Epoch 18 / 50) train acc: 0.770000; val_acc: 0.577000
(Iteration 8851 / 24500) loss: 0.751450
(Iteration 8901 / 24500) loss: 0.946195
(Iteration 8951 / 24500) loss: 0.789359
(Iteration 9001 / 24500) loss: 0.853754
(Iteration 9051 / 24500) loss: 0.920366
(Iteration 9101 / 24500) loss: 0.744781
(Iteration 9151 / 24500) loss: 0.917746
(Iteration 9201 / 24500) loss: 0.982308
(Iteration 9251 / 24500) loss: 0.784063
(Iteration 9301 / 24500) loss: 1.103952
(Epoch 19 / 50) train acc: 0.757000; val_acc: 0.578000
(Iteration 9351 / 24500) loss: 1.017878
(Iteration 9401 / 24500) loss: 0.828724
(Iteration 9451 / 24500) loss: 0.869492
(Iteration 9501 / 24500) loss: 0.755779
(Iteration 9551 / 24500) loss: 0.876743
(Iteration 9601 / 24500) loss: 0.781474
(Iteration 9651 / 24500) loss: 0.804886
(Iteration 9701 / 24500) loss: 0.904383
(Iteration 9751 / 24500) loss: 0.925073
(Epoch 20 / 50) train acc: 0.791000; val_acc: 0.576000
(Iteration 9801 / 24500) loss: 0.928241
(Iteration 9851 / 24500) loss: 0.768492
(Iteration 9901 / 24500) loss: 0.794968
(Iteration 9951 / 24500) loss: 0.740487
(Iteration 10001 / 24500) loss: 0.665971
(Iteration 10051 / 24500) loss: 0.855147
(Iteration 10101 / 24500) loss: 0.923226
(Iteration 10151 / 24500) loss: 0.724037
(Iteration 10201 / 24500) loss: 0.891601
(Iteration 10251 / 24500) loss: 0.755480
(Epoch 21 / 50) train acc: 0.798000; val_acc: 0.582000
(Iteration 10301 / 24500) loss: 0.846079
(Iteration 10351 / 24500) loss: 0.934388
(Iteration 10401 / 24500) loss: 0.729966
(Iteration 10451 / 24500) loss: 0.741908
(Iteration 10501 / 24500) loss: 0.710918
(Iteration 10551 / 24500) loss: 0.782595
(Iteration 10601 / 24500) loss: 0.711894
(Iteration 10651 / 24500) loss: 0.810862
(Iteration 10701 / 24500) loss: 0.702281
(Iteration 10751 / 24500) loss: 0.966098
(Epoch 22 / 50) train acc: 0.806000; val_acc: 0.590000
(Iteration 10801 / 24500) loss: 0.857506
(Iteration 10851 / 24500) loss: 0.965185
(Iteration 10901 / 24500) loss: 0.687210
(Iteration 10951 / 24500) loss: 0.718187
(Iteration 11001 / 24500) loss: 0.890192
(Iteration 11051 / 24500) loss: 0.952937
(Iteration 11101 / 24500) loss: 0.908840
(Iteration 11151 / 24500) loss: 0.940939
(Iteration 11201 / 24500) loss: 0.583630
(Iteration 11251 / 24500) loss: 0.889308
(Epoch 23 / 50) train acc: 0.816000; val_acc: 0.587000
(Iteration 11301 / 24500) loss: 0.844237
(Iteration 11351 / 24500) loss: 0.668069
(Iteration 11401 / 24500) loss: 0.786731
(Iteration 11451 / 24500) loss: 0.692621
(Iteration 11501 / 24500) loss: 0.840372
(Iteration 11551 / 24500) loss: 0.837270
(Iteration 11601 / 24500) loss: 0.813919
(Iteration 11651 / 24500) loss: 0.854345
(Iteration 11701 / 24500) loss: 0.662104
(Iteration 11751 / 24500) loss: 0.815855
(Epoch 24 / 50) train acc: 0.824000; val_acc: 0.582000
(Iteration 11801 / 24500) loss: 0.897064
(Iteration 11851 / 24500) loss: 0.735938
(Iteration 11901 / 24500) loss: 1.016527
(Iteration 11951 / 24500) loss: 0.874542
(Iteration 12001 / 24500) loss: 0.650084
(Iteration 12051 / 24500) loss: 0.655396
(Iteration 12101 / 24500) loss: 0.623823
(Iteration 12151 / 24500) loss: 0.758705
(Iteration 12201 / 24500) loss: 0.650682
(Epoch 25 / 50) train acc: 0.842000; val_acc: 0.596000
(Iteration 12251 / 24500) loss: 0.935931
(Iteration 12301 / 24500) loss: 0.771854
(Iteration 12351 / 24500) loss: 0.580513
(Iteration 12401 / 24500) loss: 0.779455
(Iteration 12451 / 24500) loss: 0.613415
(Iteration 12501 / 24500) loss: 0.685626
(Iteration 12551 / 24500) loss: 0.788128
(Iteration 12601 / 24500) loss: 0.776974
(Iteration 12651 / 24500) loss: 0.647062
(Iteration 12701 / 24500) loss: 0.767735
(Epoch 26 / 50) train acc: 0.819000; val_acc: 0.582000
(Iteration 12751 / 24500) loss: 0.632911
(Iteration 12801 / 24500) loss: 0.726202
(Iteration 12851 / 24500) loss: 0.738985
(Iteration 12901 / 24500) loss: 0.557004
(Iteration 12951 / 24500) loss: 0.635296
(Iteration 13001 / 24500) loss: 0.514590
(Iteration 13051 / 24500) loss: 0.719209
(Iteration 13101 / 24500) loss: 0.680600
(Iteration 13151 / 24500) loss: 0.775000
(Iteration 13201 / 24500) loss: 0.754023
(Epoch 27 / 50) train acc: 0.836000; val_acc: 0.593000
(Iteration 13251 / 24500) loss: 0.657472
(Iteration 13301 / 24500) loss: 0.680926
(Iteration 13351 / 24500) loss: 0.735675
(Iteration 13401 / 24500) loss: 0.923187
(Iteration 13451 / 24500) loss: 0.651741
(Iteration 13501 / 24500) loss: 0.760160
(Iteration 13551 / 24500) loss: 0.981263
(Iteration 13601 / 24500) loss: 0.732767
(Iteration 13651 / 24500) loss: 0.683972
(Iteration 13701 / 24500) loss: 0.651191
(Epoch 28 / 50) train acc: 0.817000; val_acc: 0.593000
(Iteration 13751 / 24500) loss: 0.802127
(Iteration 13801 / 24500) loss: 0.779066
(Iteration 13851 / 24500) loss: 0.606702
(Iteration 13901 / 24500) loss: 0.720316
(Iteration 13951 / 24500) loss: 0.761443
(Iteration 14001 / 24500) loss: 0.870236
(Iteration 14051 / 24500) loss: 0.723591
(Iteration 14101 / 24500) loss: 0.663840
(Iteration 14151 / 24500) loss: 0.786167
(Iteration 14201 / 24500) loss: 0.601530
(Epoch 29 / 50) train acc: 0.836000; val_acc: 0.583000
(Iteration 14251 / 24500) loss: 0.722645
(Iteration 14301 / 24500) loss: 0.755530
(Iteration 14351 / 24500) loss: 0.704644
(Iteration 14401 / 24500) loss: 0.748518
(Iteration 14451 / 24500) loss: 0.783260
(Iteration 14501 / 24500) loss: 0.707390
(Iteration 14551 / 24500) loss: 0.698912
(Iteration 14601 / 24500) loss: 0.603220
(Iteration 14651 / 24500) loss: 0.712357
(Epoch 30 / 50) train acc: 0.837000; val_acc: 0.594000
(Iteration 14701 / 24500) loss: 0.631250
(Iteration 14751 / 24500) loss: 0.836975
(Iteration 14801 / 24500) loss: 0.961448
(Iteration 14851 / 24500) loss: 0.836593
(Iteration 14901 / 24500) loss: 0.846515
(Iteration 14951 / 24500) loss: 0.736870
(Iteration 15001 / 24500) loss: 0.765044
(Iteration 15051 / 24500) loss: 0.740502
(Iteration 15101 / 24500) loss: 0.837906
(Iteration 15151 / 24500) loss: 0.521742
(Epoch 31 / 50) train acc: 0.853000; val_acc: 0.592000
(Iteration 15201 / 24500) loss: 0.709120
(Iteration 15251 / 24500) loss: 0.683144
(Iteration 15301 / 24500) loss: 0.715642
(Iteration 15351 / 24500) loss: 0.844771
(Iteration 15401 / 24500) loss: 0.655988
(Iteration 15451 / 24500) loss: 0.800021
(Iteration 15501 / 24500) loss: 0.557179
(Iteration 15551 / 24500) loss: 0.614025
(Iteration 15601 / 24500) loss: 0.608311
(Iteration 15651 / 24500) loss: 0.822720
(Epoch 32 / 50) train acc: 0.859000; val_acc: 0.585000
(Iteration 15701 / 24500) loss: 0.819296
(Iteration 15751 / 24500) loss: 0.710602
(Iteration 15801 / 24500) loss: 0.866746
(Iteration 15851 / 24500) loss: 0.749734
(Iteration 15901 / 24500) loss: 0.829464
(Iteration 15951 / 24500) loss: 0.747919
(Iteration 16001 / 24500) loss: 0.958310
(Iteration 16051 / 24500) loss: 0.532266
(Iteration 16101 / 24500) loss: 0.597569
(Iteration 16151 / 24500) loss: 0.731897
(Epoch 33 / 50) train acc: 0.830000; val_acc: 0.588000
(Iteration 16201 / 24500) loss: 0.567331
(Iteration 16251 / 24500) loss: 0.758520
(Iteration 16301 / 24500) loss: 0.777737
(Iteration 16351 / 24500) loss: 0.767379
(Iteration 16401 / 24500) loss: 0.637226
(Iteration 16451 / 24500) loss: 0.622154
(Iteration 16501 / 24500) loss: 0.698914
(Iteration 16551 / 24500) loss: 0.545212
(Iteration 16601 / 24500) loss: 0.644490
(Iteration 16651 / 24500) loss: 0.725531
(Epoch 34 / 50) train acc: 0.847000; val_acc: 0.590000
(Iteration 16701 / 24500) loss: 0.687794
(Iteration 16751 / 24500) loss: 0.776865
(Iteration 16801 / 24500) loss: 0.648215
(Iteration 16851 / 24500) loss: 0.687589
(Iteration 16901 / 24500) loss: 0.726914
(Iteration 16951 / 24500) loss: 0.735936
(Iteration 17001 / 24500) loss: 0.650383
(Iteration 17051 / 24500) loss: 0.780505
(Iteration 17101 / 24500) loss: 0.763917
(Epoch 35 / 50) train acc: 0.855000; val_acc: 0.586000
(Iteration 17151 / 24500) loss: 0.728564
(Iteration 17201 / 24500) loss: 0.765131
(Iteration 17251 / 24500) loss: 0.673535
(Iteration 17301 / 24500) loss: 0.570570
(Iteration 17351 / 24500) loss: 0.785756
(Iteration 17401 / 24500) loss: 0.424662
(Iteration 17451 / 24500) loss: 0.673834
(Iteration 17501 / 24500) loss: 0.655181
(Iteration 17551 / 24500) loss: 0.554574
(Iteration 17601 / 24500) loss: 0.603897
(Epoch 36 / 50) train acc: 0.843000; val_acc: 0.588000
(Iteration 17651 / 24500) loss: 0.794176
(Iteration 17701 / 24500) loss: 0.695050
(Iteration 17751 / 24500) loss: 0.533764
(Iteration 17801 / 24500) loss: 0.725923
(Iteration 17851 / 24500) loss: 0.718230
(Iteration 17901 / 24500) loss: 0.582008
(Iteration 17951 / 24500) loss: 0.583263
(Iteration 18001 / 24500) loss: 0.586561
(Iteration 18051 / 24500) loss: 0.770813
(Iteration 18101 / 24500) loss: 0.750489
(Epoch 37 / 50) train acc: 0.846000; val_acc: 0.588000
(Iteration 18151 / 24500) loss: 0.646036
(Iteration 18201 / 24500) loss: 0.654385
(Iteration 18251 / 24500) loss: 0.647392
(Iteration 18301 / 24500) loss: 0.734609
(Iteration 18351 / 24500) loss: 0.695181
(Iteration 18401 / 24500) loss: 0.755707
(Iteration 18451 / 24500) loss: 0.630840
(Iteration 18501 / 24500) loss: 0.744641
(Iteration 18551 / 24500) loss: 0.650902
(Iteration 18601 / 24500) loss: 0.552795
(Epoch 38 / 50) train acc: 0.853000; val_acc: 0.590000
(Iteration 18651 / 24500) loss: 0.564162
(Iteration 18701 / 24500) loss: 0.569446
(Iteration 18751 / 24500) loss: 0.914159
(Iteration 18801 / 24500) loss: 0.970014
(Iteration 18851 / 24500) loss: 0.666982
(Iteration 18901 / 24500) loss: 0.672322
(Iteration 18951 / 24500) loss: 0.721812
(Iteration 19001 / 24500) loss: 0.511328
(Iteration 19051 / 24500) loss: 0.704034
(Iteration 19101 / 24500) loss: 0.815221
(Epoch 39 / 50) train acc: 0.855000; val_acc: 0.590000
(Iteration 19151 / 24500) loss: 0.706452
(Iteration 19201 / 24500) loss: 0.807563
(Iteration 19251 / 24500) loss: 0.772053
(Iteration 19301 / 24500) loss: 0.718141
(Iteration 19351 / 24500) loss: 0.674569
(Iteration 19401 / 24500) loss: 0.834507
(Iteration 19451 / 24500) loss: 0.832292
(Iteration 19501 / 24500) loss: 0.764666
(Iteration 19551 / 24500) loss: 0.645235
(Epoch 40 / 50) train acc: 0.853000; val_acc: 0.589000
(Iteration 19601 / 24500) loss: 0.655381
(Iteration 19651 / 24500) loss: 0.631948
(Iteration 19701 / 24500) loss: 0.702479
(Iteration 19751 / 24500) loss: 0.814414
(Iteration 19801 / 24500) loss: 0.687080
(Iteration 19851 / 24500) loss: 0.497703
(Iteration 19901 / 24500) loss: 0.668716
(Iteration 19951 / 24500) loss: 0.812100
(Iteration 20001 / 24500) loss: 0.560951
(Iteration 20051 / 24500) loss: 0.777928
(Epoch 41 / 50) train acc: 0.839000; val_acc: 0.590000
(Iteration 20101 / 24500) loss: 0.746758
(Iteration 20151 / 24500) loss: 0.465279
(Iteration 20201 / 24500) loss: 0.646768
(Iteration 20251 / 24500) loss: 0.612780
(Iteration 20301 / 24500) loss: 0.633310
(Iteration 20351 / 24500) loss: 0.814951
(Iteration 20401 / 24500) loss: 0.592911
(Iteration 20451 / 24500) loss: 0.673729
(Iteration 20501 / 24500) loss: 0.761498
(Iteration 20551 / 24500) loss: 0.825034
(Epoch 42 / 50) train acc: 0.857000; val_acc: 0.581000
(Iteration 20601 / 24500) loss: 0.651456
(Iteration 20651 / 24500) loss: 0.533138
(Iteration 20701 / 24500) loss: 0.627994
(Iteration 20751 / 24500) loss: 0.644368
(Iteration 20801 / 24500) loss: 0.656284
(Iteration 20851 / 24500) loss: 0.637388
(Iteration 20901 / 24500) loss: 0.655390
(Iteration 20951 / 24500) loss: 0.538309
(Iteration 21001 / 24500) loss: 0.717755
(Iteration 21051 / 24500) loss: 0.703012
(Epoch 43 / 50) train acc: 0.864000; val_acc: 0.588000
(Iteration 21101 / 24500) loss: 0.620757
(Iteration 21151 / 24500) loss: 0.522546
(Iteration 21201 / 24500) loss: 0.470623
(Iteration 21251 / 24500) loss: 0.979358
(Iteration 21301 / 24500) loss: 0.801739
(Iteration 21351 / 24500) loss: 0.665601
(Iteration 21401 / 24500) loss: 0.496071
(Iteration 21451 / 24500) loss: 0.684154
(Iteration 21501 / 24500) loss: 0.638944
(Iteration 21551 / 24500) loss: 0.784844
(Epoch 44 / 50) train acc: 0.865000; val_acc: 0.595000
(Iteration 21601 / 24500) loss: 0.576663
(Iteration 21651 / 24500) loss: 0.639701
(Iteration 21701 / 24500) loss: 0.638435
(Iteration 21751 / 24500) loss: 0.663459
(Iteration 21801 / 24500) loss: 0.614691
(Iteration 21851 / 24500) loss: 0.561645
(Iteration 21901 / 24500) loss: 0.724466
(Iteration 21951 / 24500) loss: 0.803618
(Iteration 22001 / 24500) loss: 0.585278
(Epoch 45 / 50) train acc: 0.857000; val_acc: 0.589000
(Iteration 22051 / 24500) loss: 0.737435
(Iteration 22101 / 24500) loss: 0.524869
(Iteration 22151 / 24500) loss: 0.678614
(Iteration 22201 / 24500) loss: 0.674350
(Iteration 22251 / 24500) loss: 0.712142
(Iteration 22301 / 24500) loss: 0.649296
(Iteration 22351 / 24500) loss: 0.720855
(Iteration 22401 / 24500) loss: 0.707919
(Iteration 22451 / 24500) loss: 0.594899
(Iteration 22501 / 24500) loss: 0.879776
(Epoch 46 / 50) train acc: 0.856000; val_acc: 0.591000
(Iteration 22551 / 24500) loss: 0.718631
(Iteration 22601 / 24500) loss: 0.630171
(Iteration 22651 / 24500) loss: 0.794367
(Iteration 22701 / 24500) loss: 0.716263
(Iteration 22751 / 24500) loss: 0.561148
(Iteration 22801 / 24500) loss: 0.647178
(Iteration 22851 / 24500) loss: 0.562161
(Iteration 22901 / 24500) loss: 0.640663
(Iteration 22951 / 24500) loss: 0.710555
(Iteration 23001 / 24500) loss: 0.576897
(Epoch 47 / 50) train acc: 0.856000; val_acc: 0.589000
(Iteration 23051 / 24500) loss: 0.799860
(Iteration 23101 / 24500) loss: 0.620304
(Iteration 23151 / 24500) loss: 0.793200
(Iteration 23201 / 24500) loss: 0.682168
(Iteration 23251 / 24500) loss: 0.591180
(Iteration 23301 / 24500) loss: 0.762108
(Iteration 23351 / 24500) loss: 0.608544
(Iteration 23401 / 24500) loss: 0.579912
(Iteration 23451 / 24500) loss: 0.538504
(Iteration 23501 / 24500) loss: 0.819802
(Epoch 48 / 50) train acc: 0.859000; val_acc: 0.590000
(Iteration 23551 / 24500) loss: 0.861830
(Iteration 23601 / 24500) loss: 0.549757
(Iteration 23651 / 24500) loss: 0.728011
(Iteration 23701 / 24500) loss: 0.768741
(Iteration 23751 / 24500) loss: 0.653765
(Iteration 23801 / 24500) loss: 0.615776
(Iteration 23851 / 24500) loss: 0.819586
(Iteration 23901 / 24500) loss: 0.664521
(Iteration 23951 / 24500) loss: 0.677487
(Iteration 24001 / 24500) loss: 0.828816
(Epoch 49 / 50) train acc: 0.854000; val_acc: 0.590000
(Iteration 24051 / 24500) loss: 0.525496
(Iteration 24101 / 24500) loss: 0.760438
(Iteration 24151 / 24500) loss: 0.642503
(Iteration 24201 / 24500) loss: 0.537727
(Iteration 24251 / 24500) loss: 0.859460
(Iteration 24301 / 24500) loss: 0.915119
(Iteration 24351 / 24500) loss: 0.765896
(Iteration 24401 / 24500) loss: 0.587625
(Iteration 24451 / 24500) loss: 0.575983
(Epoch 50 / 50) train acc: 0.865000; val_acc: 0.585000