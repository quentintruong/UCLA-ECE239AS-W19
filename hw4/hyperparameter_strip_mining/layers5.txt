layer_dims = [600, 600, 600, 600, 600]
weight_scale = 0.01
learning_rate = 1e-3
lr_decay = 0.90

model = FullyConnectedNet(layer_dims, weight_scale=weight_scale,
                          dropout=0.65, reg=0.0, use_batchnorm=True)

solver = Solver(model, data,
                num_epochs=50, batch_size=100,
                update_rule='adam',
                optim_config={
                  'learning_rate': learning_rate,
                },
                lr_decay=lr_decay,
                verbose=True, print_every=50)
solver.train()

(Iteration 1 / 24500) loss: 2.333317
(Epoch 0 / 50) train acc: 0.144000; val_acc: 0.149000
(Iteration 51 / 24500) loss: 1.826810
(Iteration 101 / 24500) loss: 1.925052
(Iteration 151 / 24500) loss: 1.706812
(Iteration 201 / 24500) loss: 1.758924
(Iteration 251 / 24500) loss: 1.874326
(Iteration 301 / 24500) loss: 1.693739
(Iteration 351 / 24500) loss: 1.521227
(Iteration 401 / 24500) loss: 1.623397
(Iteration 451 / 24500) loss: 1.474746
(Epoch 1 / 50) train acc: 0.454000; val_acc: 0.439000
(Iteration 501 / 24500) loss: 1.487947
(Iteration 551 / 24500) loss: 1.645598
(Iteration 601 / 24500) loss: 1.569300
(Iteration 651 / 24500) loss: 1.774324
(Iteration 701 / 24500) loss: 1.508567
(Iteration 751 / 24500) loss: 1.784095
(Iteration 801 / 24500) loss: 1.354668
(Iteration 851 / 24500) loss: 1.599809
(Iteration 901 / 24500) loss: 1.543173
(Iteration 951 / 24500) loss: 1.461995
(Epoch 2 / 50) train acc: 0.497000; val_acc: 0.508000
(Iteration 1001 / 24500) loss: 1.588724
(Iteration 1051 / 24500) loss: 1.417722
(Iteration 1101 / 24500) loss: 1.493968
(Iteration 1151 / 24500) loss: 1.373407
(Iteration 1201 / 24500) loss: 1.392217
(Iteration 1251 / 24500) loss: 1.304650
(Iteration 1301 / 24500) loss: 1.343553
(Iteration 1351 / 24500) loss: 1.413463
(Iteration 1401 / 24500) loss: 1.446043
(Iteration 1451 / 24500) loss: 1.408683
(Epoch 3 / 50) train acc: 0.542000; val_acc: 0.505000
(Iteration 1501 / 24500) loss: 1.456913
(Iteration 1551 / 24500) loss: 1.497327
(Iteration 1601 / 24500) loss: 1.463427
(Iteration 1651 / 24500) loss: 1.376414
(Iteration 1701 / 24500) loss: 1.280934
(Iteration 1751 / 24500) loss: 1.392514
(Iteration 1801 / 24500) loss: 1.459001
(Iteration 1851 / 24500) loss: 1.392469
(Iteration 1901 / 24500) loss: 1.345998
(Iteration 1951 / 24500) loss: 1.360993
(Epoch 4 / 50) train acc: 0.553000; val_acc: 0.526000
(Iteration 2001 / 24500) loss: 1.471488
(Iteration 2051 / 24500) loss: 1.407598
(Iteration 2101 / 24500) loss: 1.150635
(Iteration 2151 / 24500) loss: 1.528720
(Iteration 2201 / 24500) loss: 1.265015
(Iteration 2251 / 24500) loss: 1.293765
(Iteration 2301 / 24500) loss: 1.285381
(Iteration 2351 / 24500) loss: 1.403590
(Iteration 2401 / 24500) loss: 1.259331
(Epoch 5 / 50) train acc: 0.571000; val_acc: 0.532000
(Iteration 2451 / 24500) loss: 1.370475
(Iteration 2501 / 24500) loss: 1.253135
(Iteration 2551 / 24500) loss: 1.292543
(Iteration 2601 / 24500) loss: 1.209286
(Iteration 2651 / 24500) loss: 1.045808
(Iteration 2701 / 24500) loss: 1.382313
(Iteration 2751 / 24500) loss: 1.407252
(Iteration 2801 / 24500) loss: 1.199024
(Iteration 2851 / 24500) loss: 1.141265
(Iteration 2901 / 24500) loss: 1.255047
(Epoch 6 / 50) train acc: 0.577000; val_acc: 0.529000
(Iteration 2951 / 24500) loss: 1.284663
(Iteration 3001 / 24500) loss: 1.125001
(Iteration 3051 / 24500) loss: 1.102355
(Iteration 3101 / 24500) loss: 1.333018
(Iteration 3151 / 24500) loss: 1.283981
(Iteration 3201 / 24500) loss: 1.467028
(Iteration 3251 / 24500) loss: 1.444180
(Iteration 3301 / 24500) loss: 1.147436
(Iteration 3351 / 24500) loss: 1.222811
(Iteration 3401 / 24500) loss: 1.180056
(Epoch 7 / 50) train acc: 0.590000; val_acc: 0.534000
(Iteration 3451 / 24500) loss: 1.210329
(Iteration 3501 / 24500) loss: 1.170530
(Iteration 3551 / 24500) loss: 1.143127
(Iteration 3601 / 24500) loss: 1.255698
(Iteration 3651 / 24500) loss: 1.167449
(Iteration 3701 / 24500) loss: 1.275042
(Iteration 3751 / 24500) loss: 1.267956
(Iteration 3801 / 24500) loss: 1.196819
(Iteration 3851 / 24500) loss: 1.128717
(Iteration 3901 / 24500) loss: 1.197012
(Epoch 8 / 50) train acc: 0.646000; val_acc: 0.545000
(Iteration 3951 / 24500) loss: 1.148258
(Iteration 4001 / 24500) loss: 1.204952
(Iteration 4051 / 24500) loss: 1.418676
(Iteration 4101 / 24500) loss: 1.124450
(Iteration 4151 / 24500) loss: 1.076955
(Iteration 4201 / 24500) loss: 1.127723
(Iteration 4251 / 24500) loss: 1.168671
(Iteration 4301 / 24500) loss: 1.129712
(Iteration 4351 / 24500) loss: 0.907602
(Iteration 4401 / 24500) loss: 1.187377
(Epoch 9 / 50) train acc: 0.617000; val_acc: 0.555000
(Iteration 4451 / 24500) loss: 1.171945
(Iteration 4501 / 24500) loss: 1.210096
(Iteration 4551 / 24500) loss: 1.060363
(Iteration 4601 / 24500) loss: 1.028425
(Iteration 4651 / 24500) loss: 1.052357
(Iteration 4701 / 24500) loss: 1.199342
(Iteration 4751 / 24500) loss: 0.946984
(Iteration 4801 / 24500) loss: 1.131811
(Iteration 4851 / 24500) loss: 1.039088
(Epoch 10 / 50) train acc: 0.635000; val_acc: 0.554000
(Iteration 4901 / 24500) loss: 0.959067
(Iteration 4951 / 24500) loss: 1.209574
(Iteration 5001 / 24500) loss: 1.122206
(Iteration 5051 / 24500) loss: 1.039762
(Iteration 5101 / 24500) loss: 1.185187
(Iteration 5151 / 24500) loss: 1.118088
(Iteration 5201 / 24500) loss: 1.014107
(Iteration 5251 / 24500) loss: 1.150844
(Iteration 5301 / 24500) loss: 1.251722
(Iteration 5351 / 24500) loss: 1.205765
(Epoch 11 / 50) train acc: 0.659000; val_acc: 0.556000
(Iteration 5401 / 24500) loss: 1.423752
(Iteration 5451 / 24500) loss: 1.099283
(Iteration 5501 / 24500) loss: 1.104935
(Iteration 5551 / 24500) loss: 1.176992
(Iteration 5601 / 24500) loss: 1.069634
(Iteration 5651 / 24500) loss: 1.087007
(Iteration 5701 / 24500) loss: 0.847040
(Iteration 5751 / 24500) loss: 1.350969
(Iteration 5801 / 24500) loss: 1.086146
(Iteration 5851 / 24500) loss: 1.100929
(Epoch 12 / 50) train acc: 0.678000; val_acc: 0.562000
(Iteration 5901 / 24500) loss: 1.196173
(Iteration 5951 / 24500) loss: 1.093808
(Iteration 6001 / 24500) loss: 1.047124
(Iteration 6051 / 24500) loss: 1.289898
(Iteration 6101 / 24500) loss: 1.085270
(Iteration 6151 / 24500) loss: 0.886961
(Iteration 6201 / 24500) loss: 1.142071
(Iteration 6251 / 24500) loss: 1.243143
(Iteration 6301 / 24500) loss: 0.958784
(Iteration 6351 / 24500) loss: 1.122911
(Epoch 13 / 50) train acc: 0.671000; val_acc: 0.575000
(Iteration 6401 / 24500) loss: 1.078318
(Iteration 6451 / 24500) loss: 1.123434
(Iteration 6501 / 24500) loss: 0.950585
(Iteration 6551 / 24500) loss: 0.991378
(Iteration 6601 / 24500) loss: 0.977675
(Iteration 6651 / 24500) loss: 1.092351
(Iteration 6701 / 24500) loss: 1.153568
(Iteration 6751 / 24500) loss: 1.225170
(Iteration 6801 / 24500) loss: 1.185855
(Iteration 6851 / 24500) loss: 0.907383
(Epoch 14 / 50) train acc: 0.704000; val_acc: 0.575000
(Iteration 6901 / 24500) loss: 1.235109
(Iteration 6951 / 24500) loss: 1.239277
(Iteration 7001 / 24500) loss: 1.040558
(Iteration 7051 / 24500) loss: 1.012101
(Iteration 7101 / 24500) loss: 1.167877
(Iteration 7151 / 24500) loss: 1.074032
(Iteration 7201 / 24500) loss: 1.068161
(Iteration 7251 / 24500) loss: 1.066569
(Iteration 7301 / 24500) loss: 1.007332
(Epoch 15 / 50) train acc: 0.698000; val_acc: 0.576000
(Iteration 7351 / 24500) loss: 1.003337
(Iteration 7401 / 24500) loss: 0.945551
(Iteration 7451 / 24500) loss: 1.033857
(Iteration 7501 / 24500) loss: 1.090162
(Iteration 7551 / 24500) loss: 1.135743
(Iteration 7601 / 24500) loss: 1.048486
(Iteration 7651 / 24500) loss: 0.993174
(Iteration 7701 / 24500) loss: 0.982207
(Iteration 7751 / 24500) loss: 0.840551
(Iteration 7801 / 24500) loss: 0.976484
(Epoch 16 / 50) train acc: 0.727000; val_acc: 0.567000
(Iteration 7851 / 24500) loss: 0.950241
(Iteration 7901 / 24500) loss: 0.950368
(Iteration 7951 / 24500) loss: 1.191071
(Iteration 8001 / 24500) loss: 0.954152
(Iteration 8051 / 24500) loss: 1.055456
(Iteration 8101 / 24500) loss: 1.167444
(Iteration 8151 / 24500) loss: 0.977391
(Iteration 8201 / 24500) loss: 0.939283
(Iteration 8251 / 24500) loss: 0.922121
(Iteration 8301 / 24500) loss: 1.091329
(Epoch 17 / 50) train acc: 0.751000; val_acc: 0.570000
(Iteration 8351 / 24500) loss: 1.046612
(Iteration 8401 / 24500) loss: 0.866778
(Iteration 8451 / 24500) loss: 1.081191
(Iteration 8501 / 24500) loss: 1.004019
(Iteration 8551 / 24500) loss: 0.986985
(Iteration 8601 / 24500) loss: 0.935365
(Iteration 8651 / 24500) loss: 1.066173
(Iteration 8701 / 24500) loss: 0.964065
(Iteration 8751 / 24500) loss: 0.924080
(Iteration 8801 / 24500) loss: 1.200885
(Epoch 18 / 50) train acc: 0.719000; val_acc: 0.582000
(Iteration 8851 / 24500) loss: 0.938904
(Iteration 8901 / 24500) loss: 0.966758
(Iteration 8951 / 24500) loss: 0.886913
(Iteration 9001 / 24500) loss: 0.935087
(Iteration 9051 / 24500) loss: 1.086763
(Iteration 9101 / 24500) loss: 1.026735
(Iteration 9151 / 24500) loss: 0.885413
(Iteration 9201 / 24500) loss: 0.944571
(Iteration 9251 / 24500) loss: 1.042079
(Iteration 9301 / 24500) loss: 1.038064
(Epoch 19 / 50) train acc: 0.728000; val_acc: 0.585000
(Iteration 9351 / 24500) loss: 0.803815
(Iteration 9401 / 24500) loss: 0.940642
(Iteration 9451 / 24500) loss: 1.139209
(Iteration 9501 / 24500) loss: 0.917645
(Iteration 9551 / 24500) loss: 0.926111
(Iteration 9601 / 24500) loss: 1.056113
(Iteration 9651 / 24500) loss: 1.076795
(Iteration 9701 / 24500) loss: 0.871781
(Iteration 9751 / 24500) loss: 1.024174
(Epoch 20 / 50) train acc: 0.742000; val_acc: 0.579000
(Iteration 9801 / 24500) loss: 0.855803
(Iteration 9851 / 24500) loss: 1.108062
(Iteration 9901 / 24500) loss: 0.806541
(Iteration 9951 / 24500) loss: 0.830831
(Iteration 10001 / 24500) loss: 0.801605
(Iteration 10051 / 24500) loss: 0.955604
(Iteration 10101 / 24500) loss: 1.045674
(Iteration 10151 / 24500) loss: 0.824698
(Iteration 10201 / 24500) loss: 1.015687
(Iteration 10251 / 24500) loss: 0.855497
(Epoch 21 / 50) train acc: 0.747000; val_acc: 0.576000
(Iteration 10301 / 24500) loss: 0.817283
(Iteration 10351 / 24500) loss: 0.913097
(Iteration 10401 / 24500) loss: 0.821409
(Iteration 10451 / 24500) loss: 0.924922
(Iteration 10501 / 24500) loss: 0.740113
(Iteration 10551 / 24500) loss: 1.025084
(Iteration 10601 / 24500) loss: 0.904537
(Iteration 10651 / 24500) loss: 0.985268
(Iteration 10701 / 24500) loss: 1.091726
(Iteration 10751 / 24500) loss: 0.936921
(Epoch 22 / 50) train acc: 0.725000; val_acc: 0.582000
(Iteration 10801 / 24500) loss: 0.865705
(Iteration 10851 / 24500) loss: 0.845768
(Iteration 10901 / 24500) loss: 0.906380
(Iteration 10951 / 24500) loss: 0.939335
(Iteration 11001 / 24500) loss: 0.883242
(Iteration 11051 / 24500) loss: 0.840798
(Iteration 11101 / 24500) loss: 0.779900
(Iteration 11151 / 24500) loss: 0.883886
(Iteration 11201 / 24500) loss: 1.008121
(Iteration 11251 / 24500) loss: 0.909460
(Epoch 23 / 50) train acc: 0.735000; val_acc: 0.587000
(Iteration 11301 / 24500) loss: 0.926116
(Iteration 11351 / 24500) loss: 0.898230
(Iteration 11401 / 24500) loss: 0.799848
(Iteration 11451 / 24500) loss: 1.203768
(Iteration 11501 / 24500) loss: 1.099213
(Iteration 11551 / 24500) loss: 0.911113
(Iteration 11601 / 24500) loss: 1.215141
(Iteration 11651 / 24500) loss: 0.983546
(Iteration 11701 / 24500) loss: 1.067534
(Iteration 11751 / 24500) loss: 0.973621
(Epoch 24 / 50) train acc: 0.739000; val_acc: 0.575000
(Iteration 11801 / 24500) loss: 0.931155
(Iteration 11851 / 24500) loss: 1.082798
(Iteration 11901 / 24500) loss: 0.922455
(Iteration 11951 / 24500) loss: 0.955091
(Iteration 12001 / 24500) loss: 1.150495
(Iteration 12051 / 24500) loss: 0.810312
(Iteration 12101 / 24500) loss: 0.879574
(Iteration 12151 / 24500) loss: 0.993582
(Iteration 12201 / 24500) loss: 0.929313
(Epoch 25 / 50) train acc: 0.751000; val_acc: 0.575000
(Iteration 12251 / 24500) loss: 0.740467
(Iteration 12301 / 24500) loss: 1.023598
(Iteration 12351 / 24500) loss: 0.834233
(Iteration 12401 / 24500) loss: 0.832414
(Iteration 12451 / 24500) loss: 1.133337
(Iteration 12501 / 24500) loss: 0.793788
(Iteration 12551 / 24500) loss: 0.878442
(Iteration 12601 / 24500) loss: 0.882678
(Iteration 12651 / 24500) loss: 0.964952
(Iteration 12701 / 24500) loss: 0.771205
(Epoch 26 / 50) train acc: 0.748000; val_acc: 0.572000
(Iteration 12751 / 24500) loss: 0.704874
(Iteration 12801 / 24500) loss: 0.791030
(Iteration 12851 / 24500) loss: 0.826986
(Iteration 12901 / 24500) loss: 0.760117
(Iteration 12951 / 24500) loss: 0.873824
(Iteration 13001 / 24500) loss: 0.600410
(Iteration 13051 / 24500) loss: 0.895965
(Iteration 13101 / 24500) loss: 0.884248
(Iteration 13151 / 24500) loss: 1.138439
(Iteration 13201 / 24500) loss: 1.059267
(Epoch 27 / 50) train acc: 0.755000; val_acc: 0.579000
(Iteration 13251 / 24500) loss: 0.862011
(Iteration 13301 / 24500) loss: 0.873833
(Iteration 13351 / 24500) loss: 0.871902
(Iteration 13401 / 24500) loss: 0.935921
(Iteration 13451 / 24500) loss: 0.978166
(Iteration 13501 / 24500) loss: 0.849386
(Iteration 13551 / 24500) loss: 0.759449
(Iteration 13601 / 24500) loss: 0.813823
(Iteration 13651 / 24500) loss: 0.926340
(Iteration 13701 / 24500) loss: 0.793837
(Epoch 28 / 50) train acc: 0.774000; val_acc: 0.575000
(Iteration 13751 / 24500) loss: 0.801678
(Iteration 13801 / 24500) loss: 0.893011
(Iteration 13851 / 24500) loss: 0.667192
(Iteration 13901 / 24500) loss: 0.807778
(Iteration 13951 / 24500) loss: 0.901488
(Iteration 14001 / 24500) loss: 1.081328
(Iteration 14051 / 24500) loss: 0.743845
(Iteration 14101 / 24500) loss: 0.887959
(Iteration 14151 / 24500) loss: 0.854160
(Iteration 14201 / 24500) loss: 0.772484
(Epoch 29 / 50) train acc: 0.764000; val_acc: 0.581000
(Iteration 14251 / 24500) loss: 0.886432
(Iteration 14301 / 24500) loss: 0.843769
(Iteration 14351 / 24500) loss: 0.887150
(Iteration 14401 / 24500) loss: 0.923367
(Iteration 14451 / 24500) loss: 1.078399
(Iteration 14501 / 24500) loss: 0.858031
(Iteration 14551 / 24500) loss: 0.790305
(Iteration 14601 / 24500) loss: 0.905274
(Iteration 14651 / 24500) loss: 0.790549
(Epoch 30 / 50) train acc: 0.787000; val_acc: 0.586000
(Iteration 14701 / 24500) loss: 0.843527
(Iteration 14751 / 24500) loss: 0.813688
(Iteration 14801 / 24500) loss: 1.006453
(Iteration 14851 / 24500) loss: 0.997618
(Iteration 14901 / 24500) loss: 0.714649
(Iteration 14951 / 24500) loss: 0.836562
(Iteration 15001 / 24500) loss: 0.768241
(Iteration 15051 / 24500) loss: 0.957920
(Iteration 15101 / 24500) loss: 1.030320
(Iteration 15151 / 24500) loss: 0.717985
(Epoch 31 / 50) train acc: 0.770000; val_acc: 0.585000
(Iteration 15201 / 24500) loss: 0.729872
(Iteration 15251 / 24500) loss: 0.920338
(Iteration 15301 / 24500) loss: 0.953992
(Iteration 15351 / 24500) loss: 0.804504
(Iteration 15401 / 24500) loss: 0.897899
(Iteration 15451 / 24500) loss: 0.838271
(Iteration 15501 / 24500) loss: 1.217652
(Iteration 15551 / 24500) loss: 0.741587
(Iteration 15601 / 24500) loss: 0.787945
(Iteration 15651 / 24500) loss: 0.733219
(Epoch 32 / 50) train acc: 0.772000; val_acc: 0.581000
(Iteration 15701 / 24500) loss: 0.837869
(Iteration 15751 / 24500) loss: 0.877254
(Iteration 15801 / 24500) loss: 0.850219
(Iteration 15851 / 24500) loss: 0.766748
(Iteration 15901 / 24500) loss: 0.820057
(Iteration 15951 / 24500) loss: 0.993653
(Iteration 16001 / 24500) loss: 0.635045
(Iteration 16051 / 24500) loss: 0.830178
(Iteration 16101 / 24500) loss: 0.878715
(Iteration 16151 / 24500) loss: 0.885487
(Epoch 33 / 50) train acc: 0.780000; val_acc: 0.586000
(Iteration 16201 / 24500) loss: 0.792921
(Iteration 16251 / 24500) loss: 0.797099
(Iteration 16301 / 24500) loss: 0.945966
(Iteration 16351 / 24500) loss: 0.819988
(Iteration 16401 / 24500) loss: 0.859561
(Iteration 16451 / 24500) loss: 0.854288
(Iteration 16501 / 24500) loss: 0.728220
(Iteration 16551 / 24500) loss: 0.832759
(Iteration 16601 / 24500) loss: 0.925431
(Iteration 16651 / 24500) loss: 0.869027
(Epoch 34 / 50) train acc: 0.757000; val_acc: 0.584000
(Iteration 16701 / 24500) loss: 0.791696
(Iteration 16751 / 24500) loss: 0.919105
(Iteration 16801 / 24500) loss: 0.874667
(Iteration 16851 / 24500) loss: 0.808399
(Iteration 16901 / 24500) loss: 0.955491
(Iteration 16951 / 24500) loss: 1.016605
(Iteration 17001 / 24500) loss: 0.711415
(Iteration 17051 / 24500) loss: 0.894859
(Iteration 17101 / 24500) loss: 0.879067
(Epoch 35 / 50) train acc: 0.776000; val_acc: 0.580000
(Iteration 17151 / 24500) loss: 0.842060
(Iteration 17201 / 24500) loss: 0.778327
(Iteration 17251 / 24500) loss: 0.846580
(Iteration 17301 / 24500) loss: 0.799380
(Iteration 17351 / 24500) loss: 0.851049
(Iteration 17401 / 24500) loss: 0.813829
(Iteration 17451 / 24500) loss: 1.138046
(Iteration 17501 / 24500) loss: 0.830393
(Iteration 17551 / 24500) loss: 0.749677
(Iteration 17601 / 24500) loss: 0.845864
(Epoch 36 / 50) train acc: 0.772000; val_acc: 0.580000
(Iteration 17651 / 24500) loss: 0.986319
(Iteration 17701 / 24500) loss: 0.926798
(Iteration 17751 / 24500) loss: 0.916280
(Iteration 17801 / 24500) loss: 0.867369
(Iteration 17851 / 24500) loss: 0.719909
(Iteration 17901 / 24500) loss: 0.668187
(Iteration 17951 / 24500) loss: 0.794067
(Iteration 18001 / 24500) loss: 1.184137
(Iteration 18051 / 24500) loss: 1.049916
(Iteration 18101 / 24500) loss: 0.807746
(Epoch 37 / 50) train acc: 0.781000; val_acc: 0.580000
(Iteration 18151 / 24500) loss: 0.810342
(Iteration 18201 / 24500) loss: 0.922982
(Iteration 18251 / 24500) loss: 0.846921
(Iteration 18301 / 24500) loss: 0.770654
(Iteration 18351 / 24500) loss: 0.835804
(Iteration 18401 / 24500) loss: 0.917202
(Iteration 18451 / 24500) loss: 0.810552
(Iteration 18501 / 24500) loss: 0.854925
(Iteration 18551 / 24500) loss: 0.934328
(Iteration 18601 / 24500) loss: 0.824836
(Epoch 38 / 50) train acc: 0.784000; val_acc: 0.579000
(Iteration 18651 / 24500) loss: 0.717485
(Iteration 18701 / 24500) loss: 0.859244
(Iteration 18751 / 24500) loss: 0.849528
(Iteration 18801 / 24500) loss: 0.836765
(Iteration 18851 / 24500) loss: 0.740384
(Iteration 18901 / 24500) loss: 0.899805
(Iteration 18951 / 24500) loss: 0.797189
(Iteration 19001 / 24500) loss: 0.840106
(Iteration 19051 / 24500) loss: 0.779907
(Iteration 19101 / 24500) loss: 0.851453
(Epoch 39 / 50) train acc: 0.796000; val_acc: 0.584000
(Iteration 19151 / 24500) loss: 0.927474
(Iteration 19201 / 24500) loss: 0.789081
(Iteration 19251 / 24500) loss: 0.859459
(Iteration 19301 / 24500) loss: 0.774875
(Iteration 19351 / 24500) loss: 0.806491
(Iteration 19401 / 24500) loss: 0.786737
(Iteration 19451 / 24500) loss: 0.923514
(Iteration 19501 / 24500) loss: 0.720522
(Iteration 19551 / 24500) loss: 0.854604
(Epoch 40 / 50) train acc: 0.754000; val_acc: 0.582000
(Iteration 19601 / 24500) loss: 0.808292
(Iteration 19651 / 24500) loss: 0.843663
(Iteration 19701 / 24500) loss: 0.873896
(Iteration 19751 / 24500) loss: 0.787178
(Iteration 19801 / 24500) loss: 1.061665
(Iteration 19851 / 24500) loss: 0.828296
(Iteration 19901 / 24500) loss: 0.793008
(Iteration 19951 / 24500) loss: 1.011128
(Iteration 20001 / 24500) loss: 1.033169
(Iteration 20051 / 24500) loss: 0.881743
(Epoch 41 / 50) train acc: 0.781000; val_acc: 0.586000
(Iteration 20101 / 24500) loss: 0.743556
(Iteration 20151 / 24500) loss: 0.830829
(Iteration 20201 / 24500) loss: 0.790293
(Iteration 20251 / 24500) loss: 0.801615
(Iteration 20301 / 24500) loss: 0.794545
(Iteration 20351 / 24500) loss: 0.901073
(Iteration 20401 / 24500) loss: 0.677189
(Iteration 20451 / 24500) loss: 0.785162
(Iteration 20501 / 24500) loss: 0.735084
(Iteration 20551 / 24500) loss: 0.834033
(Epoch 42 / 50) train acc: 0.793000; val_acc: 0.587000
(Iteration 20601 / 24500) loss: 0.726501
(Iteration 20651 / 24500) loss: 0.797384
(Iteration 20701 / 24500) loss: 0.973296
(Iteration 20751 / 24500) loss: 0.843931
(Iteration 20801 / 24500) loss: 0.696487
(Iteration 20851 / 24500) loss: 0.880501
(Iteration 20901 / 24500) loss: 0.856346
(Iteration 20951 / 24500) loss: 0.856892
(Iteration 21001 / 24500) loss: 0.802313
(Iteration 21051 / 24500) loss: 0.652848
(Epoch 43 / 50) train acc: 0.791000; val_acc: 0.585000
(Iteration 21101 / 24500) loss: 0.865725
(Iteration 21151 / 24500) loss: 1.033808
(Iteration 21201 / 24500) loss: 0.723528
(Iteration 21251 / 24500) loss: 0.819900
(Iteration 21301 / 24500) loss: 0.801056
(Iteration 21351 / 24500) loss: 0.741303
(Iteration 21401 / 24500) loss: 0.742676
(Iteration 21451 / 24500) loss: 0.838284
(Iteration 21501 / 24500) loss: 0.761813
(Iteration 21551 / 24500) loss: 0.876352
(Epoch 44 / 50) train acc: 0.792000; val_acc: 0.585000
(Iteration 21601 / 24500) loss: 0.871369
(Iteration 21651 / 24500) loss: 0.698466
(Iteration 21701 / 24500) loss: 0.946704
(Iteration 21751 / 24500) loss: 0.960780
(Iteration 21801 / 24500) loss: 0.915426
(Iteration 21851 / 24500) loss: 0.705291
(Iteration 21901 / 24500) loss: 0.853605
(Iteration 21951 / 24500) loss: 0.848152
(Iteration 22001 / 24500) loss: 0.815219
(Epoch 45 / 50) train acc: 0.760000; val_acc: 0.580000
(Iteration 22051 / 24500) loss: 0.791606
(Iteration 22101 / 24500) loss: 0.869299
(Iteration 22151 / 24500) loss: 0.721335
(Iteration 22201 / 24500) loss: 0.816073
(Iteration 22251 / 24500) loss: 0.773005
(Iteration 22301 / 24500) loss: 0.888781
(Iteration 22351 / 24500) loss: 0.760705
(Iteration 22401 / 24500) loss: 0.855879
(Iteration 22451 / 24500) loss: 0.890487
(Iteration 22501 / 24500) loss: 0.943905
(Epoch 46 / 50) train acc: 0.792000; val_acc: 0.580000
(Iteration 22551 / 24500) loss: 0.863522
(Iteration 22601 / 24500) loss: 1.013548
(Iteration 22651 / 24500) loss: 0.948761
(Iteration 22701 / 24500) loss: 0.807243
(Iteration 22751 / 24500) loss: 0.906950
(Iteration 22801 / 24500) loss: 0.807118
(Iteration 22851 / 24500) loss: 0.758932
(Iteration 22901 / 24500) loss: 0.829233
(Iteration 22951 / 24500) loss: 0.703985
(Iteration 23001 / 24500) loss: 0.950642
(Epoch 47 / 50) train acc: 0.799000; val_acc: 0.581000
(Iteration 23051 / 24500) loss: 0.688329
(Iteration 23101 / 24500) loss: 0.830001
(Iteration 23151 / 24500) loss: 1.048779
(Iteration 23201 / 24500) loss: 0.847288
(Iteration 23251 / 24500) loss: 0.528600
(Iteration 23301 / 24500) loss: 0.742808
(Iteration 23351 / 24500) loss: 0.820529
(Iteration 23401 / 24500) loss: 0.824102
(Iteration 23451 / 24500) loss: 0.896319
(Iteration 23501 / 24500) loss: 0.790407
(Epoch 48 / 50) train acc: 0.790000; val_acc: 0.582000
(Iteration 23551 / 24500) loss: 0.753306
(Iteration 23601 / 24500) loss: 0.797669
(Iteration 23651 / 24500) loss: 0.839218
(Iteration 23701 / 24500) loss: 0.846950
(Iteration 23751 / 24500) loss: 0.976724
(Iteration 23801 / 24500) loss: 0.788112
(Iteration 23851 / 24500) loss: 0.929589
(Iteration 23901 / 24500) loss: 0.809895
(Iteration 23951 / 24500) loss: 0.938980
(Iteration 24001 / 24500) loss: 0.808364
(Epoch 49 / 50) train acc: 0.790000; val_acc: 0.584000
(Iteration 24051 / 24500) loss: 0.739902
(Iteration 24101 / 24500) loss: 0.802488
(Iteration 24151 / 24500) loss: 0.657349
(Iteration 24201 / 24500) loss: 0.762027
(Iteration 24251 / 24500) loss: 0.917712
(Iteration 24301 / 24500) loss: 0.953045
(Iteration 24351 / 24500) loss: 0.959973
(Iteration 24401 / 24500) loss: 0.832033
(Iteration 24451 / 24500) loss: 0.931569
(Epoch 50 / 50) train acc: 0.759000; val_acc: 0.582000